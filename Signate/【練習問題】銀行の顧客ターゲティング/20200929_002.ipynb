{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataの読み込み\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submit_df = pd.read_csv('submit_sample.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27128, 18), (18083, 17), (18083, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの量の確認\n",
    "train_df.shape,test_df.shape,submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータがわかるようにダミーの目的変数を代入\n",
    "test_df['y']=-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データ、テストデータを結合\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # カテゴリカラムの前処理\n",
    "categorical_features = ['job', 'marital', 'education','default','housing','loan','contact','month','poutcome']\n",
    "# for col in categorical_features:\n",
    "#     lbl = preprocessing.LabelEncoder()\n",
    "#     lbl.fit(all_df[col])\n",
    "#     lbl.transform(all_df[col])\n",
    "#     all_df[col]=lbl.transform(all_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.get_dummies(all_df, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータの分割\n",
    "train_df = all_df[all_df['y']!=-999]\n",
    "test_df = all_df[all_df['y']==-999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['y']\n",
    "X_train = train_df.drop(['y','id'], axis=1)\n",
    "X_test = test_df.drop(['y','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238082\tvalid_1's binary_logloss: 0.240731\n",
      "[20]\ttraining's binary_logloss: 0.206788\tvalid_1's binary_logloss: 0.214783\n",
      "[30]\ttraining's binary_logloss: 0.190233\tvalid_1's binary_logloss: 0.203889\n",
      "[40]\ttraining's binary_logloss: 0.179181\tvalid_1's binary_logloss: 0.199116\n",
      "[50]\ttraining's binary_logloss: 0.171395\tvalid_1's binary_logloss: 0.197962\n",
      "[60]\ttraining's binary_logloss: 0.165444\tvalid_1's binary_logloss: 0.197785\n",
      "[70]\ttraining's binary_logloss: 0.160017\tvalid_1's binary_logloss: 0.197045\n",
      "[80]\ttraining's binary_logloss: 0.155355\tvalid_1's binary_logloss: 0.197356\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.160017\tvalid_1's binary_logloss: 0.197045\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234737\tvalid_1's binary_logloss: 0.243639\n",
      "[20]\ttraining's binary_logloss: 0.205136\tvalid_1's binary_logloss: 0.220195\n",
      "[30]\ttraining's binary_logloss: 0.189438\tvalid_1's binary_logloss: 0.210359\n",
      "[40]\ttraining's binary_logloss: 0.179172\tvalid_1's binary_logloss: 0.206236\n",
      "[50]\ttraining's binary_logloss: 0.171358\tvalid_1's binary_logloss: 0.204245\n",
      "[60]\ttraining's binary_logloss: 0.164192\tvalid_1's binary_logloss: 0.201748\n",
      "[70]\ttraining's binary_logloss: 0.158519\tvalid_1's binary_logloss: 0.200484\n",
      "[80]\ttraining's binary_logloss: 0.153676\tvalid_1's binary_logloss: 0.19945\n",
      "[90]\ttraining's binary_logloss: 0.149019\tvalid_1's binary_logloss: 0.199288\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.151565\tvalid_1's binary_logloss: 0.19882\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234581\tvalid_1's binary_logloss: 0.245861\n",
      "[20]\ttraining's binary_logloss: 0.203755\tvalid_1's binary_logloss: 0.22122\n",
      "[30]\ttraining's binary_logloss: 0.185917\tvalid_1's binary_logloss: 0.210374\n",
      "[40]\ttraining's binary_logloss: 0.175817\tvalid_1's binary_logloss: 0.207251\n",
      "[50]\ttraining's binary_logloss: 0.167632\tvalid_1's binary_logloss: 0.205759\n",
      "[60]\ttraining's binary_logloss: 0.160631\tvalid_1's binary_logloss: 0.205043\n",
      "[70]\ttraining's binary_logloss: 0.154483\tvalid_1's binary_logloss: 0.204465\n",
      "[80]\ttraining's binary_logloss: 0.149423\tvalid_1's binary_logloss: 0.204368\n",
      "[90]\ttraining's binary_logloss: 0.144542\tvalid_1's binary_logloss: 0.204106\n",
      "[100]\ttraining's binary_logloss: 0.140247\tvalid_1's binary_logloss: 0.204179\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's binary_logloss: 0.142058\tvalid_1's binary_logloss: 0.203975\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237898\tvalid_1's binary_logloss: 0.240773\n",
      "[20]\ttraining's binary_logloss: 0.207411\tvalid_1's binary_logloss: 0.214718\n",
      "[30]\ttraining's binary_logloss: 0.189844\tvalid_1's binary_logloss: 0.202645\n",
      "[40]\ttraining's binary_logloss: 0.179561\tvalid_1's binary_logloss: 0.198632\n",
      "[50]\ttraining's binary_logloss: 0.171044\tvalid_1's binary_logloss: 0.196624\n",
      "[60]\ttraining's binary_logloss: 0.164015\tvalid_1's binary_logloss: 0.19597\n",
      "[70]\ttraining's binary_logloss: 0.158191\tvalid_1's binary_logloss: 0.195615\n",
      "[80]\ttraining's binary_logloss: 0.15276\tvalid_1's binary_logloss: 0.19538\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.155201\tvalid_1's binary_logloss: 0.195264\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235294\tvalid_1's binary_logloss: 0.245148\n",
      "[20]\ttraining's binary_logloss: 0.204694\tvalid_1's binary_logloss: 0.219812\n",
      "[30]\ttraining's binary_logloss: 0.188665\tvalid_1's binary_logloss: 0.210757\n",
      "[40]\ttraining's binary_logloss: 0.177517\tvalid_1's binary_logloss: 0.205895\n",
      "[50]\ttraining's binary_logloss: 0.169799\tvalid_1's binary_logloss: 0.204605\n",
      "[60]\ttraining's binary_logloss: 0.162831\tvalid_1's binary_logloss: 0.203451\n",
      "[70]\ttraining's binary_logloss: 0.157488\tvalid_1's binary_logloss: 0.202971\n",
      "[80]\ttraining's binary_logloss: 0.152434\tvalid_1's binary_logloss: 0.202896\n",
      "[90]\ttraining's binary_logloss: 0.147016\tvalid_1's binary_logloss: 0.201986\n",
      "[100]\ttraining's binary_logloss: 0.142056\tvalid_1's binary_logloss: 0.201588\n",
      "[110]\ttraining's binary_logloss: 0.13779\tvalid_1's binary_logloss: 0.201414\n",
      "[120]\ttraining's binary_logloss: 0.133638\tvalid_1's binary_logloss: 0.201124\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's binary_logloss: 0.134437\tvalid_1's binary_logloss: 0.201031\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234501\tvalid_1's binary_logloss: 0.241434\n",
      "[20]\ttraining's binary_logloss: 0.204494\tvalid_1's binary_logloss: 0.217494\n",
      "[30]\ttraining's binary_logloss: 0.188124\tvalid_1's binary_logloss: 0.20793\n",
      "[40]\ttraining's binary_logloss: 0.177675\tvalid_1's binary_logloss: 0.203841\n",
      "[50]\ttraining's binary_logloss: 0.16934\tvalid_1's binary_logloss: 0.202377\n",
      "[60]\ttraining's binary_logloss: 0.162678\tvalid_1's binary_logloss: 0.201448\n",
      "[70]\ttraining's binary_logloss: 0.156946\tvalid_1's binary_logloss: 0.2014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.151854\tvalid_1's binary_logloss: 0.201075\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.153755\tvalid_1's binary_logloss: 0.200942\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232864\tvalid_1's binary_logloss: 0.24711\n",
      "[20]\ttraining's binary_logloss: 0.201532\tvalid_1's binary_logloss: 0.223347\n",
      "[30]\ttraining's binary_logloss: 0.185889\tvalid_1's binary_logloss: 0.215363\n",
      "[40]\ttraining's binary_logloss: 0.175031\tvalid_1's binary_logloss: 0.211425\n",
      "[50]\ttraining's binary_logloss: 0.166868\tvalid_1's binary_logloss: 0.210204\n",
      "[60]\ttraining's binary_logloss: 0.160522\tvalid_1's binary_logloss: 0.209172\n",
      "[70]\ttraining's binary_logloss: 0.154945\tvalid_1's binary_logloss: 0.208965\n",
      "[80]\ttraining's binary_logloss: 0.149578\tvalid_1's binary_logloss: 0.208926\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.151032\tvalid_1's binary_logloss: 0.208777\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235326\tvalid_1's binary_logloss: 0.243896\n",
      "[20]\ttraining's binary_logloss: 0.205327\tvalid_1's binary_logloss: 0.219168\n",
      "[30]\ttraining's binary_logloss: 0.1881\tvalid_1's binary_logloss: 0.207613\n",
      "[40]\ttraining's binary_logloss: 0.177812\tvalid_1's binary_logloss: 0.203389\n",
      "[50]\ttraining's binary_logloss: 0.170252\tvalid_1's binary_logloss: 0.201798\n",
      "[60]\ttraining's binary_logloss: 0.163581\tvalid_1's binary_logloss: 0.201509\n",
      "[70]\ttraining's binary_logloss: 0.157953\tvalid_1's binary_logloss: 0.200867\n",
      "[80]\ttraining's binary_logloss: 0.152375\tvalid_1's binary_logloss: 0.200827\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.154874\tvalid_1's binary_logloss: 0.200764\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235149\tvalid_1's binary_logloss: 0.245428\n",
      "[20]\ttraining's binary_logloss: 0.202987\tvalid_1's binary_logloss: 0.220308\n",
      "[30]\ttraining's binary_logloss: 0.187088\tvalid_1's binary_logloss: 0.211736\n",
      "[40]\ttraining's binary_logloss: 0.175969\tvalid_1's binary_logloss: 0.207779\n",
      "[50]\ttraining's binary_logloss: 0.168\tvalid_1's binary_logloss: 0.206399\n",
      "[60]\ttraining's binary_logloss: 0.161217\tvalid_1's binary_logloss: 0.206104\n",
      "[70]\ttraining's binary_logloss: 0.155346\tvalid_1's binary_logloss: 0.206107\n",
      "[80]\ttraining's binary_logloss: 0.150199\tvalid_1's binary_logloss: 0.20612\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.154275\tvalid_1's binary_logloss: 0.205732\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235591\tvalid_1's binary_logloss: 0.243792\n",
      "[20]\ttraining's binary_logloss: 0.202884\tvalid_1's binary_logloss: 0.219018\n",
      "[30]\ttraining's binary_logloss: 0.187073\tvalid_1's binary_logloss: 0.210162\n",
      "[40]\ttraining's binary_logloss: 0.176116\tvalid_1's binary_logloss: 0.205055\n",
      "[50]\ttraining's binary_logloss: 0.168045\tvalid_1's binary_logloss: 0.204462\n",
      "[60]\ttraining's binary_logloss: 0.161322\tvalid_1's binary_logloss: 0.203099\n",
      "[70]\ttraining's binary_logloss: 0.155881\tvalid_1's binary_logloss: 0.202258\n",
      "[80]\ttraining's binary_logloss: 0.150977\tvalid_1's binary_logloss: 0.201995\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.151319\tvalid_1's binary_logloss: 0.201918\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23559\tvalid_1's binary_logloss: 0.241691\n",
      "[20]\ttraining's binary_logloss: 0.204489\tvalid_1's binary_logloss: 0.217477\n",
      "[30]\ttraining's binary_logloss: 0.188793\tvalid_1's binary_logloss: 0.208924\n",
      "[40]\ttraining's binary_logloss: 0.178105\tvalid_1's binary_logloss: 0.204437\n",
      "[50]\ttraining's binary_logloss: 0.169703\tvalid_1's binary_logloss: 0.20204\n",
      "[60]\ttraining's binary_logloss: 0.163296\tvalid_1's binary_logloss: 0.201516\n",
      "[70]\ttraining's binary_logloss: 0.157245\tvalid_1's binary_logloss: 0.200544\n",
      "[80]\ttraining's binary_logloss: 0.152043\tvalid_1's binary_logloss: 0.200604\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.157245\tvalid_1's binary_logloss: 0.200544\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235795\tvalid_1's binary_logloss: 0.244387\n",
      "[20]\ttraining's binary_logloss: 0.205611\tvalid_1's binary_logloss: 0.219045\n",
      "[30]\ttraining's binary_logloss: 0.190161\tvalid_1's binary_logloss: 0.209457\n",
      "[40]\ttraining's binary_logloss: 0.179063\tvalid_1's binary_logloss: 0.204847\n",
      "[50]\ttraining's binary_logloss: 0.171043\tvalid_1's binary_logloss: 0.203121\n",
      "[60]\ttraining's binary_logloss: 0.164483\tvalid_1's binary_logloss: 0.20241\n",
      "[70]\ttraining's binary_logloss: 0.15864\tvalid_1's binary_logloss: 0.201703\n",
      "[80]\ttraining's binary_logloss: 0.153427\tvalid_1's binary_logloss: 0.201426\n",
      "[90]\ttraining's binary_logloss: 0.148778\tvalid_1's binary_logloss: 0.201498\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.152475\tvalid_1's binary_logloss: 0.20135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235335\tvalid_1's binary_logloss: 0.243823\n",
      "[20]\ttraining's binary_logloss: 0.203243\tvalid_1's binary_logloss: 0.219584\n",
      "[30]\ttraining's binary_logloss: 0.186701\tvalid_1's binary_logloss: 0.208725\n",
      "[40]\ttraining's binary_logloss: 0.176395\tvalid_1's binary_logloss: 0.204447\n",
      "[50]\ttraining's binary_logloss: 0.168263\tvalid_1's binary_logloss: 0.203232\n",
      "[60]\ttraining's binary_logloss: 0.161529\tvalid_1's binary_logloss: 0.202217\n",
      "[70]\ttraining's binary_logloss: 0.156281\tvalid_1's binary_logloss: 0.202345\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.157184\tvalid_1's binary_logloss: 0.202133\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236462\tvalid_1's binary_logloss: 0.241023\n",
      "[20]\ttraining's binary_logloss: 0.204457\tvalid_1's binary_logloss: 0.216136\n",
      "[30]\ttraining's binary_logloss: 0.189472\tvalid_1's binary_logloss: 0.207946\n",
      "[40]\ttraining's binary_logloss: 0.178262\tvalid_1's binary_logloss: 0.202896\n",
      "[50]\ttraining's binary_logloss: 0.169909\tvalid_1's binary_logloss: 0.200686\n",
      "[60]\ttraining's binary_logloss: 0.162898\tvalid_1's binary_logloss: 0.199599\n",
      "[70]\ttraining's binary_logloss: 0.157455\tvalid_1's binary_logloss: 0.199107\n",
      "[80]\ttraining's binary_logloss: 0.152075\tvalid_1's binary_logloss: 0.199026\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.153053\tvalid_1's binary_logloss: 0.19874\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23457\tvalid_1's binary_logloss: 0.241904\n",
      "[20]\ttraining's binary_logloss: 0.204296\tvalid_1's binary_logloss: 0.219036\n",
      "[30]\ttraining's binary_logloss: 0.188902\tvalid_1's binary_logloss: 0.210597\n",
      "[40]\ttraining's binary_logloss: 0.178866\tvalid_1's binary_logloss: 0.207344\n",
      "[50]\ttraining's binary_logloss: 0.171209\tvalid_1's binary_logloss: 0.205624\n",
      "[60]\ttraining's binary_logloss: 0.164101\tvalid_1's binary_logloss: 0.204444\n",
      "[70]\ttraining's binary_logloss: 0.158793\tvalid_1's binary_logloss: 0.203664\n",
      "[80]\ttraining's binary_logloss: 0.15358\tvalid_1's binary_logloss: 0.203877\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.158793\tvalid_1's binary_logloss: 0.203664\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237142\tvalid_1's binary_logloss: 0.242958\n",
      "[20]\ttraining's binary_logloss: 0.20493\tvalid_1's binary_logloss: 0.216224\n",
      "[30]\ttraining's binary_logloss: 0.189699\tvalid_1's binary_logloss: 0.20709\n",
      "[40]\ttraining's binary_logloss: 0.178907\tvalid_1's binary_logloss: 0.203009\n",
      "[50]\ttraining's binary_logloss: 0.170537\tvalid_1's binary_logloss: 0.201783\n",
      "[60]\ttraining's binary_logloss: 0.163896\tvalid_1's binary_logloss: 0.200548\n",
      "[70]\ttraining's binary_logloss: 0.158308\tvalid_1's binary_logloss: 0.200683\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.163896\tvalid_1's binary_logloss: 0.200548\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234524\tvalid_1's binary_logloss: 0.245198\n",
      "[20]\ttraining's binary_logloss: 0.203325\tvalid_1's binary_logloss: 0.220256\n",
      "[30]\ttraining's binary_logloss: 0.187213\tvalid_1's binary_logloss: 0.210623\n",
      "[40]\ttraining's binary_logloss: 0.177205\tvalid_1's binary_logloss: 0.207264\n",
      "[50]\ttraining's binary_logloss: 0.16892\tvalid_1's binary_logloss: 0.205808\n",
      "[60]\ttraining's binary_logloss: 0.16193\tvalid_1's binary_logloss: 0.205124\n",
      "[70]\ttraining's binary_logloss: 0.156088\tvalid_1's binary_logloss: 0.204078\n",
      "[80]\ttraining's binary_logloss: 0.150568\tvalid_1's binary_logloss: 0.203636\n",
      "[90]\ttraining's binary_logloss: 0.145896\tvalid_1's binary_logloss: 0.203309\n",
      "[100]\ttraining's binary_logloss: 0.141691\tvalid_1's binary_logloss: 0.203692\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.145553\tvalid_1's binary_logloss: 0.203308\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234197\tvalid_1's binary_logloss: 0.24583\n",
      "[20]\ttraining's binary_logloss: 0.203182\tvalid_1's binary_logloss: 0.22204\n",
      "[30]\ttraining's binary_logloss: 0.18676\tvalid_1's binary_logloss: 0.212351\n",
      "[40]\ttraining's binary_logloss: 0.17588\tvalid_1's binary_logloss: 0.207458\n",
      "[50]\ttraining's binary_logloss: 0.167887\tvalid_1's binary_logloss: 0.206021\n",
      "[60]\ttraining's binary_logloss: 0.161096\tvalid_1's binary_logloss: 0.205901\n",
      "[70]\ttraining's binary_logloss: 0.155279\tvalid_1's binary_logloss: 0.205477\n",
      "[80]\ttraining's binary_logloss: 0.149912\tvalid_1's binary_logloss: 0.205113\n",
      "[90]\ttraining's binary_logloss: 0.145283\tvalid_1's binary_logloss: 0.205106\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.14778\tvalid_1's binary_logloss: 0.204827\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233871\tvalid_1's binary_logloss: 0.245613\n",
      "[20]\ttraining's binary_logloss: 0.203646\tvalid_1's binary_logloss: 0.22237\n",
      "[30]\ttraining's binary_logloss: 0.187271\tvalid_1's binary_logloss: 0.212715\n",
      "[40]\ttraining's binary_logloss: 0.176225\tvalid_1's binary_logloss: 0.208709\n",
      "[50]\ttraining's binary_logloss: 0.168401\tvalid_1's binary_logloss: 0.207672\n",
      "[60]\ttraining's binary_logloss: 0.161449\tvalid_1's binary_logloss: 0.206248\n",
      "[70]\ttraining's binary_logloss: 0.155957\tvalid_1's binary_logloss: 0.205862\n",
      "[80]\ttraining's binary_logloss: 0.15057\tvalid_1's binary_logloss: 0.205349\n",
      "[90]\ttraining's binary_logloss: 0.14612\tvalid_1's binary_logloss: 0.205166\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.148943\tvalid_1's binary_logloss: 0.205161\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232662\tvalid_1's binary_logloss: 0.247441\n",
      "[20]\ttraining's binary_logloss: 0.202022\tvalid_1's binary_logloss: 0.223911\n",
      "[30]\ttraining's binary_logloss: 0.185763\tvalid_1's binary_logloss: 0.215126\n",
      "[40]\ttraining's binary_logloss: 0.174885\tvalid_1's binary_logloss: 0.211359\n",
      "[50]\ttraining's binary_logloss: 0.166851\tvalid_1's binary_logloss: 0.210565\n",
      "[60]\ttraining's binary_logloss: 0.160226\tvalid_1's binary_logloss: 0.209766\n",
      "[70]\ttraining's binary_logloss: 0.154202\tvalid_1's binary_logloss: 0.209527\n",
      "[80]\ttraining's binary_logloss: 0.148985\tvalid_1's binary_logloss: 0.209581\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.151721\tvalid_1's binary_logloss: 0.209287\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238186\tvalid_1's binary_logloss: 0.241115\n",
      "[20]\ttraining's binary_logloss: 0.20755\tvalid_1's binary_logloss: 0.214655\n",
      "[30]\ttraining's binary_logloss: 0.190198\tvalid_1's binary_logloss: 0.201527\n",
      "[40]\ttraining's binary_logloss: 0.18035\tvalid_1's binary_logloss: 0.197705\n",
      "[50]\ttraining's binary_logloss: 0.172235\tvalid_1's binary_logloss: 0.19575\n",
      "[60]\ttraining's binary_logloss: 0.165331\tvalid_1's binary_logloss: 0.194495\n",
      "[70]\ttraining's binary_logloss: 0.15995\tvalid_1's binary_logloss: 0.194083\n",
      "[80]\ttraining's binary_logloss: 0.154886\tvalid_1's binary_logloss: 0.193716\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.155452\tvalid_1's binary_logloss: 0.193577\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236733\tvalid_1's binary_logloss: 0.240596\n",
      "[20]\ttraining's binary_logloss: 0.204898\tvalid_1's binary_logloss: 0.216137\n",
      "[30]\ttraining's binary_logloss: 0.187684\tvalid_1's binary_logloss: 0.205955\n",
      "[40]\ttraining's binary_logloss: 0.177083\tvalid_1's binary_logloss: 0.202102\n",
      "[50]\ttraining's binary_logloss: 0.169423\tvalid_1's binary_logloss: 0.201104\n",
      "[60]\ttraining's binary_logloss: 0.162866\tvalid_1's binary_logloss: 0.200804\n",
      "[70]\ttraining's binary_logloss: 0.157474\tvalid_1's binary_logloss: 0.200576\n",
      "[80]\ttraining's binary_logloss: 0.152604\tvalid_1's binary_logloss: 0.200502\n",
      "[90]\ttraining's binary_logloss: 0.147962\tvalid_1's binary_logloss: 0.200479\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.15084\tvalid_1's binary_logloss: 0.200305\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232978\tvalid_1's binary_logloss: 0.247095\n",
      "[20]\ttraining's binary_logloss: 0.201541\tvalid_1's binary_logloss: 0.223638\n",
      "[30]\ttraining's binary_logloss: 0.185247\tvalid_1's binary_logloss: 0.21402\n",
      "[40]\ttraining's binary_logloss: 0.174975\tvalid_1's binary_logloss: 0.210376\n",
      "[50]\ttraining's binary_logloss: 0.167089\tvalid_1's binary_logloss: 0.209203\n",
      "[60]\ttraining's binary_logloss: 0.160628\tvalid_1's binary_logloss: 0.208482\n",
      "[70]\ttraining's binary_logloss: 0.154809\tvalid_1's binary_logloss: 0.208421\n",
      "[80]\ttraining's binary_logloss: 0.149733\tvalid_1's binary_logloss: 0.208362\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.152244\tvalid_1's binary_logloss: 0.208112\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234136\tvalid_1's binary_logloss: 0.243159\n",
      "[20]\ttraining's binary_logloss: 0.202612\tvalid_1's binary_logloss: 0.219246\n",
      "[30]\ttraining's binary_logloss: 0.187176\tvalid_1's binary_logloss: 0.210504\n",
      "[40]\ttraining's binary_logloss: 0.177038\tvalid_1's binary_logloss: 0.20658\n",
      "[50]\ttraining's binary_logloss: 0.169013\tvalid_1's binary_logloss: 0.205331\n",
      "[60]\ttraining's binary_logloss: 0.162012\tvalid_1's binary_logloss: 0.204904\n",
      "[70]\ttraining's binary_logloss: 0.15589\tvalid_1's binary_logloss: 0.204698\n",
      "[80]\ttraining's binary_logloss: 0.150377\tvalid_1's binary_logloss: 0.204522\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.152898\tvalid_1's binary_logloss: 0.204423\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236753\tvalid_1's binary_logloss: 0.240661\n",
      "[20]\ttraining's binary_logloss: 0.20669\tvalid_1's binary_logloss: 0.215441\n",
      "[30]\ttraining's binary_logloss: 0.190243\tvalid_1's binary_logloss: 0.204631\n",
      "[40]\ttraining's binary_logloss: 0.178891\tvalid_1's binary_logloss: 0.198911\n",
      "[50]\ttraining's binary_logloss: 0.17099\tvalid_1's binary_logloss: 0.197018\n",
      "[60]\ttraining's binary_logloss: 0.16459\tvalid_1's binary_logloss: 0.195864\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.165154\tvalid_1's binary_logloss: 0.195854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237423\tvalid_1's binary_logloss: 0.240373\n",
      "[20]\ttraining's binary_logloss: 0.205244\tvalid_1's binary_logloss: 0.212294\n",
      "[30]\ttraining's binary_logloss: 0.189553\tvalid_1's binary_logloss: 0.201575\n",
      "[40]\ttraining's binary_logloss: 0.179791\tvalid_1's binary_logloss: 0.197418\n",
      "[50]\ttraining's binary_logloss: 0.172097\tvalid_1's binary_logloss: 0.195698\n",
      "[60]\ttraining's binary_logloss: 0.165835\tvalid_1's binary_logloss: 0.195077\n",
      "[70]\ttraining's binary_logloss: 0.159943\tvalid_1's binary_logloss: 0.194527\n",
      "[80]\ttraining's binary_logloss: 0.154591\tvalid_1's binary_logloss: 0.193977\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.155544\tvalid_1's binary_logloss: 0.193891\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236024\tvalid_1's binary_logloss: 0.245267\n",
      "[20]\ttraining's binary_logloss: 0.205819\tvalid_1's binary_logloss: 0.221023\n",
      "[30]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.21148\n",
      "[40]\ttraining's binary_logloss: 0.180228\tvalid_1's binary_logloss: 0.207393\n",
      "[50]\ttraining's binary_logloss: 0.171806\tvalid_1's binary_logloss: 0.205502\n",
      "[60]\ttraining's binary_logloss: 0.164787\tvalid_1's binary_logloss: 0.203456\n",
      "[70]\ttraining's binary_logloss: 0.15855\tvalid_1's binary_logloss: 0.201789\n",
      "[80]\ttraining's binary_logloss: 0.152963\tvalid_1's binary_logloss: 0.201331\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.156646\tvalid_1's binary_logloss: 0.201136\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235135\tvalid_1's binary_logloss: 0.242591\n",
      "[20]\ttraining's binary_logloss: 0.204131\tvalid_1's binary_logloss: 0.218203\n",
      "[30]\ttraining's binary_logloss: 0.187175\tvalid_1's binary_logloss: 0.206646\n",
      "[40]\ttraining's binary_logloss: 0.176606\tvalid_1's binary_logloss: 0.203709\n",
      "[50]\ttraining's binary_logloss: 0.168097\tvalid_1's binary_logloss: 0.202274\n",
      "[60]\ttraining's binary_logloss: 0.161083\tvalid_1's binary_logloss: 0.201374\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.161802\tvalid_1's binary_logloss: 0.201191\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234595\tvalid_1's binary_logloss: 0.243364\n",
      "[20]\ttraining's binary_logloss: 0.20486\tvalid_1's binary_logloss: 0.221003\n",
      "[30]\ttraining's binary_logloss: 0.188215\tvalid_1's binary_logloss: 0.210669\n",
      "[40]\ttraining's binary_logloss: 0.177392\tvalid_1's binary_logloss: 0.205628\n",
      "[50]\ttraining's binary_logloss: 0.169421\tvalid_1's binary_logloss: 0.203551\n",
      "[60]\ttraining's binary_logloss: 0.162951\tvalid_1's binary_logloss: 0.203062\n",
      "[70]\ttraining's binary_logloss: 0.157503\tvalid_1's binary_logloss: 0.202316\n",
      "[80]\ttraining's binary_logloss: 0.152447\tvalid_1's binary_logloss: 0.202374\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.154281\tvalid_1's binary_logloss: 0.202178\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236111\tvalid_1's binary_logloss: 0.246157\n",
      "[20]\ttraining's binary_logloss: 0.203998\tvalid_1's binary_logloss: 0.219707\n",
      "[30]\ttraining's binary_logloss: 0.187687\tvalid_1's binary_logloss: 0.20877\n",
      "[40]\ttraining's binary_logloss: 0.177107\tvalid_1's binary_logloss: 0.204664\n",
      "[50]\ttraining's binary_logloss: 0.168895\tvalid_1's binary_logloss: 0.203269\n",
      "[60]\ttraining's binary_logloss: 0.162554\tvalid_1's binary_logloss: 0.202963\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.164959\tvalid_1's binary_logloss: 0.202755\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235814\tvalid_1's binary_logloss: 0.243569\n",
      "[20]\ttraining's binary_logloss: 0.205447\tvalid_1's binary_logloss: 0.220816\n",
      "[30]\ttraining's binary_logloss: 0.187908\tvalid_1's binary_logloss: 0.209829\n",
      "[40]\ttraining's binary_logloss: 0.177248\tvalid_1's binary_logloss: 0.20557\n",
      "[50]\ttraining's binary_logloss: 0.16962\tvalid_1's binary_logloss: 0.203532\n",
      "[60]\ttraining's binary_logloss: 0.162478\tvalid_1's binary_logloss: 0.203188\n",
      "[70]\ttraining's binary_logloss: 0.156539\tvalid_1's binary_logloss: 0.202973\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.159359\tvalid_1's binary_logloss: 0.20284\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234916\tvalid_1's binary_logloss: 0.242824\n",
      "[20]\ttraining's binary_logloss: 0.203605\tvalid_1's binary_logloss: 0.219742\n",
      "[30]\ttraining's binary_logloss: 0.187129\tvalid_1's binary_logloss: 0.210698\n",
      "[40]\ttraining's binary_logloss: 0.177039\tvalid_1's binary_logloss: 0.20702\n",
      "[50]\ttraining's binary_logloss: 0.16869\tvalid_1's binary_logloss: 0.204758\n",
      "[60]\ttraining's binary_logloss: 0.161786\tvalid_1's binary_logloss: 0.204053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\ttraining's binary_logloss: 0.156248\tvalid_1's binary_logloss: 0.203745\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.160671\tvalid_1's binary_logloss: 0.203614\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235819\tvalid_1's binary_logloss: 0.243072\n",
      "[20]\ttraining's binary_logloss: 0.205517\tvalid_1's binary_logloss: 0.218722\n",
      "[30]\ttraining's binary_logloss: 0.18928\tvalid_1's binary_logloss: 0.207847\n",
      "[40]\ttraining's binary_logloss: 0.178125\tvalid_1's binary_logloss: 0.203801\n",
      "[50]\ttraining's binary_logloss: 0.169859\tvalid_1's binary_logloss: 0.201954\n",
      "[60]\ttraining's binary_logloss: 0.163127\tvalid_1's binary_logloss: 0.201184\n",
      "[70]\ttraining's binary_logloss: 0.157622\tvalid_1's binary_logloss: 0.201042\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.159259\tvalid_1's binary_logloss: 0.200632\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235996\tvalid_1's binary_logloss: 0.2473\n",
      "[20]\ttraining's binary_logloss: 0.202443\tvalid_1's binary_logloss: 0.219943\n",
      "[30]\ttraining's binary_logloss: 0.18573\tvalid_1's binary_logloss: 0.208413\n",
      "[40]\ttraining's binary_logloss: 0.175727\tvalid_1's binary_logloss: 0.204863\n",
      "[50]\ttraining's binary_logloss: 0.168621\tvalid_1's binary_logloss: 0.203706\n",
      "[60]\ttraining's binary_logloss: 0.162257\tvalid_1's binary_logloss: 0.202534\n",
      "[70]\ttraining's binary_logloss: 0.156706\tvalid_1's binary_logloss: 0.202563\n",
      "[80]\ttraining's binary_logloss: 0.151411\tvalid_1's binary_logloss: 0.201757\n",
      "[90]\ttraining's binary_logloss: 0.146184\tvalid_1's binary_logloss: 0.201554\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.147171\tvalid_1's binary_logloss: 0.201337\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232551\tvalid_1's binary_logloss: 0.244328\n",
      "[20]\ttraining's binary_logloss: 0.201526\tvalid_1's binary_logloss: 0.221154\n",
      "[30]\ttraining's binary_logloss: 0.185473\tvalid_1's binary_logloss: 0.211155\n",
      "[40]\ttraining's binary_logloss: 0.175155\tvalid_1's binary_logloss: 0.20668\n",
      "[50]\ttraining's binary_logloss: 0.167528\tvalid_1's binary_logloss: 0.205804\n",
      "[60]\ttraining's binary_logloss: 0.16102\tvalid_1's binary_logloss: 0.205262\n",
      "[70]\ttraining's binary_logloss: 0.155042\tvalid_1's binary_logloss: 0.204888\n",
      "[80]\ttraining's binary_logloss: 0.149935\tvalid_1's binary_logloss: 0.204413\n",
      "[90]\ttraining's binary_logloss: 0.145402\tvalid_1's binary_logloss: 0.204481\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's binary_logloss: 0.146817\tvalid_1's binary_logloss: 0.204293\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233255\tvalid_1's binary_logloss: 0.243542\n",
      "[20]\ttraining's binary_logloss: 0.202997\tvalid_1's binary_logloss: 0.220755\n",
      "[30]\ttraining's binary_logloss: 0.186388\tvalid_1's binary_logloss: 0.21057\n",
      "[40]\ttraining's binary_logloss: 0.17614\tvalid_1's binary_logloss: 0.206784\n",
      "[50]\ttraining's binary_logloss: 0.16851\tvalid_1's binary_logloss: 0.205171\n",
      "[60]\ttraining's binary_logloss: 0.162091\tvalid_1's binary_logloss: 0.20438\n",
      "[70]\ttraining's binary_logloss: 0.156461\tvalid_1's binary_logloss: 0.204275\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.160393\tvalid_1's binary_logloss: 0.204211\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237016\tvalid_1's binary_logloss: 0.240111\n",
      "[20]\ttraining's binary_logloss: 0.206918\tvalid_1's binary_logloss: 0.214419\n",
      "[30]\ttraining's binary_logloss: 0.189921\tvalid_1's binary_logloss: 0.201854\n",
      "[40]\ttraining's binary_logloss: 0.179611\tvalid_1's binary_logloss: 0.198341\n",
      "[50]\ttraining's binary_logloss: 0.172173\tvalid_1's binary_logloss: 0.196747\n",
      "[60]\ttraining's binary_logloss: 0.165391\tvalid_1's binary_logloss: 0.195422\n",
      "[70]\ttraining's binary_logloss: 0.159659\tvalid_1's binary_logloss: 0.195011\n",
      "[80]\ttraining's binary_logloss: 0.15482\tvalid_1's binary_logloss: 0.19454\n",
      "[90]\ttraining's binary_logloss: 0.150052\tvalid_1's binary_logloss: 0.195047\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's binary_logloss: 0.153242\tvalid_1's binary_logloss: 0.194492\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237317\tvalid_1's binary_logloss: 0.242629\n",
      "[20]\ttraining's binary_logloss: 0.205847\tvalid_1's binary_logloss: 0.217199\n",
      "[30]\ttraining's binary_logloss: 0.189203\tvalid_1's binary_logloss: 0.206872\n",
      "[40]\ttraining's binary_logloss: 0.17971\tvalid_1's binary_logloss: 0.203114\n",
      "[50]\ttraining's binary_logloss: 0.171973\tvalid_1's binary_logloss: 0.200794\n",
      "[60]\ttraining's binary_logloss: 0.165296\tvalid_1's binary_logloss: 0.200149\n",
      "[70]\ttraining's binary_logloss: 0.159447\tvalid_1's binary_logloss: 0.199886\n",
      "[80]\ttraining's binary_logloss: 0.154032\tvalid_1's binary_logloss: 0.199224\n",
      "[90]\ttraining's binary_logloss: 0.149066\tvalid_1's binary_logloss: 0.199364\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.1536\tvalid_1's binary_logloss: 0.19917\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233237\tvalid_1's binary_logloss: 0.245852\n",
      "[20]\ttraining's binary_logloss: 0.202406\tvalid_1's binary_logloss: 0.221329\n",
      "[30]\ttraining's binary_logloss: 0.186222\tvalid_1's binary_logloss: 0.211349\n",
      "[40]\ttraining's binary_logloss: 0.175612\tvalid_1's binary_logloss: 0.20671\n",
      "[50]\ttraining's binary_logloss: 0.16737\tvalid_1's binary_logloss: 0.204714\n",
      "[60]\ttraining's binary_logloss: 0.160657\tvalid_1's binary_logloss: 0.204131\n",
      "[70]\ttraining's binary_logloss: 0.154814\tvalid_1's binary_logloss: 0.204546\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.159493\tvalid_1's binary_logloss: 0.204042\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235341\tvalid_1's binary_logloss: 0.242005\n",
      "[20]\ttraining's binary_logloss: 0.204618\tvalid_1's binary_logloss: 0.217388\n",
      "[30]\ttraining's binary_logloss: 0.187996\tvalid_1's binary_logloss: 0.206852\n",
      "[40]\ttraining's binary_logloss: 0.1776\tvalid_1's binary_logloss: 0.202617\n",
      "[50]\ttraining's binary_logloss: 0.169761\tvalid_1's binary_logloss: 0.200644\n",
      "[60]\ttraining's binary_logloss: 0.163669\tvalid_1's binary_logloss: 0.200266\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.1661\tvalid_1's binary_logloss: 0.199941\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235189\tvalid_1's binary_logloss: 0.245616\n",
      "[20]\ttraining's binary_logloss: 0.203789\tvalid_1's binary_logloss: 0.221286\n",
      "[30]\ttraining's binary_logloss: 0.186772\tvalid_1's binary_logloss: 0.210058\n",
      "[40]\ttraining's binary_logloss: 0.17648\tvalid_1's binary_logloss: 0.206404\n",
      "[50]\ttraining's binary_logloss: 0.16924\tvalid_1's binary_logloss: 0.205687\n",
      "[60]\ttraining's binary_logloss: 0.163042\tvalid_1's binary_logloss: 0.205726\n",
      "[70]\ttraining's binary_logloss: 0.157664\tvalid_1's binary_logloss: 0.205543\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.158975\tvalid_1's binary_logloss: 0.205379\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233962\tvalid_1's binary_logloss: 0.247513\n",
      "[20]\ttraining's binary_logloss: 0.202867\tvalid_1's binary_logloss: 0.2228\n",
      "[30]\ttraining's binary_logloss: 0.186284\tvalid_1's binary_logloss: 0.212004\n",
      "[40]\ttraining's binary_logloss: 0.175685\tvalid_1's binary_logloss: 0.208672\n",
      "[50]\ttraining's binary_logloss: 0.167943\tvalid_1's binary_logloss: 0.206883\n",
      "[60]\ttraining's binary_logloss: 0.161613\tvalid_1's binary_logloss: 0.206707\n",
      "[70]\ttraining's binary_logloss: 0.155586\tvalid_1's binary_logloss: 0.207241\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.160394\tvalid_1's binary_logloss: 0.206491\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233095\tvalid_1's binary_logloss: 0.247952\n",
      "[20]\ttraining's binary_logloss: 0.202624\tvalid_1's binary_logloss: 0.224859\n",
      "[30]\ttraining's binary_logloss: 0.18556\tvalid_1's binary_logloss: 0.214713\n",
      "[40]\ttraining's binary_logloss: 0.174945\tvalid_1's binary_logloss: 0.210742\n",
      "[50]\ttraining's binary_logloss: 0.166777\tvalid_1's binary_logloss: 0.209626\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.167457\tvalid_1's binary_logloss: 0.209431\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237376\tvalid_1's binary_logloss: 0.241981\n",
      "[20]\ttraining's binary_logloss: 0.206449\tvalid_1's binary_logloss: 0.216132\n",
      "[30]\ttraining's binary_logloss: 0.190022\tvalid_1's binary_logloss: 0.204371\n",
      "[40]\ttraining's binary_logloss: 0.179549\tvalid_1's binary_logloss: 0.199744\n",
      "[50]\ttraining's binary_logloss: 0.171475\tvalid_1's binary_logloss: 0.197941\n",
      "[60]\ttraining's binary_logloss: 0.164329\tvalid_1's binary_logloss: 0.195962\n",
      "[70]\ttraining's binary_logloss: 0.158553\tvalid_1's binary_logloss: 0.195139\n",
      "[80]\ttraining's binary_logloss: 0.153114\tvalid_1's binary_logloss: 0.194714\n",
      "[90]\ttraining's binary_logloss: 0.148499\tvalid_1's binary_logloss: 0.194746\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.152656\tvalid_1's binary_logloss: 0.194654\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234851\tvalid_1's binary_logloss: 0.242918\n",
      "[20]\ttraining's binary_logloss: 0.205228\tvalid_1's binary_logloss: 0.217814\n",
      "[30]\ttraining's binary_logloss: 0.18931\tvalid_1's binary_logloss: 0.207928\n",
      "[40]\ttraining's binary_logloss: 0.177937\tvalid_1's binary_logloss: 0.202574\n",
      "[50]\ttraining's binary_logloss: 0.170078\tvalid_1's binary_logloss: 0.20069\n",
      "[60]\ttraining's binary_logloss: 0.163534\tvalid_1's binary_logloss: 0.200041\n",
      "[70]\ttraining's binary_logloss: 0.157783\tvalid_1's binary_logloss: 0.199834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.151993\tvalid_1's binary_logloss: 0.199221\n",
      "[90]\ttraining's binary_logloss: 0.147114\tvalid_1's binary_logloss: 0.198605\n",
      "[100]\ttraining's binary_logloss: 0.142454\tvalid_1's binary_logloss: 0.199023\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.146513\tvalid_1's binary_logloss: 0.198546\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233789\tvalid_1's binary_logloss: 0.247904\n",
      "[20]\ttraining's binary_logloss: 0.201269\tvalid_1's binary_logloss: 0.223429\n",
      "[30]\ttraining's binary_logloss: 0.184749\tvalid_1's binary_logloss: 0.213977\n",
      "[40]\ttraining's binary_logloss: 0.173846\tvalid_1's binary_logloss: 0.211066\n",
      "[50]\ttraining's binary_logloss: 0.165682\tvalid_1's binary_logloss: 0.209996\n",
      "[60]\ttraining's binary_logloss: 0.159347\tvalid_1's binary_logloss: 0.209706\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.162275\tvalid_1's binary_logloss: 0.209568\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234848\tvalid_1's binary_logloss: 0.244429\n",
      "[20]\ttraining's binary_logloss: 0.204222\tvalid_1's binary_logloss: 0.222095\n",
      "[30]\ttraining's binary_logloss: 0.189049\tvalid_1's binary_logloss: 0.213992\n",
      "[40]\ttraining's binary_logloss: 0.177222\tvalid_1's binary_logloss: 0.208192\n",
      "[50]\ttraining's binary_logloss: 0.169033\tvalid_1's binary_logloss: 0.206085\n",
      "[60]\ttraining's binary_logloss: 0.161487\tvalid_1's binary_logloss: 0.204534\n",
      "[70]\ttraining's binary_logloss: 0.155345\tvalid_1's binary_logloss: 0.204431\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.158196\tvalid_1's binary_logloss: 0.204376\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235237\tvalid_1's binary_logloss: 0.245537\n",
      "[20]\ttraining's binary_logloss: 0.20461\tvalid_1's binary_logloss: 0.221497\n",
      "[30]\ttraining's binary_logloss: 0.187155\tvalid_1's binary_logloss: 0.210253\n",
      "[40]\ttraining's binary_logloss: 0.176532\tvalid_1's binary_logloss: 0.206132\n",
      "[50]\ttraining's binary_logloss: 0.168676\tvalid_1's binary_logloss: 0.205231\n",
      "[60]\ttraining's binary_logloss: 0.162233\tvalid_1's binary_logloss: 0.204402\n",
      "[70]\ttraining's binary_logloss: 0.15653\tvalid_1's binary_logloss: 0.203737\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.158209\tvalid_1's binary_logloss: 0.203553\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235688\tvalid_1's binary_logloss: 0.245569\n",
      "[20]\ttraining's binary_logloss: 0.20425\tvalid_1's binary_logloss: 0.21929\n",
      "[30]\ttraining's binary_logloss: 0.18827\tvalid_1's binary_logloss: 0.20929\n",
      "[40]\ttraining's binary_logloss: 0.177512\tvalid_1's binary_logloss: 0.205289\n",
      "[50]\ttraining's binary_logloss: 0.169555\tvalid_1's binary_logloss: 0.203759\n",
      "[60]\ttraining's binary_logloss: 0.163073\tvalid_1's binary_logloss: 0.203095\n",
      "[70]\ttraining's binary_logloss: 0.156572\tvalid_1's binary_logloss: 0.202302\n",
      "[80]\ttraining's binary_logloss: 0.151449\tvalid_1's binary_logloss: 0.201707\n",
      "[90]\ttraining's binary_logloss: 0.146601\tvalid_1's binary_logloss: 0.201537\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's binary_logloss: 0.149765\tvalid_1's binary_logloss: 0.201437\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235522\tvalid_1's binary_logloss: 0.244898\n",
      "[20]\ttraining's binary_logloss: 0.204269\tvalid_1's binary_logloss: 0.220179\n",
      "[30]\ttraining's binary_logloss: 0.188653\tvalid_1's binary_logloss: 0.210681\n",
      "[40]\ttraining's binary_logloss: 0.177616\tvalid_1's binary_logloss: 0.20569\n",
      "[50]\ttraining's binary_logloss: 0.169478\tvalid_1's binary_logloss: 0.20404\n",
      "[60]\ttraining's binary_logloss: 0.162008\tvalid_1's binary_logloss: 0.202693\n",
      "[70]\ttraining's binary_logloss: 0.156006\tvalid_1's binary_logloss: 0.202399\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's binary_logloss: 0.158345\tvalid_1's binary_logloss: 0.202338\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235608\tvalid_1's binary_logloss: 0.246365\n",
      "[20]\ttraining's binary_logloss: 0.203597\tvalid_1's binary_logloss: 0.220012\n",
      "[30]\ttraining's binary_logloss: 0.187368\tvalid_1's binary_logloss: 0.21079\n",
      "[40]\ttraining's binary_logloss: 0.176116\tvalid_1's binary_logloss: 0.206423\n",
      "[50]\ttraining's binary_logloss: 0.168019\tvalid_1's binary_logloss: 0.204655\n",
      "[60]\ttraining's binary_logloss: 0.161337\tvalid_1's binary_logloss: 0.204244\n",
      "[70]\ttraining's binary_logloss: 0.155343\tvalid_1's binary_logloss: 0.203579\n",
      "[80]\ttraining's binary_logloss: 0.150487\tvalid_1's binary_logloss: 0.203271\n",
      "[90]\ttraining's binary_logloss: 0.145636\tvalid_1's binary_logloss: 0.202777\n",
      "[100]\ttraining's binary_logloss: 0.141264\tvalid_1's binary_logloss: 0.202543\n",
      "[110]\ttraining's binary_logloss: 0.1369\tvalid_1's binary_logloss: 0.202571\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's binary_logloss: 0.140715\tvalid_1's binary_logloss: 0.202265\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's binary_logloss: 0.233709\tvalid_1's binary_logloss: 0.244638\n",
      "[20]\ttraining's binary_logloss: 0.202672\tvalid_1's binary_logloss: 0.22178\n",
      "[30]\ttraining's binary_logloss: 0.185985\tvalid_1's binary_logloss: 0.211468\n",
      "[40]\ttraining's binary_logloss: 0.175924\tvalid_1's binary_logloss: 0.207957\n",
      "[50]\ttraining's binary_logloss: 0.168368\tvalid_1's binary_logloss: 0.206394\n",
      "[60]\ttraining's binary_logloss: 0.161962\tvalid_1's binary_logloss: 0.205785\n",
      "[70]\ttraining's binary_logloss: 0.156189\tvalid_1's binary_logloss: 0.205518\n",
      "[80]\ttraining's binary_logloss: 0.151092\tvalid_1's binary_logloss: 0.205254\n",
      "[90]\ttraining's binary_logloss: 0.146057\tvalid_1's binary_logloss: 0.205133\n",
      "[100]\ttraining's binary_logloss: 0.1415\tvalid_1's binary_logloss: 0.205438\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.145073\tvalid_1's binary_logloss: 0.204925\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236939\tvalid_1's binary_logloss: 0.24595\n",
      "[20]\ttraining's binary_logloss: 0.206554\tvalid_1's binary_logloss: 0.220105\n",
      "[30]\ttraining's binary_logloss: 0.190565\tvalid_1's binary_logloss: 0.209766\n",
      "[40]\ttraining's binary_logloss: 0.179498\tvalid_1's binary_logloss: 0.205567\n",
      "[50]\ttraining's binary_logloss: 0.170405\tvalid_1's binary_logloss: 0.203092\n",
      "[60]\ttraining's binary_logloss: 0.163204\tvalid_1's binary_logloss: 0.202269\n",
      "[70]\ttraining's binary_logloss: 0.157273\tvalid_1's binary_logloss: 0.201973\n",
      "[80]\ttraining's binary_logloss: 0.152235\tvalid_1's binary_logloss: 0.202141\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.156779\tvalid_1's binary_logloss: 0.201782\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235426\tvalid_1's binary_logloss: 0.241725\n",
      "[20]\ttraining's binary_logloss: 0.203579\tvalid_1's binary_logloss: 0.215672\n",
      "[30]\ttraining's binary_logloss: 0.188904\tvalid_1's binary_logloss: 0.206649\n",
      "[40]\ttraining's binary_logloss: 0.179024\tvalid_1's binary_logloss: 0.20315\n",
      "[50]\ttraining's binary_logloss: 0.17089\tvalid_1's binary_logloss: 0.201594\n",
      "[60]\ttraining's binary_logloss: 0.164265\tvalid_1's binary_logloss: 0.201251\n",
      "[70]\ttraining's binary_logloss: 0.158612\tvalid_1's binary_logloss: 0.200969\n",
      "[80]\ttraining's binary_logloss: 0.153108\tvalid_1's binary_logloss: 0.199624\n",
      "[90]\ttraining's binary_logloss: 0.148339\tvalid_1's binary_logloss: 0.199728\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.153108\tvalid_1's binary_logloss: 0.199624\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23644\tvalid_1's binary_logloss: 0.24578\n",
      "[20]\ttraining's binary_logloss: 0.204978\tvalid_1's binary_logloss: 0.220208\n",
      "[30]\ttraining's binary_logloss: 0.188264\tvalid_1's binary_logloss: 0.20899\n",
      "[40]\ttraining's binary_logloss: 0.178136\tvalid_1's binary_logloss: 0.20563\n",
      "[50]\ttraining's binary_logloss: 0.170171\tvalid_1's binary_logloss: 0.204733\n",
      "[60]\ttraining's binary_logloss: 0.163379\tvalid_1's binary_logloss: 0.203887\n",
      "[70]\ttraining's binary_logloss: 0.15786\tvalid_1's binary_logloss: 0.203369\n",
      "[80]\ttraining's binary_logloss: 0.152631\tvalid_1's binary_logloss: 0.203284\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.155334\tvalid_1's binary_logloss: 0.203153\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236366\tvalid_1's binary_logloss: 0.24584\n",
      "[20]\ttraining's binary_logloss: 0.204987\tvalid_1's binary_logloss: 0.220119\n",
      "[30]\ttraining's binary_logloss: 0.188737\tvalid_1's binary_logloss: 0.209462\n",
      "[40]\ttraining's binary_logloss: 0.178331\tvalid_1's binary_logloss: 0.204766\n",
      "[50]\ttraining's binary_logloss: 0.170291\tvalid_1's binary_logloss: 0.203146\n",
      "[60]\ttraining's binary_logloss: 0.163548\tvalid_1's binary_logloss: 0.201787\n",
      "[70]\ttraining's binary_logloss: 0.157817\tvalid_1's binary_logloss: 0.201176\n",
      "[80]\ttraining's binary_logloss: 0.152481\tvalid_1's binary_logloss: 0.200331\n",
      "[90]\ttraining's binary_logloss: 0.147624\tvalid_1's binary_logloss: 0.200252\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.148139\tvalid_1's binary_logloss: 0.200147\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238293\tvalid_1's binary_logloss: 0.243323\n",
      "[20]\ttraining's binary_logloss: 0.206442\tvalid_1's binary_logloss: 0.21773\n",
      "[30]\ttraining's binary_logloss: 0.189646\tvalid_1's binary_logloss: 0.207056\n",
      "[40]\ttraining's binary_logloss: 0.179659\tvalid_1's binary_logloss: 0.203602\n",
      "[50]\ttraining's binary_logloss: 0.171431\tvalid_1's binary_logloss: 0.201688\n",
      "[60]\ttraining's binary_logloss: 0.164499\tvalid_1's binary_logloss: 0.200143\n",
      "[70]\ttraining's binary_logloss: 0.158567\tvalid_1's binary_logloss: 0.19952\n",
      "[80]\ttraining's binary_logloss: 0.153409\tvalid_1's binary_logloss: 0.199403\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.157502\tvalid_1's binary_logloss: 0.199191\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236227\tvalid_1's binary_logloss: 0.245207\n",
      "[20]\ttraining's binary_logloss: 0.205602\tvalid_1's binary_logloss: 0.219407\n",
      "[30]\ttraining's binary_logloss: 0.1896\tvalid_1's binary_logloss: 0.208559\n",
      "[40]\ttraining's binary_logloss: 0.179271\tvalid_1's binary_logloss: 0.203449\n",
      "[50]\ttraining's binary_logloss: 0.170664\tvalid_1's binary_logloss: 0.201962\n",
      "[60]\ttraining's binary_logloss: 0.164111\tvalid_1's binary_logloss: 0.20092\n",
      "[70]\ttraining's binary_logloss: 0.158804\tvalid_1's binary_logloss: 0.200712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.154028\tvalid_1's binary_logloss: 0.200648\n",
      "[90]\ttraining's binary_logloss: 0.14887\tvalid_1's binary_logloss: 0.201281\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.154028\tvalid_1's binary_logloss: 0.200648\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236644\tvalid_1's binary_logloss: 0.246423\n",
      "[20]\ttraining's binary_logloss: 0.20596\tvalid_1's binary_logloss: 0.221406\n",
      "[30]\ttraining's binary_logloss: 0.188858\tvalid_1's binary_logloss: 0.207264\n",
      "[40]\ttraining's binary_logloss: 0.1786\tvalid_1's binary_logloss: 0.202957\n",
      "[50]\ttraining's binary_logloss: 0.171094\tvalid_1's binary_logloss: 0.201152\n",
      "[60]\ttraining's binary_logloss: 0.164066\tvalid_1's binary_logloss: 0.19989\n",
      "[70]\ttraining's binary_logloss: 0.158205\tvalid_1's binary_logloss: 0.199752\n",
      "[80]\ttraining's binary_logloss: 0.152921\tvalid_1's binary_logloss: 0.199711\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.154815\tvalid_1's binary_logloss: 0.199473\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234851\tvalid_1's binary_logloss: 0.242263\n",
      "[20]\ttraining's binary_logloss: 0.204641\tvalid_1's binary_logloss: 0.21678\n",
      "[30]\ttraining's binary_logloss: 0.188619\tvalid_1's binary_logloss: 0.20709\n",
      "[40]\ttraining's binary_logloss: 0.177707\tvalid_1's binary_logloss: 0.202806\n",
      "[50]\ttraining's binary_logloss: 0.169914\tvalid_1's binary_logloss: 0.201099\n",
      "[60]\ttraining's binary_logloss: 0.162481\tvalid_1's binary_logloss: 0.199309\n",
      "[70]\ttraining's binary_logloss: 0.156802\tvalid_1's binary_logloss: 0.199329\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.159932\tvalid_1's binary_logloss: 0.198949\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235035\tvalid_1's binary_logloss: 0.238946\n",
      "[20]\ttraining's binary_logloss: 0.204779\tvalid_1's binary_logloss: 0.214813\n",
      "[30]\ttraining's binary_logloss: 0.188944\tvalid_1's binary_logloss: 0.204882\n",
      "[40]\ttraining's binary_logloss: 0.178406\tvalid_1's binary_logloss: 0.20024\n",
      "[50]\ttraining's binary_logloss: 0.17024\tvalid_1's binary_logloss: 0.198365\n",
      "[60]\ttraining's binary_logloss: 0.163916\tvalid_1's binary_logloss: 0.197589\n",
      "[70]\ttraining's binary_logloss: 0.158041\tvalid_1's binary_logloss: 0.19745\n",
      "[80]\ttraining's binary_logloss: 0.153159\tvalid_1's binary_logloss: 0.197601\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.156908\tvalid_1's binary_logloss: 0.197328\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238281\tvalid_1's binary_logloss: 0.241149\n",
      "[20]\ttraining's binary_logloss: 0.208342\tvalid_1's binary_logloss: 0.216063\n",
      "[30]\ttraining's binary_logloss: 0.191682\tvalid_1's binary_logloss: 0.205848\n",
      "[40]\ttraining's binary_logloss: 0.180934\tvalid_1's binary_logloss: 0.20148\n",
      "[50]\ttraining's binary_logloss: 0.172263\tvalid_1's binary_logloss: 0.199449\n",
      "[60]\ttraining's binary_logloss: 0.165853\tvalid_1's binary_logloss: 0.198193\n",
      "[70]\ttraining's binary_logloss: 0.160305\tvalid_1's binary_logloss: 0.197148\n",
      "[80]\ttraining's binary_logloss: 0.155486\tvalid_1's binary_logloss: 0.196518\n",
      "[90]\ttraining's binary_logloss: 0.151112\tvalid_1's binary_logloss: 0.19664\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.151819\tvalid_1's binary_logloss: 0.196387\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232778\tvalid_1's binary_logloss: 0.245133\n",
      "[20]\ttraining's binary_logloss: 0.201331\tvalid_1's binary_logloss: 0.220011\n",
      "[30]\ttraining's binary_logloss: 0.185356\tvalid_1's binary_logloss: 0.210825\n",
      "[40]\ttraining's binary_logloss: 0.175512\tvalid_1's binary_logloss: 0.207942\n",
      "[50]\ttraining's binary_logloss: 0.168446\tvalid_1's binary_logloss: 0.207255\n",
      "[60]\ttraining's binary_logloss: 0.161569\tvalid_1's binary_logloss: 0.206324\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.162187\tvalid_1's binary_logloss: 0.206182\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23585\tvalid_1's binary_logloss: 0.243792\n",
      "[20]\ttraining's binary_logloss: 0.205472\tvalid_1's binary_logloss: 0.219991\n",
      "[30]\ttraining's binary_logloss: 0.189202\tvalid_1's binary_logloss: 0.210674\n",
      "[40]\ttraining's binary_logloss: 0.177824\tvalid_1's binary_logloss: 0.206587\n",
      "[50]\ttraining's binary_logloss: 0.169485\tvalid_1's binary_logloss: 0.204711\n",
      "[60]\ttraining's binary_logloss: 0.162522\tvalid_1's binary_logloss: 0.203565\n",
      "[70]\ttraining's binary_logloss: 0.15728\tvalid_1's binary_logloss: 0.203421\n",
      "[80]\ttraining's binary_logloss: 0.152284\tvalid_1's binary_logloss: 0.203286\n",
      "[90]\ttraining's binary_logloss: 0.147294\tvalid_1's binary_logloss: 0.203251\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.151182\tvalid_1's binary_logloss: 0.203075\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234796\tvalid_1's binary_logloss: 0.244056\n",
      "[20]\ttraining's binary_logloss: 0.204225\tvalid_1's binary_logloss: 0.219735\n",
      "[30]\ttraining's binary_logloss: 0.188112\tvalid_1's binary_logloss: 0.21097\n",
      "[40]\ttraining's binary_logloss: 0.17687\tvalid_1's binary_logloss: 0.206358\n",
      "[50]\ttraining's binary_logloss: 0.16847\tvalid_1's binary_logloss: 0.204598\n",
      "[60]\ttraining's binary_logloss: 0.161637\tvalid_1's binary_logloss: 0.203847\n",
      "[70]\ttraining's binary_logloss: 0.155801\tvalid_1's binary_logloss: 0.203385\n",
      "[80]\ttraining's binary_logloss: 0.150397\tvalid_1's binary_logloss: 0.203\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.152576\tvalid_1's binary_logloss: 0.202986\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238379\tvalid_1's binary_logloss: 0.242693\n",
      "[20]\ttraining's binary_logloss: 0.206446\tvalid_1's binary_logloss: 0.215831\n",
      "[30]\ttraining's binary_logloss: 0.188543\tvalid_1's binary_logloss: 0.204425\n",
      "[40]\ttraining's binary_logloss: 0.178553\tvalid_1's binary_logloss: 0.201297\n",
      "[50]\ttraining's binary_logloss: 0.171284\tvalid_1's binary_logloss: 0.19958\n",
      "[60]\ttraining's binary_logloss: 0.164803\tvalid_1's binary_logloss: 0.198927\n",
      "[70]\ttraining's binary_logloss: 0.158734\tvalid_1's binary_logloss: 0.198794\n",
      "[80]\ttraining's binary_logloss: 0.153357\tvalid_1's binary_logloss: 0.198567\n",
      "[90]\ttraining's binary_logloss: 0.148125\tvalid_1's binary_logloss: 0.198439\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's binary_logloss: 0.149721\tvalid_1's binary_logloss: 0.19837\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232279\tvalid_1's binary_logloss: 0.250784\n",
      "[20]\ttraining's binary_logloss: 0.201077\tvalid_1's binary_logloss: 0.228027\n",
      "[30]\ttraining's binary_logloss: 0.185864\tvalid_1's binary_logloss: 0.219292\n",
      "[40]\ttraining's binary_logloss: 0.175094\tvalid_1's binary_logloss: 0.214147\n",
      "[50]\ttraining's binary_logloss: 0.166834\tvalid_1's binary_logloss: 0.212329\n",
      "[60]\ttraining's binary_logloss: 0.15982\tvalid_1's binary_logloss: 0.211972\n",
      "[70]\ttraining's binary_logloss: 0.154236\tvalid_1's binary_logloss: 0.211202\n",
      "[80]\ttraining's binary_logloss: 0.149235\tvalid_1's binary_logloss: 0.211142\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.149759\tvalid_1's binary_logloss: 0.211\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238036\tvalid_1's binary_logloss: 0.240458\n",
      "[20]\ttraining's binary_logloss: 0.207506\tvalid_1's binary_logloss: 0.214557\n",
      "[30]\ttraining's binary_logloss: 0.190647\tvalid_1's binary_logloss: 0.204075\n",
      "[40]\ttraining's binary_logloss: 0.179817\tvalid_1's binary_logloss: 0.199354\n",
      "[50]\ttraining's binary_logloss: 0.171877\tvalid_1's binary_logloss: 0.197812\n",
      "[60]\ttraining's binary_logloss: 0.1648\tvalid_1's binary_logloss: 0.196415\n",
      "[70]\ttraining's binary_logloss: 0.159217\tvalid_1's binary_logloss: 0.196459\n",
      "[80]\ttraining's binary_logloss: 0.153976\tvalid_1's binary_logloss: 0.195829\n",
      "[90]\ttraining's binary_logloss: 0.149434\tvalid_1's binary_logloss: 0.19554\n",
      "[100]\ttraining's binary_logloss: 0.145145\tvalid_1's binary_logloss: 0.195365\n",
      "[110]\ttraining's binary_logloss: 0.140879\tvalid_1's binary_logloss: 0.195276\n",
      "[120]\ttraining's binary_logloss: 0.136854\tvalid_1's binary_logloss: 0.19575\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's binary_logloss: 0.140101\tvalid_1's binary_logloss: 0.195168\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23697\tvalid_1's binary_logloss: 0.241648\n",
      "[20]\ttraining's binary_logloss: 0.204976\tvalid_1's binary_logloss: 0.216034\n",
      "[30]\ttraining's binary_logloss: 0.188507\tvalid_1's binary_logloss: 0.206351\n",
      "[40]\ttraining's binary_logloss: 0.178839\tvalid_1's binary_logloss: 0.203212\n",
      "[50]\ttraining's binary_logloss: 0.170549\tvalid_1's binary_logloss: 0.201638\n",
      "[60]\ttraining's binary_logloss: 0.164223\tvalid_1's binary_logloss: 0.201317\n",
      "[70]\ttraining's binary_logloss: 0.158338\tvalid_1's binary_logloss: 0.200748\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.160052\tvalid_1's binary_logloss: 0.20061\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237606\tvalid_1's binary_logloss: 0.239036\n",
      "[20]\ttraining's binary_logloss: 0.206345\tvalid_1's binary_logloss: 0.214587\n",
      "[30]\ttraining's binary_logloss: 0.189798\tvalid_1's binary_logloss: 0.20415\n",
      "[40]\ttraining's binary_logloss: 0.179168\tvalid_1's binary_logloss: 0.19987\n",
      "[50]\ttraining's binary_logloss: 0.171331\tvalid_1's binary_logloss: 0.19794\n",
      "[60]\ttraining's binary_logloss: 0.164493\tvalid_1's binary_logloss: 0.197177\n",
      "[70]\ttraining's binary_logloss: 0.158859\tvalid_1's binary_logloss: 0.196201\n",
      "[80]\ttraining's binary_logloss: 0.153719\tvalid_1's binary_logloss: 0.195693\n",
      "[90]\ttraining's binary_logloss: 0.149117\tvalid_1's binary_logloss: 0.195632\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.151314\tvalid_1's binary_logloss: 0.1954\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237227\tvalid_1's binary_logloss: 0.24155\n",
      "[20]\ttraining's binary_logloss: 0.20655\tvalid_1's binary_logloss: 0.214629\n",
      "[30]\ttraining's binary_logloss: 0.189971\tvalid_1's binary_logloss: 0.203519\n",
      "[40]\ttraining's binary_logloss: 0.179386\tvalid_1's binary_logloss: 0.198766\n",
      "[50]\ttraining's binary_logloss: 0.171353\tvalid_1's binary_logloss: 0.196212\n",
      "[60]\ttraining's binary_logloss: 0.164925\tvalid_1's binary_logloss: 0.195402\n",
      "[70]\ttraining's binary_logloss: 0.159209\tvalid_1's binary_logloss: 0.194983\n",
      "[80]\ttraining's binary_logloss: 0.154006\tvalid_1's binary_logloss: 0.194138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.154471\tvalid_1's binary_logloss: 0.194087\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23641\tvalid_1's binary_logloss: 0.245604\n",
      "[20]\ttraining's binary_logloss: 0.204046\tvalid_1's binary_logloss: 0.219987\n",
      "[30]\ttraining's binary_logloss: 0.187977\tvalid_1's binary_logloss: 0.208324\n",
      "[40]\ttraining's binary_logloss: 0.177708\tvalid_1's binary_logloss: 0.204917\n",
      "[50]\ttraining's binary_logloss: 0.169964\tvalid_1's binary_logloss: 0.203313\n",
      "[60]\ttraining's binary_logloss: 0.163646\tvalid_1's binary_logloss: 0.202506\n",
      "[70]\ttraining's binary_logloss: 0.157928\tvalid_1's binary_logloss: 0.20236\n",
      "[80]\ttraining's binary_logloss: 0.152504\tvalid_1's binary_logloss: 0.201907\n",
      "[90]\ttraining's binary_logloss: 0.147238\tvalid_1's binary_logloss: 0.201856\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.150198\tvalid_1's binary_logloss: 0.201663\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237439\tvalid_1's binary_logloss: 0.24138\n",
      "[20]\ttraining's binary_logloss: 0.205743\tvalid_1's binary_logloss: 0.216039\n",
      "[30]\ttraining's binary_logloss: 0.188611\tvalid_1's binary_logloss: 0.205025\n",
      "[40]\ttraining's binary_logloss: 0.178412\tvalid_1's binary_logloss: 0.201247\n",
      "[50]\ttraining's binary_logloss: 0.169884\tvalid_1's binary_logloss: 0.199271\n",
      "[60]\ttraining's binary_logloss: 0.163106\tvalid_1's binary_logloss: 0.197845\n",
      "[70]\ttraining's binary_logloss: 0.156998\tvalid_1's binary_logloss: 0.197155\n",
      "[80]\ttraining's binary_logloss: 0.151925\tvalid_1's binary_logloss: 0.196668\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.153733\tvalid_1's binary_logloss: 0.196598\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234893\tvalid_1's binary_logloss: 0.242281\n",
      "[20]\ttraining's binary_logloss: 0.203102\tvalid_1's binary_logloss: 0.217861\n",
      "[30]\ttraining's binary_logloss: 0.186182\tvalid_1's binary_logloss: 0.208404\n",
      "[40]\ttraining's binary_logloss: 0.175507\tvalid_1's binary_logloss: 0.204462\n",
      "[50]\ttraining's binary_logloss: 0.16766\tvalid_1's binary_logloss: 0.203861\n",
      "[60]\ttraining's binary_logloss: 0.161301\tvalid_1's binary_logloss: 0.203446\n",
      "[70]\ttraining's binary_logloss: 0.155686\tvalid_1's binary_logloss: 0.203274\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.158607\tvalid_1's binary_logloss: 0.203093\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234028\tvalid_1's binary_logloss: 0.247511\n",
      "[20]\ttraining's binary_logloss: 0.202079\tvalid_1's binary_logloss: 0.222684\n",
      "[30]\ttraining's binary_logloss: 0.185392\tvalid_1's binary_logloss: 0.213408\n",
      "[40]\ttraining's binary_logloss: 0.175404\tvalid_1's binary_logloss: 0.210437\n",
      "[50]\ttraining's binary_logloss: 0.167192\tvalid_1's binary_logloss: 0.208928\n",
      "[60]\ttraining's binary_logloss: 0.160924\tvalid_1's binary_logloss: 0.208049\n",
      "[70]\ttraining's binary_logloss: 0.154987\tvalid_1's binary_logloss: 0.207696\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.156132\tvalid_1's binary_logloss: 0.207484\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235656\tvalid_1's binary_logloss: 0.240758\n",
      "[20]\ttraining's binary_logloss: 0.204439\tvalid_1's binary_logloss: 0.215474\n",
      "[30]\ttraining's binary_logloss: 0.188675\tvalid_1's binary_logloss: 0.204846\n",
      "[40]\ttraining's binary_logloss: 0.178776\tvalid_1's binary_logloss: 0.20053\n",
      "[50]\ttraining's binary_logloss: 0.170946\tvalid_1's binary_logloss: 0.198234\n",
      "[60]\ttraining's binary_logloss: 0.164892\tvalid_1's binary_logloss: 0.197656\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.16649\tvalid_1's binary_logloss: 0.197539\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1000\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236527\tvalid_1's binary_logloss: 0.244283\n",
      "[20]\ttraining's binary_logloss: 0.205648\tvalid_1's binary_logloss: 0.218979\n",
      "[30]\ttraining's binary_logloss: 0.188285\tvalid_1's binary_logloss: 0.20848\n",
      "[40]\ttraining's binary_logloss: 0.177492\tvalid_1's binary_logloss: 0.204129\n",
      "[50]\ttraining's binary_logloss: 0.169854\tvalid_1's binary_logloss: 0.202699\n",
      "[60]\ttraining's binary_logloss: 0.162856\tvalid_1's binary_logloss: 0.202729\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.16416\tvalid_1's binary_logloss: 0.202411\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234855\tvalid_1's binary_logloss: 0.245435\n",
      "[20]\ttraining's binary_logloss: 0.202639\tvalid_1's binary_logloss: 0.221697\n",
      "[30]\ttraining's binary_logloss: 0.185702\tvalid_1's binary_logloss: 0.211563\n",
      "[40]\ttraining's binary_logloss: 0.175497\tvalid_1's binary_logloss: 0.207414\n",
      "[50]\ttraining's binary_logloss: 0.167715\tvalid_1's binary_logloss: 0.205575\n",
      "[60]\ttraining's binary_logloss: 0.161462\tvalid_1's binary_logloss: 0.204744\n",
      "[70]\ttraining's binary_logloss: 0.155821\tvalid_1's binary_logloss: 0.20443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.150726\tvalid_1's binary_logloss: 0.204444\n",
      "[90]\ttraining's binary_logloss: 0.145987\tvalid_1's binary_logloss: 0.204419\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.149614\tvalid_1's binary_logloss: 0.204171\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236413\tvalid_1's binary_logloss: 0.244616\n",
      "[20]\ttraining's binary_logloss: 0.204204\tvalid_1's binary_logloss: 0.221034\n",
      "[30]\ttraining's binary_logloss: 0.188337\tvalid_1's binary_logloss: 0.21176\n",
      "[40]\ttraining's binary_logloss: 0.177269\tvalid_1's binary_logloss: 0.206773\n",
      "[50]\ttraining's binary_logloss: 0.16909\tvalid_1's binary_logloss: 0.205924\n",
      "[60]\ttraining's binary_logloss: 0.162275\tvalid_1's binary_logloss: 0.205167\n",
      "[70]\ttraining's binary_logloss: 0.156434\tvalid_1's binary_logloss: 0.204525\n",
      "[80]\ttraining's binary_logloss: 0.151159\tvalid_1's binary_logloss: 0.204424\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.15174\tvalid_1's binary_logloss: 0.204254\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.238748\tvalid_1's binary_logloss: 0.240147\n",
      "[20]\ttraining's binary_logloss: 0.206992\tvalid_1's binary_logloss: 0.210734\n",
      "[30]\ttraining's binary_logloss: 0.190579\tvalid_1's binary_logloss: 0.200313\n",
      "[40]\ttraining's binary_logloss: 0.179477\tvalid_1's binary_logloss: 0.196074\n",
      "[50]\ttraining's binary_logloss: 0.17156\tvalid_1's binary_logloss: 0.194369\n",
      "[60]\ttraining's binary_logloss: 0.165077\tvalid_1's binary_logloss: 0.193736\n",
      "[70]\ttraining's binary_logloss: 0.159202\tvalid_1's binary_logloss: 0.193507\n",
      "[80]\ttraining's binary_logloss: 0.153979\tvalid_1's binary_logloss: 0.192969\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.15547\tvalid_1's binary_logloss: 0.192918\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233918\tvalid_1's binary_logloss: 0.245176\n",
      "[20]\ttraining's binary_logloss: 0.202782\tvalid_1's binary_logloss: 0.221806\n",
      "[30]\ttraining's binary_logloss: 0.186886\tvalid_1's binary_logloss: 0.211869\n",
      "[40]\ttraining's binary_logloss: 0.176697\tvalid_1's binary_logloss: 0.209131\n",
      "[50]\ttraining's binary_logloss: 0.168038\tvalid_1's binary_logloss: 0.207568\n",
      "[60]\ttraining's binary_logloss: 0.161253\tvalid_1's binary_logloss: 0.207091\n",
      "[70]\ttraining's binary_logloss: 0.15513\tvalid_1's binary_logloss: 0.206748\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.159415\tvalid_1's binary_logloss: 0.206722\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235208\tvalid_1's binary_logloss: 0.242482\n",
      "[20]\ttraining's binary_logloss: 0.204134\tvalid_1's binary_logloss: 0.217572\n",
      "[30]\ttraining's binary_logloss: 0.187383\tvalid_1's binary_logloss: 0.207451\n",
      "[40]\ttraining's binary_logloss: 0.176612\tvalid_1's binary_logloss: 0.202251\n",
      "[50]\ttraining's binary_logloss: 0.16916\tvalid_1's binary_logloss: 0.20114\n",
      "[60]\ttraining's binary_logloss: 0.162991\tvalid_1's binary_logloss: 0.200479\n",
      "[70]\ttraining's binary_logloss: 0.157273\tvalid_1's binary_logloss: 0.200292\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.160486\tvalid_1's binary_logloss: 0.200064\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234229\tvalid_1's binary_logloss: 0.244636\n",
      "[20]\ttraining's binary_logloss: 0.203218\tvalid_1's binary_logloss: 0.220354\n",
      "[30]\ttraining's binary_logloss: 0.186292\tvalid_1's binary_logloss: 0.210657\n",
      "[40]\ttraining's binary_logloss: 0.176071\tvalid_1's binary_logloss: 0.20773\n",
      "[50]\ttraining's binary_logloss: 0.168048\tvalid_1's binary_logloss: 0.206698\n",
      "[60]\ttraining's binary_logloss: 0.161857\tvalid_1's binary_logloss: 0.206489\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.165371\tvalid_1's binary_logloss: 0.206348\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234365\tvalid_1's binary_logloss: 0.24202\n",
      "[20]\ttraining's binary_logloss: 0.204233\tvalid_1's binary_logloss: 0.217263\n",
      "[30]\ttraining's binary_logloss: 0.187887\tvalid_1's binary_logloss: 0.207081\n",
      "[40]\ttraining's binary_logloss: 0.177448\tvalid_1's binary_logloss: 0.202471\n",
      "[50]\ttraining's binary_logloss: 0.170071\tvalid_1's binary_logloss: 0.201471\n",
      "[60]\ttraining's binary_logloss: 0.163358\tvalid_1's binary_logloss: 0.200449\n",
      "[70]\ttraining's binary_logloss: 0.158017\tvalid_1's binary_logloss: 0.200452\n",
      "[80]\ttraining's binary_logloss: 0.153399\tvalid_1's binary_logloss: 0.200024\n",
      "[90]\ttraining's binary_logloss: 0.148138\tvalid_1's binary_logloss: 0.199517\n",
      "[100]\ttraining's binary_logloss: 0.144234\tvalid_1's binary_logloss: 0.199365\n",
      "[110]\ttraining's binary_logloss: 0.140399\tvalid_1's binary_logloss: 0.19929\n",
      "[120]\ttraining's binary_logloss: 0.136648\tvalid_1's binary_logloss: 0.199659\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.140111\tvalid_1's binary_logloss: 0.199222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237268\tvalid_1's binary_logloss: 0.243832\n",
      "[20]\ttraining's binary_logloss: 0.205799\tvalid_1's binary_logloss: 0.21849\n",
      "[30]\ttraining's binary_logloss: 0.189038\tvalid_1's binary_logloss: 0.20821\n",
      "[40]\ttraining's binary_logloss: 0.178387\tvalid_1's binary_logloss: 0.204088\n",
      "[50]\ttraining's binary_logloss: 0.170661\tvalid_1's binary_logloss: 0.202784\n",
      "[60]\ttraining's binary_logloss: 0.164409\tvalid_1's binary_logloss: 0.202064\n",
      "[70]\ttraining's binary_logloss: 0.158496\tvalid_1's binary_logloss: 0.201478\n",
      "[80]\ttraining's binary_logloss: 0.153298\tvalid_1's binary_logloss: 0.201133\n",
      "[90]\ttraining's binary_logloss: 0.148805\tvalid_1's binary_logloss: 0.201099\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.152269\tvalid_1's binary_logloss: 0.200857\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1001\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234423\tvalid_1's binary_logloss: 0.246745\n",
      "[20]\ttraining's binary_logloss: 0.201026\tvalid_1's binary_logloss: 0.220832\n",
      "[30]\ttraining's binary_logloss: 0.185303\tvalid_1's binary_logloss: 0.211778\n",
      "[40]\ttraining's binary_logloss: 0.174988\tvalid_1's binary_logloss: 0.207753\n",
      "[50]\ttraining's binary_logloss: 0.167526\tvalid_1's binary_logloss: 0.20623\n",
      "[60]\ttraining's binary_logloss: 0.160998\tvalid_1's binary_logloss: 0.205144\n",
      "[70]\ttraining's binary_logloss: 0.155639\tvalid_1's binary_logloss: 0.205133\n",
      "[80]\ttraining's binary_logloss: 0.150144\tvalid_1's binary_logloss: 0.204929\n",
      "[90]\ttraining's binary_logloss: 0.145696\tvalid_1's binary_logloss: 0.205081\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.148434\tvalid_1's binary_logloss: 0.204815\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236582\tvalid_1's binary_logloss: 0.244826\n",
      "[20]\ttraining's binary_logloss: 0.205905\tvalid_1's binary_logloss: 0.220421\n",
      "[30]\ttraining's binary_logloss: 0.188895\tvalid_1's binary_logloss: 0.209992\n",
      "[40]\ttraining's binary_logloss: 0.178777\tvalid_1's binary_logloss: 0.20537\n",
      "[50]\ttraining's binary_logloss: 0.170941\tvalid_1's binary_logloss: 0.203707\n",
      "[60]\ttraining's binary_logloss: 0.163971\tvalid_1's binary_logloss: 0.203087\n",
      "[70]\ttraining's binary_logloss: 0.158354\tvalid_1's binary_logloss: 0.202453\n",
      "[80]\ttraining's binary_logloss: 0.153136\tvalid_1's binary_logloss: 0.201941\n",
      "[90]\ttraining's binary_logloss: 0.148973\tvalid_1's binary_logloss: 0.202263\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.153136\tvalid_1's binary_logloss: 0.201941\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233623\tvalid_1's binary_logloss: 0.244952\n",
      "[20]\ttraining's binary_logloss: 0.203472\tvalid_1's binary_logloss: 0.222041\n",
      "[30]\ttraining's binary_logloss: 0.187296\tvalid_1's binary_logloss: 0.21238\n",
      "[40]\ttraining's binary_logloss: 0.177161\tvalid_1's binary_logloss: 0.208563\n",
      "[50]\ttraining's binary_logloss: 0.16853\tvalid_1's binary_logloss: 0.20678\n",
      "[60]\ttraining's binary_logloss: 0.161544\tvalid_1's binary_logloss: 0.205985\n",
      "[70]\ttraining's binary_logloss: 0.156116\tvalid_1's binary_logloss: 0.205851\n",
      "[80]\ttraining's binary_logloss: 0.151076\tvalid_1's binary_logloss: 0.204912\n",
      "[90]\ttraining's binary_logloss: 0.146514\tvalid_1's binary_logloss: 0.204647\n",
      "[100]\ttraining's binary_logloss: 0.142274\tvalid_1's binary_logloss: 0.204713\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.145317\tvalid_1's binary_logloss: 0.20448\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237895\tvalid_1's binary_logloss: 0.241646\n",
      "[20]\ttraining's binary_logloss: 0.205931\tvalid_1's binary_logloss: 0.217119\n",
      "[30]\ttraining's binary_logloss: 0.189756\tvalid_1's binary_logloss: 0.208036\n",
      "[40]\ttraining's binary_logloss: 0.178127\tvalid_1's binary_logloss: 0.203765\n",
      "[50]\ttraining's binary_logloss: 0.169751\tvalid_1's binary_logloss: 0.202208\n",
      "[60]\ttraining's binary_logloss: 0.163254\tvalid_1's binary_logloss: 0.201604\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.163872\tvalid_1's binary_logloss: 0.201578\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232714\tvalid_1's binary_logloss: 0.247716\n",
      "[20]\ttraining's binary_logloss: 0.201533\tvalid_1's binary_logloss: 0.224838\n",
      "[30]\ttraining's binary_logloss: 0.186122\tvalid_1's binary_logloss: 0.216306\n",
      "[40]\ttraining's binary_logloss: 0.175655\tvalid_1's binary_logloss: 0.212155\n",
      "[50]\ttraining's binary_logloss: 0.167468\tvalid_1's binary_logloss: 0.210271\n",
      "[60]\ttraining's binary_logloss: 0.161219\tvalid_1's binary_logloss: 0.209537\n",
      "[70]\ttraining's binary_logloss: 0.155487\tvalid_1's binary_logloss: 0.209366\n",
      "[80]\ttraining's binary_logloss: 0.149984\tvalid_1's binary_logloss: 0.20906\n",
      "[90]\ttraining's binary_logloss: 0.14534\tvalid_1's binary_logloss: 0.209262\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.148028\tvalid_1's binary_logloss: 0.208952\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235345\tvalid_1's binary_logloss: 0.241961\n",
      "[20]\ttraining's binary_logloss: 0.204024\tvalid_1's binary_logloss: 0.217135\n",
      "[30]\ttraining's binary_logloss: 0.188652\tvalid_1's binary_logloss: 0.207702\n",
      "[40]\ttraining's binary_logloss: 0.177855\tvalid_1's binary_logloss: 0.203443\n",
      "[50]\ttraining's binary_logloss: 0.170083\tvalid_1's binary_logloss: 0.201722\n",
      "[60]\ttraining's binary_logloss: 0.163654\tvalid_1's binary_logloss: 0.201482\n",
      "[70]\ttraining's binary_logloss: 0.157842\tvalid_1's binary_logloss: 0.200626\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.160334\tvalid_1's binary_logloss: 0.200437\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233779\tvalid_1's binary_logloss: 0.245161\n",
      "[20]\ttraining's binary_logloss: 0.202\tvalid_1's binary_logloss: 0.221615\n",
      "[30]\ttraining's binary_logloss: 0.186718\tvalid_1's binary_logloss: 0.212295\n",
      "[40]\ttraining's binary_logloss: 0.176061\tvalid_1's binary_logloss: 0.208357\n",
      "[50]\ttraining's binary_logloss: 0.168813\tvalid_1's binary_logloss: 0.207778\n",
      "[60]\ttraining's binary_logloss: 0.16166\tvalid_1's binary_logloss: 0.205698\n",
      "[70]\ttraining's binary_logloss: 0.155797\tvalid_1's binary_logloss: 0.205284\n",
      "[80]\ttraining's binary_logloss: 0.151018\tvalid_1's binary_logloss: 0.205065\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.151904\tvalid_1's binary_logloss: 0.205051\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237741\tvalid_1's binary_logloss: 0.239102\n",
      "[20]\ttraining's binary_logloss: 0.206506\tvalid_1's binary_logloss: 0.212905\n",
      "[30]\ttraining's binary_logloss: 0.189832\tvalid_1's binary_logloss: 0.201971\n",
      "[40]\ttraining's binary_logloss: 0.179943\tvalid_1's binary_logloss: 0.198334\n",
      "[50]\ttraining's binary_logloss: 0.171958\tvalid_1's binary_logloss: 0.19636\n",
      "[60]\ttraining's binary_logloss: 0.16526\tvalid_1's binary_logloss: 0.195471\n",
      "[70]\ttraining's binary_logloss: 0.159262\tvalid_1's binary_logloss: 0.194927\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.161994\tvalid_1's binary_logloss: 0.194836\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237747\tvalid_1's binary_logloss: 0.242016\n",
      "[20]\ttraining's binary_logloss: 0.206991\tvalid_1's binary_logloss: 0.216467\n",
      "[30]\ttraining's binary_logloss: 0.1905\tvalid_1's binary_logloss: 0.205309\n",
      "[40]\ttraining's binary_logloss: 0.179963\tvalid_1's binary_logloss: 0.200181\n",
      "[50]\ttraining's binary_logloss: 0.172835\tvalid_1's binary_logloss: 0.19899\n",
      "[60]\ttraining's binary_logloss: 0.165768\tvalid_1's binary_logloss: 0.197962\n",
      "[70]\ttraining's binary_logloss: 0.160029\tvalid_1's binary_logloss: 0.197735\n",
      "[80]\ttraining's binary_logloss: 0.154682\tvalid_1's binary_logloss: 0.197531\n",
      "[90]\ttraining's binary_logloss: 0.150243\tvalid_1's binary_logloss: 0.197415\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.151114\tvalid_1's binary_logloss: 0.197397\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23393\tvalid_1's binary_logloss: 0.24787\n",
      "[20]\ttraining's binary_logloss: 0.201513\tvalid_1's binary_logloss: 0.222365\n",
      "[30]\ttraining's binary_logloss: 0.185759\tvalid_1's binary_logloss: 0.212305\n",
      "[40]\ttraining's binary_logloss: 0.175975\tvalid_1's binary_logloss: 0.208959\n",
      "[50]\ttraining's binary_logloss: 0.16789\tvalid_1's binary_logloss: 0.207558\n",
      "[60]\ttraining's binary_logloss: 0.161428\tvalid_1's binary_logloss: 0.207321\n",
      "[70]\ttraining's binary_logloss: 0.155651\tvalid_1's binary_logloss: 0.206469\n",
      "[80]\ttraining's binary_logloss: 0.150676\tvalid_1's binary_logloss: 0.206296\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.151677\tvalid_1's binary_logloss: 0.2061\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1003\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234002\tvalid_1's binary_logloss: 0.248086\n",
      "[20]\ttraining's binary_logloss: 0.201632\tvalid_1's binary_logloss: 0.224375\n",
      "[30]\ttraining's binary_logloss: 0.184761\tvalid_1's binary_logloss: 0.214817\n",
      "[40]\ttraining's binary_logloss: 0.17453\tvalid_1's binary_logloss: 0.211666\n",
      "[50]\ttraining's binary_logloss: 0.165982\tvalid_1's binary_logloss: 0.209277\n",
      "[60]\ttraining's binary_logloss: 0.159574\tvalid_1's binary_logloss: 0.208746\n",
      "[70]\ttraining's binary_logloss: 0.153263\tvalid_1's binary_logloss: 0.208646\n",
      "[80]\ttraining's binary_logloss: 0.148035\tvalid_1's binary_logloss: 0.208259\n",
      "[90]\ttraining's binary_logloss: 0.143644\tvalid_1's binary_logloss: 0.208532\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.148035\tvalid_1's binary_logloss: 0.208259\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236903\tvalid_1's binary_logloss: 0.240429\n",
      "[20]\ttraining's binary_logloss: 0.205549\tvalid_1's binary_logloss: 0.214614\n",
      "[30]\ttraining's binary_logloss: 0.188871\tvalid_1's binary_logloss: 0.204739\n",
      "[40]\ttraining's binary_logloss: 0.178172\tvalid_1's binary_logloss: 0.201076\n",
      "[50]\ttraining's binary_logloss: 0.170675\tvalid_1's binary_logloss: 0.199285\n",
      "[60]\ttraining's binary_logloss: 0.163949\tvalid_1's binary_logloss: 0.198919\n",
      "[70]\ttraining's binary_logloss: 0.158028\tvalid_1's binary_logloss: 0.19833\n",
      "[80]\ttraining's binary_logloss: 0.15283\tvalid_1's binary_logloss: 0.198247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttraining's binary_logloss: 0.147336\tvalid_1's binary_logloss: 0.197549\n",
      "[100]\ttraining's binary_logloss: 0.142851\tvalid_1's binary_logloss: 0.198016\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.147336\tvalid_1's binary_logloss: 0.197549\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1004\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23518\tvalid_1's binary_logloss: 0.244296\n",
      "[20]\ttraining's binary_logloss: 0.202984\tvalid_1's binary_logloss: 0.219697\n",
      "[30]\ttraining's binary_logloss: 0.186905\tvalid_1's binary_logloss: 0.209324\n",
      "[40]\ttraining's binary_logloss: 0.177219\tvalid_1's binary_logloss: 0.20537\n",
      "[50]\ttraining's binary_logloss: 0.169024\tvalid_1's binary_logloss: 0.203639\n",
      "[60]\ttraining's binary_logloss: 0.162\tvalid_1's binary_logloss: 0.203\n",
      "[70]\ttraining's binary_logloss: 0.156002\tvalid_1's binary_logloss: 0.202988\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's binary_logloss: 0.158027\tvalid_1's binary_logloss: 0.202972\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237857\tvalid_1's binary_logloss: 0.240517\n",
      "[20]\ttraining's binary_logloss: 0.206567\tvalid_1's binary_logloss: 0.216493\n",
      "[30]\ttraining's binary_logloss: 0.189799\tvalid_1's binary_logloss: 0.206115\n",
      "[40]\ttraining's binary_logloss: 0.179414\tvalid_1's binary_logloss: 0.203111\n",
      "[50]\ttraining's binary_logloss: 0.170892\tvalid_1's binary_logloss: 0.201631\n",
      "[60]\ttraining's binary_logloss: 0.164044\tvalid_1's binary_logloss: 0.20116\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.168562\tvalid_1's binary_logloss: 0.201019\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23391\tvalid_1's binary_logloss: 0.244127\n",
      "[20]\ttraining's binary_logloss: 0.203478\tvalid_1's binary_logloss: 0.221752\n",
      "[30]\ttraining's binary_logloss: 0.187853\tvalid_1's binary_logloss: 0.212781\n",
      "[40]\ttraining's binary_logloss: 0.176937\tvalid_1's binary_logloss: 0.207959\n",
      "[50]\ttraining's binary_logloss: 0.169439\tvalid_1's binary_logloss: 0.206424\n",
      "[60]\ttraining's binary_logloss: 0.163163\tvalid_1's binary_logloss: 0.205977\n",
      "[70]\ttraining's binary_logloss: 0.157537\tvalid_1's binary_logloss: 0.205488\n",
      "[80]\ttraining's binary_logloss: 0.151831\tvalid_1's binary_logloss: 0.20457\n",
      "[90]\ttraining's binary_logloss: 0.147098\tvalid_1's binary_logloss: 0.204824\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.151831\tvalid_1's binary_logloss: 0.20457\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "org_X_train = X_train.copy()\n",
    "org_y_train = y_train.copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # 訓練データからデータを分割\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(org_X_train, org_y_train, test_size=0.3, random_state=i, stratify=org_y_train)\n",
    "\n",
    "    # 使用モデルはLGB（パラメータチューニング無）\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "#     lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n",
    "#     lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary'\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_eval],\n",
    "        verbose_eval=10,\n",
    "        num_boost_round=1000,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    pred_df[i] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.631701\n",
       "1        0.597465\n",
       "2        0.000889\n",
       "3        0.001358\n",
       "4        0.137246\n",
       "           ...   \n",
       "18078    0.001625\n",
       "18079    0.065244\n",
       "18080    0.001087\n",
       "18081    0.004256\n",
       "18082    0.009399\n",
       "Length: 18083, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[1] = pred_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('20200929_002.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
