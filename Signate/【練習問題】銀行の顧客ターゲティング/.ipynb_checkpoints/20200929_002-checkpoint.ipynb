{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataの読み込み\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submit_df = pd.read_csv('submit_sample.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27128, 18), (18083, 17), (18083, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの量の確認\n",
    "train_df.shape,test_df.shape,submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータがわかるようにダミーの目的変数を代入\n",
    "test_df['y']=-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データ、テストデータを結合\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # カテゴリカラムの前処理\n",
    "categorical_features = ['job', 'marital', 'education','default','housing','loan','contact','month','poutcome']\n",
    "# for col in categorical_features:\n",
    "#     lbl = preprocessing.LabelEncoder()\n",
    "#     lbl.fit(all_df[col])\n",
    "#     lbl.transform(all_df[col])\n",
    "#     all_df[col]=lbl.transform(all_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.get_dummies(all_df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータの分割\n",
    "train_df = all_df[all_df['y']!=-999]\n",
    "test_df = all_df[all_df['y']==-999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['y']\n",
    "X_train = train_df.drop(['y','id'], axis=1)\n",
    "X_test = test_df.drop(['y','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237052\tvalid_1's binary_logloss: 0.24011\n",
      "[20]\ttraining's binary_logloss: 0.205676\tvalid_1's binary_logloss: 0.214091\n",
      "[30]\ttraining's binary_logloss: 0.189687\tvalid_1's binary_logloss: 0.203555\n",
      "[40]\ttraining's binary_logloss: 0.178996\tvalid_1's binary_logloss: 0.1994\n",
      "[50]\ttraining's binary_logloss: 0.170496\tvalid_1's binary_logloss: 0.19713\n",
      "[60]\ttraining's binary_logloss: 0.163495\tvalid_1's binary_logloss: 0.195199\n",
      "[70]\ttraining's binary_logloss: 0.15744\tvalid_1's binary_logloss: 0.194861\n",
      "[80]\ttraining's binary_logloss: 0.152105\tvalid_1's binary_logloss: 0.194313\n",
      "[90]\ttraining's binary_logloss: 0.146967\tvalid_1's binary_logloss: 0.194523\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.151154\tvalid_1's binary_logloss: 0.194225\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234027\tvalid_1's binary_logloss: 0.244608\n",
      "[20]\ttraining's binary_logloss: 0.20319\tvalid_1's binary_logloss: 0.220296\n",
      "[30]\ttraining's binary_logloss: 0.186854\tvalid_1's binary_logloss: 0.20943\n",
      "[40]\ttraining's binary_logloss: 0.176721\tvalid_1's binary_logloss: 0.205674\n",
      "[50]\ttraining's binary_logloss: 0.168293\tvalid_1's binary_logloss: 0.20343\n",
      "[60]\ttraining's binary_logloss: 0.162238\tvalid_1's binary_logloss: 0.202559\n",
      "[70]\ttraining's binary_logloss: 0.156654\tvalid_1's binary_logloss: 0.202118\n",
      "[80]\ttraining's binary_logloss: 0.151321\tvalid_1's binary_logloss: 0.202204\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.154004\tvalid_1's binary_logloss: 0.201765\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233622\tvalid_1's binary_logloss: 0.245449\n",
      "[20]\ttraining's binary_logloss: 0.202101\tvalid_1's binary_logloss: 0.220209\n",
      "[30]\ttraining's binary_logloss: 0.185182\tvalid_1's binary_logloss: 0.20967\n",
      "[40]\ttraining's binary_logloss: 0.173971\tvalid_1's binary_logloss: 0.205881\n",
      "[50]\ttraining's binary_logloss: 0.165806\tvalid_1's binary_logloss: 0.204654\n",
      "[60]\ttraining's binary_logloss: 0.159534\tvalid_1's binary_logloss: 0.204472\n",
      "[70]\ttraining's binary_logloss: 0.153422\tvalid_1's binary_logloss: 0.204506\n",
      "[80]\ttraining's binary_logloss: 0.147828\tvalid_1's binary_logloss: 0.203774\n",
      "[90]\ttraining's binary_logloss: 0.14293\tvalid_1's binary_logloss: 0.203587\n",
      "[100]\ttraining's binary_logloss: 0.138396\tvalid_1's binary_logloss: 0.20381\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.142104\tvalid_1's binary_logloss: 0.203289\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237645\tvalid_1's binary_logloss: 0.240069\n",
      "[20]\ttraining's binary_logloss: 0.206108\tvalid_1's binary_logloss: 0.213551\n",
      "[30]\ttraining's binary_logloss: 0.189487\tvalid_1's binary_logloss: 0.202417\n",
      "[40]\ttraining's binary_logloss: 0.178316\tvalid_1's binary_logloss: 0.197475\n",
      "[50]\ttraining's binary_logloss: 0.169786\tvalid_1's binary_logloss: 0.195381\n",
      "[60]\ttraining's binary_logloss: 0.162676\tvalid_1's binary_logloss: 0.194542\n",
      "[70]\ttraining's binary_logloss: 0.15645\tvalid_1's binary_logloss: 0.193472\n",
      "[80]\ttraining's binary_logloss: 0.150811\tvalid_1's binary_logloss: 0.193829\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.155147\tvalid_1's binary_logloss: 0.1934\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234946\tvalid_1's binary_logloss: 0.24512\n",
      "[20]\ttraining's binary_logloss: 0.204225\tvalid_1's binary_logloss: 0.220706\n",
      "[30]\ttraining's binary_logloss: 0.187374\tvalid_1's binary_logloss: 0.209816\n",
      "[40]\ttraining's binary_logloss: 0.176116\tvalid_1's binary_logloss: 0.205817\n",
      "[50]\ttraining's binary_logloss: 0.16788\tvalid_1's binary_logloss: 0.20506\n",
      "[60]\ttraining's binary_logloss: 0.161427\tvalid_1's binary_logloss: 0.204804\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.16313\tvalid_1's binary_logloss: 0.204679\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233647\tvalid_1's binary_logloss: 0.240866\n",
      "[20]\ttraining's binary_logloss: 0.203487\tvalid_1's binary_logloss: 0.216052\n",
      "[30]\ttraining's binary_logloss: 0.18669\tvalid_1's binary_logloss: 0.205849\n",
      "[40]\ttraining's binary_logloss: 0.176499\tvalid_1's binary_logloss: 0.201448\n",
      "[50]\ttraining's binary_logloss: 0.168618\tvalid_1's binary_logloss: 0.200652\n",
      "[60]\ttraining's binary_logloss: 0.162122\tvalid_1's binary_logloss: 0.199716\n",
      "[70]\ttraining's binary_logloss: 0.156134\tvalid_1's binary_logloss: 0.19952\n",
      "[80]\ttraining's binary_logloss: 0.150555\tvalid_1's binary_logloss: 0.198732\n",
      "[90]\ttraining's binary_logloss: 0.145625\tvalid_1's binary_logloss: 0.198368\n",
      "[100]\ttraining's binary_logloss: 0.140954\tvalid_1's binary_logloss: 0.198188\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.143748\tvalid_1's binary_logloss: 0.198044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232071\tvalid_1's binary_logloss: 0.246596\n",
      "[20]\ttraining's binary_logloss: 0.200567\tvalid_1's binary_logloss: 0.222505\n",
      "[30]\ttraining's binary_logloss: 0.184404\tvalid_1's binary_logloss: 0.213353\n",
      "[40]\ttraining's binary_logloss: 0.173658\tvalid_1's binary_logloss: 0.210596\n",
      "[50]\ttraining's binary_logloss: 0.16557\tvalid_1's binary_logloss: 0.208326\n",
      "[60]\ttraining's binary_logloss: 0.159022\tvalid_1's binary_logloss: 0.207655\n",
      "[70]\ttraining's binary_logloss: 0.153303\tvalid_1's binary_logloss: 0.207281\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.153797\tvalid_1's binary_logloss: 0.207258\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234379\tvalid_1's binary_logloss: 0.243054\n",
      "[20]\ttraining's binary_logloss: 0.203599\tvalid_1's binary_logloss: 0.217372\n",
      "[30]\ttraining's binary_logloss: 0.186847\tvalid_1's binary_logloss: 0.205557\n",
      "[40]\ttraining's binary_logloss: 0.176313\tvalid_1's binary_logloss: 0.201395\n",
      "[50]\ttraining's binary_logloss: 0.168234\tvalid_1's binary_logloss: 0.199768\n",
      "[60]\ttraining's binary_logloss: 0.161266\tvalid_1's binary_logloss: 0.19856\n",
      "[70]\ttraining's binary_logloss: 0.15604\tvalid_1's binary_logloss: 0.197862\n",
      "[80]\ttraining's binary_logloss: 0.151091\tvalid_1's binary_logloss: 0.198045\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.15604\tvalid_1's binary_logloss: 0.197862\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233736\tvalid_1's binary_logloss: 0.244918\n",
      "[20]\ttraining's binary_logloss: 0.2022\tvalid_1's binary_logloss: 0.21955\n",
      "[30]\ttraining's binary_logloss: 0.185573\tvalid_1's binary_logloss: 0.211236\n",
      "[40]\ttraining's binary_logloss: 0.174605\tvalid_1's binary_logloss: 0.20764\n",
      "[50]\ttraining's binary_logloss: 0.16654\tvalid_1's binary_logloss: 0.206359\n",
      "[60]\ttraining's binary_logloss: 0.160349\tvalid_1's binary_logloss: 0.206456\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.165704\tvalid_1's binary_logloss: 0.206267\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23495\tvalid_1's binary_logloss: 0.243823\n",
      "[20]\ttraining's binary_logloss: 0.202423\tvalid_1's binary_logloss: 0.218829\n",
      "[30]\ttraining's binary_logloss: 0.18632\tvalid_1's binary_logloss: 0.209868\n",
      "[40]\ttraining's binary_logloss: 0.176226\tvalid_1's binary_logloss: 0.206025\n",
      "[50]\ttraining's binary_logloss: 0.168438\tvalid_1's binary_logloss: 0.20472\n",
      "[60]\ttraining's binary_logloss: 0.161477\tvalid_1's binary_logloss: 0.203682\n",
      "[70]\ttraining's binary_logloss: 0.155549\tvalid_1's binary_logloss: 0.202915\n",
      "[80]\ttraining's binary_logloss: 0.149247\tvalid_1's binary_logloss: 0.20164\n",
      "[90]\ttraining's binary_logloss: 0.144105\tvalid_1's binary_logloss: 0.201378\n",
      "[100]\ttraining's binary_logloss: 0.139186\tvalid_1's binary_logloss: 0.201598\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.143636\tvalid_1's binary_logloss: 0.201378\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235087\tvalid_1's binary_logloss: 0.241415\n",
      "[20]\ttraining's binary_logloss: 0.203167\tvalid_1's binary_logloss: 0.215086\n",
      "[30]\ttraining's binary_logloss: 0.186896\tvalid_1's binary_logloss: 0.205493\n",
      "[40]\ttraining's binary_logloss: 0.176441\tvalid_1's binary_logloss: 0.201086\n",
      "[50]\ttraining's binary_logloss: 0.168569\tvalid_1's binary_logloss: 0.199516\n",
      "[60]\ttraining's binary_logloss: 0.161998\tvalid_1's binary_logloss: 0.198764\n",
      "[70]\ttraining's binary_logloss: 0.155806\tvalid_1's binary_logloss: 0.19809\n",
      "[80]\ttraining's binary_logloss: 0.150429\tvalid_1's binary_logloss: 0.197644\n",
      "[90]\ttraining's binary_logloss: 0.145693\tvalid_1's binary_logloss: 0.197914\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.150026\tvalid_1's binary_logloss: 0.197631\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235318\tvalid_1's binary_logloss: 0.243416\n",
      "[20]\ttraining's binary_logloss: 0.204442\tvalid_1's binary_logloss: 0.218012\n",
      "[30]\ttraining's binary_logloss: 0.189383\tvalid_1's binary_logloss: 0.208545\n",
      "[40]\ttraining's binary_logloss: 0.178204\tvalid_1's binary_logloss: 0.204035\n",
      "[50]\ttraining's binary_logloss: 0.169778\tvalid_1's binary_logloss: 0.201722\n",
      "[60]\ttraining's binary_logloss: 0.162682\tvalid_1's binary_logloss: 0.200989\n",
      "[70]\ttraining's binary_logloss: 0.157175\tvalid_1's binary_logloss: 0.200398\n",
      "[80]\ttraining's binary_logloss: 0.151983\tvalid_1's binary_logloss: 0.200905\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.157175\tvalid_1's binary_logloss: 0.200398\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's binary_logloss: 0.233554\tvalid_1's binary_logloss: 0.242397\n",
      "[20]\ttraining's binary_logloss: 0.201945\tvalid_1's binary_logloss: 0.217509\n",
      "[30]\ttraining's binary_logloss: 0.18544\tvalid_1's binary_logloss: 0.206722\n",
      "[40]\ttraining's binary_logloss: 0.174633\tvalid_1's binary_logloss: 0.202244\n",
      "[50]\ttraining's binary_logloss: 0.166336\tvalid_1's binary_logloss: 0.200573\n",
      "[60]\ttraining's binary_logloss: 0.159828\tvalid_1's binary_logloss: 0.200422\n",
      "[70]\ttraining's binary_logloss: 0.153997\tvalid_1's binary_logloss: 0.200188\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.1544\tvalid_1's binary_logloss: 0.200096\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235131\tvalid_1's binary_logloss: 0.240956\n",
      "[20]\ttraining's binary_logloss: 0.203865\tvalid_1's binary_logloss: 0.216084\n",
      "[30]\ttraining's binary_logloss: 0.186106\tvalid_1's binary_logloss: 0.206194\n",
      "[40]\ttraining's binary_logloss: 0.175631\tvalid_1's binary_logloss: 0.202224\n",
      "[50]\ttraining's binary_logloss: 0.167236\tvalid_1's binary_logloss: 0.200649\n",
      "[60]\ttraining's binary_logloss: 0.160797\tvalid_1's binary_logloss: 0.199903\n",
      "[70]\ttraining's binary_logloss: 0.154661\tvalid_1's binary_logloss: 0.199021\n",
      "[80]\ttraining's binary_logloss: 0.149308\tvalid_1's binary_logloss: 0.199057\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.151359\tvalid_1's binary_logloss: 0.198846\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23462\tvalid_1's binary_logloss: 0.242107\n",
      "[20]\ttraining's binary_logloss: 0.203555\tvalid_1's binary_logloss: 0.21799\n",
      "[30]\ttraining's binary_logloss: 0.187905\tvalid_1's binary_logloss: 0.209221\n",
      "[40]\ttraining's binary_logloss: 0.177051\tvalid_1's binary_logloss: 0.205826\n",
      "[50]\ttraining's binary_logloss: 0.168887\tvalid_1's binary_logloss: 0.203488\n",
      "[60]\ttraining's binary_logloss: 0.161963\tvalid_1's binary_logloss: 0.202027\n",
      "[70]\ttraining's binary_logloss: 0.155975\tvalid_1's binary_logloss: 0.201942\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.157696\tvalid_1's binary_logloss: 0.201851\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237243\tvalid_1's binary_logloss: 0.242287\n",
      "[20]\ttraining's binary_logloss: 0.205152\tvalid_1's binary_logloss: 0.217002\n",
      "[30]\ttraining's binary_logloss: 0.187994\tvalid_1's binary_logloss: 0.205817\n",
      "[40]\ttraining's binary_logloss: 0.177983\tvalid_1's binary_logloss: 0.202445\n",
      "[50]\ttraining's binary_logloss: 0.169602\tvalid_1's binary_logloss: 0.200275\n",
      "[60]\ttraining's binary_logloss: 0.162751\tvalid_1's binary_logloss: 0.19967\n",
      "[70]\ttraining's binary_logloss: 0.157036\tvalid_1's binary_logloss: 0.199196\n",
      "[80]\ttraining's binary_logloss: 0.152232\tvalid_1's binary_logloss: 0.199269\n",
      "[90]\ttraining's binary_logloss: 0.147411\tvalid_1's binary_logloss: 0.199472\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.15124\tvalid_1's binary_logloss: 0.199066\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23355\tvalid_1's binary_logloss: 0.24402\n",
      "[20]\ttraining's binary_logloss: 0.203021\tvalid_1's binary_logloss: 0.22\n",
      "[30]\ttraining's binary_logloss: 0.186727\tvalid_1's binary_logloss: 0.212012\n",
      "[40]\ttraining's binary_logloss: 0.176128\tvalid_1's binary_logloss: 0.208299\n",
      "[50]\ttraining's binary_logloss: 0.168107\tvalid_1's binary_logloss: 0.206898\n",
      "[60]\ttraining's binary_logloss: 0.16141\tvalid_1's binary_logloss: 0.20652\n",
      "[70]\ttraining's binary_logloss: 0.155268\tvalid_1's binary_logloss: 0.205815\n",
      "[80]\ttraining's binary_logloss: 0.149338\tvalid_1's binary_logloss: 0.205748\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.153721\tvalid_1's binary_logloss: 0.205707\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233549\tvalid_1's binary_logloss: 0.245189\n",
      "[20]\ttraining's binary_logloss: 0.203058\tvalid_1's binary_logloss: 0.222142\n",
      "[30]\ttraining's binary_logloss: 0.185554\tvalid_1's binary_logloss: 0.210794\n",
      "[40]\ttraining's binary_logloss: 0.174812\tvalid_1's binary_logloss: 0.206891\n",
      "[50]\ttraining's binary_logloss: 0.166455\tvalid_1's binary_logloss: 0.205151\n",
      "[60]\ttraining's binary_logloss: 0.159555\tvalid_1's binary_logloss: 0.204221\n",
      "[70]\ttraining's binary_logloss: 0.153643\tvalid_1's binary_logloss: 0.203607\n",
      "[80]\ttraining's binary_logloss: 0.148667\tvalid_1's binary_logloss: 0.203269\n",
      "[90]\ttraining's binary_logloss: 0.143613\tvalid_1's binary_logloss: 0.202655\n",
      "[100]\ttraining's binary_logloss: 0.1389\tvalid_1's binary_logloss: 0.202786\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.14305\tvalid_1's binary_logloss: 0.202445\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232798\tvalid_1's binary_logloss: 0.24517\n",
      "[20]\ttraining's binary_logloss: 0.201681\tvalid_1's binary_logloss: 0.221505\n",
      "[30]\ttraining's binary_logloss: 0.185791\tvalid_1's binary_logloss: 0.212551\n",
      "[40]\ttraining's binary_logloss: 0.174957\tvalid_1's binary_logloss: 0.209026\n",
      "[50]\ttraining's binary_logloss: 0.166631\tvalid_1's binary_logloss: 0.207842\n",
      "[60]\ttraining's binary_logloss: 0.159751\tvalid_1's binary_logloss: 0.207178\n",
      "[70]\ttraining's binary_logloss: 0.15377\tvalid_1's binary_logloss: 0.206944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.148136\tvalid_1's binary_logloss: 0.206855\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.151528\tvalid_1's binary_logloss: 0.206826\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.231748\tvalid_1's binary_logloss: 0.246704\n",
      "[20]\ttraining's binary_logloss: 0.201661\tvalid_1's binary_logloss: 0.224541\n",
      "[30]\ttraining's binary_logloss: 0.185046\tvalid_1's binary_logloss: 0.214978\n",
      "[40]\ttraining's binary_logloss: 0.174243\tvalid_1's binary_logloss: 0.21093\n",
      "[50]\ttraining's binary_logloss: 0.166423\tvalid_1's binary_logloss: 0.209846\n",
      "[60]\ttraining's binary_logloss: 0.159268\tvalid_1's binary_logloss: 0.209187\n",
      "[70]\ttraining's binary_logloss: 0.153413\tvalid_1's binary_logloss: 0.208955\n",
      "[80]\ttraining's binary_logloss: 0.148261\tvalid_1's binary_logloss: 0.208915\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.150867\tvalid_1's binary_logloss: 0.208692\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237726\tvalid_1's binary_logloss: 0.24062\n",
      "[20]\ttraining's binary_logloss: 0.207625\tvalid_1's binary_logloss: 0.214934\n",
      "[30]\ttraining's binary_logloss: 0.190262\tvalid_1's binary_logloss: 0.202588\n",
      "[40]\ttraining's binary_logloss: 0.179691\tvalid_1's binary_logloss: 0.198596\n",
      "[50]\ttraining's binary_logloss: 0.1717\tvalid_1's binary_logloss: 0.197153\n",
      "[60]\ttraining's binary_logloss: 0.16473\tvalid_1's binary_logloss: 0.196241\n",
      "[70]\ttraining's binary_logloss: 0.158551\tvalid_1's binary_logloss: 0.195355\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.160455\tvalid_1's binary_logloss: 0.195062\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234723\tvalid_1's binary_logloss: 0.239159\n",
      "[20]\ttraining's binary_logloss: 0.20229\tvalid_1's binary_logloss: 0.213864\n",
      "[30]\ttraining's binary_logloss: 0.186061\tvalid_1's binary_logloss: 0.20431\n",
      "[40]\ttraining's binary_logloss: 0.175597\tvalid_1's binary_logloss: 0.200381\n",
      "[50]\ttraining's binary_logloss: 0.167745\tvalid_1's binary_logloss: 0.199061\n",
      "[60]\ttraining's binary_logloss: 0.160486\tvalid_1's binary_logloss: 0.198843\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.164656\tvalid_1's binary_logloss: 0.198668\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232149\tvalid_1's binary_logloss: 0.246223\n",
      "[20]\ttraining's binary_logloss: 0.200468\tvalid_1's binary_logloss: 0.223257\n",
      "[30]\ttraining's binary_logloss: 0.184658\tvalid_1's binary_logloss: 0.213689\n",
      "[40]\ttraining's binary_logloss: 0.174438\tvalid_1's binary_logloss: 0.210218\n",
      "[50]\ttraining's binary_logloss: 0.166495\tvalid_1's binary_logloss: 0.208917\n",
      "[60]\ttraining's binary_logloss: 0.159148\tvalid_1's binary_logloss: 0.206925\n",
      "[70]\ttraining's binary_logloss: 0.153085\tvalid_1's binary_logloss: 0.206843\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.154787\tvalid_1's binary_logloss: 0.206813\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23374\tvalid_1's binary_logloss: 0.243198\n",
      "[20]\ttraining's binary_logloss: 0.201881\tvalid_1's binary_logloss: 0.218632\n",
      "[30]\ttraining's binary_logloss: 0.185889\tvalid_1's binary_logloss: 0.209834\n",
      "[40]\ttraining's binary_logloss: 0.176251\tvalid_1's binary_logloss: 0.207086\n",
      "[50]\ttraining's binary_logloss: 0.167895\tvalid_1's binary_logloss: 0.205011\n",
      "[60]\ttraining's binary_logloss: 0.160714\tvalid_1's binary_logloss: 0.204292\n",
      "[70]\ttraining's binary_logloss: 0.154777\tvalid_1's binary_logloss: 0.20398\n",
      "[80]\ttraining's binary_logloss: 0.149522\tvalid_1's binary_logloss: 0.204294\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.153614\tvalid_1's binary_logloss: 0.203795\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23633\tvalid_1's binary_logloss: 0.24046\n",
      "[20]\ttraining's binary_logloss: 0.206166\tvalid_1's binary_logloss: 0.214974\n",
      "[30]\ttraining's binary_logloss: 0.190141\tvalid_1's binary_logloss: 0.205018\n",
      "[40]\ttraining's binary_logloss: 0.17936\tvalid_1's binary_logloss: 0.200177\n",
      "[50]\ttraining's binary_logloss: 0.171268\tvalid_1's binary_logloss: 0.197669\n",
      "[60]\ttraining's binary_logloss: 0.164667\tvalid_1's binary_logloss: 0.196631\n",
      "[70]\ttraining's binary_logloss: 0.158594\tvalid_1's binary_logloss: 0.195915\n",
      "[80]\ttraining's binary_logloss: 0.153151\tvalid_1's binary_logloss: 0.195663\n",
      "[90]\ttraining's binary_logloss: 0.148345\tvalid_1's binary_logloss: 0.195551\n",
      "[100]\ttraining's binary_logloss: 0.143721\tvalid_1's binary_logloss: 0.195411\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.14733\tvalid_1's binary_logloss: 0.195341\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237118\tvalid_1's binary_logloss: 0.241399\n",
      "[20]\ttraining's binary_logloss: 0.205307\tvalid_1's binary_logloss: 0.213492\n",
      "[30]\ttraining's binary_logloss: 0.188352\tvalid_1's binary_logloss: 0.201678\n",
      "[40]\ttraining's binary_logloss: 0.178067\tvalid_1's binary_logloss: 0.197824\n",
      "[50]\ttraining's binary_logloss: 0.169903\tvalid_1's binary_logloss: 0.195871\n",
      "[60]\ttraining's binary_logloss: 0.163097\tvalid_1's binary_logloss: 0.194854\n",
      "[70]\ttraining's binary_logloss: 0.157448\tvalid_1's binary_logloss: 0.194079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.152255\tvalid_1's binary_logloss: 0.193268\n",
      "[90]\ttraining's binary_logloss: 0.147261\tvalid_1's binary_logloss: 0.193553\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.14984\tvalid_1's binary_logloss: 0.193162\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236358\tvalid_1's binary_logloss: 0.244887\n",
      "[20]\ttraining's binary_logloss: 0.204374\tvalid_1's binary_logloss: 0.219526\n",
      "[30]\ttraining's binary_logloss: 0.18857\tvalid_1's binary_logloss: 0.209571\n",
      "[40]\ttraining's binary_logloss: 0.177946\tvalid_1's binary_logloss: 0.205146\n",
      "[50]\ttraining's binary_logloss: 0.169524\tvalid_1's binary_logloss: 0.202657\n",
      "[60]\ttraining's binary_logloss: 0.162526\tvalid_1's binary_logloss: 0.201348\n",
      "[70]\ttraining's binary_logloss: 0.156627\tvalid_1's binary_logloss: 0.201561\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.161988\tvalid_1's binary_logloss: 0.201249\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234734\tvalid_1's binary_logloss: 0.241821\n",
      "[20]\ttraining's binary_logloss: 0.203451\tvalid_1's binary_logloss: 0.216797\n",
      "[30]\ttraining's binary_logloss: 0.18721\tvalid_1's binary_logloss: 0.207129\n",
      "[40]\ttraining's binary_logloss: 0.176973\tvalid_1's binary_logloss: 0.203319\n",
      "[50]\ttraining's binary_logloss: 0.167784\tvalid_1's binary_logloss: 0.200585\n",
      "[60]\ttraining's binary_logloss: 0.160867\tvalid_1's binary_logloss: 0.199973\n",
      "[70]\ttraining's binary_logloss: 0.154681\tvalid_1's binary_logloss: 0.200041\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.160288\tvalid_1's binary_logloss: 0.199935\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233928\tvalid_1's binary_logloss: 0.242656\n",
      "[20]\ttraining's binary_logloss: 0.204117\tvalid_1's binary_logloss: 0.219278\n",
      "[30]\ttraining's binary_logloss: 0.188127\tvalid_1's binary_logloss: 0.210083\n",
      "[40]\ttraining's binary_logloss: 0.176404\tvalid_1's binary_logloss: 0.204869\n",
      "[50]\ttraining's binary_logloss: 0.168756\tvalid_1's binary_logloss: 0.203547\n",
      "[60]\ttraining's binary_logloss: 0.162204\tvalid_1's binary_logloss: 0.202519\n",
      "[70]\ttraining's binary_logloss: 0.15623\tvalid_1's binary_logloss: 0.202588\n",
      "[80]\ttraining's binary_logloss: 0.150864\tvalid_1's binary_logloss: 0.202327\n",
      "[90]\ttraining's binary_logloss: 0.145743\tvalid_1's binary_logloss: 0.202217\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.14757\tvalid_1's binary_logloss: 0.201996\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235094\tvalid_1's binary_logloss: 0.245994\n",
      "[20]\ttraining's binary_logloss: 0.203683\tvalid_1's binary_logloss: 0.220287\n",
      "[30]\ttraining's binary_logloss: 0.187354\tvalid_1's binary_logloss: 0.21007\n",
      "[40]\ttraining's binary_logloss: 0.17637\tvalid_1's binary_logloss: 0.206629\n",
      "[50]\ttraining's binary_logloss: 0.168193\tvalid_1's binary_logloss: 0.205288\n",
      "[60]\ttraining's binary_logloss: 0.161035\tvalid_1's binary_logloss: 0.203796\n",
      "[70]\ttraining's binary_logloss: 0.15471\tvalid_1's binary_logloss: 0.203188\n",
      "[80]\ttraining's binary_logloss: 0.149392\tvalid_1's binary_logloss: 0.202951\n",
      "[90]\ttraining's binary_logloss: 0.14442\tvalid_1's binary_logloss: 0.20314\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.146307\tvalid_1's binary_logloss: 0.202755\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235955\tvalid_1's binary_logloss: 0.243571\n",
      "[20]\ttraining's binary_logloss: 0.204686\tvalid_1's binary_logloss: 0.219229\n",
      "[30]\ttraining's binary_logloss: 0.187775\tvalid_1's binary_logloss: 0.208483\n",
      "[40]\ttraining's binary_logloss: 0.177295\tvalid_1's binary_logloss: 0.204678\n",
      "[50]\ttraining's binary_logloss: 0.168842\tvalid_1's binary_logloss: 0.203172\n",
      "[60]\ttraining's binary_logloss: 0.161618\tvalid_1's binary_logloss: 0.201219\n",
      "[70]\ttraining's binary_logloss: 0.155437\tvalid_1's binary_logloss: 0.200107\n",
      "[80]\ttraining's binary_logloss: 0.150277\tvalid_1's binary_logloss: 0.199399\n",
      "[90]\ttraining's binary_logloss: 0.145612\tvalid_1's binary_logloss: 0.199814\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's binary_logloss: 0.14874\tvalid_1's binary_logloss: 0.199349\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234629\tvalid_1's binary_logloss: 0.243446\n",
      "[20]\ttraining's binary_logloss: 0.203433\tvalid_1's binary_logloss: 0.219303\n",
      "[30]\ttraining's binary_logloss: 0.187198\tvalid_1's binary_logloss: 0.212213\n",
      "[40]\ttraining's binary_logloss: 0.176692\tvalid_1's binary_logloss: 0.209624\n",
      "[50]\ttraining's binary_logloss: 0.168214\tvalid_1's binary_logloss: 0.207817\n",
      "[60]\ttraining's binary_logloss: 0.160986\tvalid_1's binary_logloss: 0.206493\n",
      "[70]\ttraining's binary_logloss: 0.155285\tvalid_1's binary_logloss: 0.206304\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.159717\tvalid_1's binary_logloss: 0.206107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234363\tvalid_1's binary_logloss: 0.241994\n",
      "[20]\ttraining's binary_logloss: 0.20451\tvalid_1's binary_logloss: 0.218583\n",
      "[30]\ttraining's binary_logloss: 0.18801\tvalid_1's binary_logloss: 0.208358\n",
      "[40]\ttraining's binary_logloss: 0.177094\tvalid_1's binary_logloss: 0.203883\n",
      "[50]\ttraining's binary_logloss: 0.168428\tvalid_1's binary_logloss: 0.201541\n",
      "[60]\ttraining's binary_logloss: 0.16156\tvalid_1's binary_logloss: 0.200412\n",
      "[70]\ttraining's binary_logloss: 0.155889\tvalid_1's binary_logloss: 0.200374\n",
      "[80]\ttraining's binary_logloss: 0.150873\tvalid_1's binary_logloss: 0.199749\n",
      "[90]\ttraining's binary_logloss: 0.146266\tvalid_1's binary_logloss: 0.200009\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.150873\tvalid_1's binary_logloss: 0.199749\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234148\tvalid_1's binary_logloss: 0.245233\n",
      "[20]\ttraining's binary_logloss: 0.201909\tvalid_1's binary_logloss: 0.218936\n",
      "[30]\ttraining's binary_logloss: 0.185333\tvalid_1's binary_logloss: 0.208716\n",
      "[40]\ttraining's binary_logloss: 0.175266\tvalid_1's binary_logloss: 0.204905\n",
      "[50]\ttraining's binary_logloss: 0.167264\tvalid_1's binary_logloss: 0.203596\n",
      "[60]\ttraining's binary_logloss: 0.160529\tvalid_1's binary_logloss: 0.203028\n",
      "[70]\ttraining's binary_logloss: 0.154741\tvalid_1's binary_logloss: 0.202533\n",
      "[80]\ttraining's binary_logloss: 0.149078\tvalid_1's binary_logloss: 0.2015\n",
      "[90]\ttraining's binary_logloss: 0.14389\tvalid_1's binary_logloss: 0.200571\n",
      "[100]\ttraining's binary_logloss: 0.139362\tvalid_1's binary_logloss: 0.200519\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's binary_logloss: 0.141416\tvalid_1's binary_logloss: 0.200204\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232364\tvalid_1's binary_logloss: 0.244478\n",
      "[20]\ttraining's binary_logloss: 0.201224\tvalid_1's binary_logloss: 0.220915\n",
      "[30]\ttraining's binary_logloss: 0.184299\tvalid_1's binary_logloss: 0.209695\n",
      "[40]\ttraining's binary_logloss: 0.174174\tvalid_1's binary_logloss: 0.206071\n",
      "[50]\ttraining's binary_logloss: 0.16607\tvalid_1's binary_logloss: 0.204387\n",
      "[60]\ttraining's binary_logloss: 0.159747\tvalid_1's binary_logloss: 0.204041\n",
      "[70]\ttraining's binary_logloss: 0.153987\tvalid_1's binary_logloss: 0.20393\n",
      "[80]\ttraining's binary_logloss: 0.148595\tvalid_1's binary_logloss: 0.203755\n",
      "[90]\ttraining's binary_logloss: 0.143967\tvalid_1's binary_logloss: 0.203874\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.148595\tvalid_1's binary_logloss: 0.203755\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233154\tvalid_1's binary_logloss: 0.243057\n",
      "[20]\ttraining's binary_logloss: 0.202879\tvalid_1's binary_logloss: 0.219965\n",
      "[30]\ttraining's binary_logloss: 0.185643\tvalid_1's binary_logloss: 0.209364\n",
      "[40]\ttraining's binary_logloss: 0.17509\tvalid_1's binary_logloss: 0.205196\n",
      "[50]\ttraining's binary_logloss: 0.167053\tvalid_1's binary_logloss: 0.203651\n",
      "[60]\ttraining's binary_logloss: 0.160665\tvalid_1's binary_logloss: 0.203\n",
      "[70]\ttraining's binary_logloss: 0.155098\tvalid_1's binary_logloss: 0.20211\n",
      "[80]\ttraining's binary_logloss: 0.149768\tvalid_1's binary_logloss: 0.202648\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.15443\tvalid_1's binary_logloss: 0.20209\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236839\tvalid_1's binary_logloss: 0.240381\n",
      "[20]\ttraining's binary_logloss: 0.206499\tvalid_1's binary_logloss: 0.214442\n",
      "[30]\ttraining's binary_logloss: 0.189634\tvalid_1's binary_logloss: 0.203176\n",
      "[40]\ttraining's binary_logloss: 0.178851\tvalid_1's binary_logloss: 0.197444\n",
      "[50]\ttraining's binary_logloss: 0.171107\tvalid_1's binary_logloss: 0.196009\n",
      "[60]\ttraining's binary_logloss: 0.164469\tvalid_1's binary_logloss: 0.194875\n",
      "[70]\ttraining's binary_logloss: 0.159125\tvalid_1's binary_logloss: 0.194522\n",
      "[80]\ttraining's binary_logloss: 0.153907\tvalid_1's binary_logloss: 0.193781\n",
      "[90]\ttraining's binary_logloss: 0.148202\tvalid_1's binary_logloss: 0.192933\n",
      "[100]\ttraining's binary_logloss: 0.143679\tvalid_1's binary_logloss: 0.193138\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.14783\tvalid_1's binary_logloss: 0.192823\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235544\tvalid_1's binary_logloss: 0.242042\n",
      "[20]\ttraining's binary_logloss: 0.204662\tvalid_1's binary_logloss: 0.216666\n",
      "[30]\ttraining's binary_logloss: 0.187903\tvalid_1's binary_logloss: 0.205633\n",
      "[40]\ttraining's binary_logloss: 0.177809\tvalid_1's binary_logloss: 0.2019\n",
      "[50]\ttraining's binary_logloss: 0.169376\tvalid_1's binary_logloss: 0.199869\n",
      "[60]\ttraining's binary_logloss: 0.162816\tvalid_1's binary_logloss: 0.200189\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.167971\tvalid_1's binary_logloss: 0.199847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23252\tvalid_1's binary_logloss: 0.244123\n",
      "[20]\ttraining's binary_logloss: 0.201563\tvalid_1's binary_logloss: 0.221144\n",
      "[30]\ttraining's binary_logloss: 0.186067\tvalid_1's binary_logloss: 0.212385\n",
      "[40]\ttraining's binary_logloss: 0.17503\tvalid_1's binary_logloss: 0.207673\n",
      "[50]\ttraining's binary_logloss: 0.166754\tvalid_1's binary_logloss: 0.205341\n",
      "[60]\ttraining's binary_logloss: 0.160089\tvalid_1's binary_logloss: 0.205358\n",
      "[70]\ttraining's binary_logloss: 0.154115\tvalid_1's binary_logloss: 0.2052\n",
      "[80]\ttraining's binary_logloss: 0.148885\tvalid_1's binary_logloss: 0.205049\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.150467\tvalid_1's binary_logloss: 0.2048\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234389\tvalid_1's binary_logloss: 0.241658\n",
      "[20]\ttraining's binary_logloss: 0.203592\tvalid_1's binary_logloss: 0.216963\n",
      "[30]\ttraining's binary_logloss: 0.186663\tvalid_1's binary_logloss: 0.206267\n",
      "[40]\ttraining's binary_logloss: 0.176495\tvalid_1's binary_logloss: 0.202322\n",
      "[50]\ttraining's binary_logloss: 0.168583\tvalid_1's binary_logloss: 0.200771\n",
      "[60]\ttraining's binary_logloss: 0.161682\tvalid_1's binary_logloss: 0.19975\n",
      "[70]\ttraining's binary_logloss: 0.156273\tvalid_1's binary_logloss: 0.199324\n",
      "[80]\ttraining's binary_logloss: 0.151154\tvalid_1's binary_logloss: 0.198796\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.152098\tvalid_1's binary_logloss: 0.198793\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233836\tvalid_1's binary_logloss: 0.245632\n",
      "[20]\ttraining's binary_logloss: 0.201665\tvalid_1's binary_logloss: 0.221287\n",
      "[30]\ttraining's binary_logloss: 0.185476\tvalid_1's binary_logloss: 0.211126\n",
      "[40]\ttraining's binary_logloss: 0.175157\tvalid_1's binary_logloss: 0.206451\n",
      "[50]\ttraining's binary_logloss: 0.167202\tvalid_1's binary_logloss: 0.204944\n",
      "[60]\ttraining's binary_logloss: 0.160577\tvalid_1's binary_logloss: 0.204384\n",
      "[70]\ttraining's binary_logloss: 0.154518\tvalid_1's binary_logloss: 0.204327\n",
      "[80]\ttraining's binary_logloss: 0.14951\tvalid_1's binary_logloss: 0.203834\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.150406\tvalid_1's binary_logloss: 0.203675\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233207\tvalid_1's binary_logloss: 0.246799\n",
      "[20]\ttraining's binary_logloss: 0.202307\tvalid_1's binary_logloss: 0.222875\n",
      "[30]\ttraining's binary_logloss: 0.185217\tvalid_1's binary_logloss: 0.213285\n",
      "[40]\ttraining's binary_logloss: 0.174446\tvalid_1's binary_logloss: 0.208965\n",
      "[50]\ttraining's binary_logloss: 0.166589\tvalid_1's binary_logloss: 0.207316\n",
      "[60]\ttraining's binary_logloss: 0.160115\tvalid_1's binary_logloss: 0.206882\n",
      "[70]\ttraining's binary_logloss: 0.153889\tvalid_1's binary_logloss: 0.207428\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.160115\tvalid_1's binary_logloss: 0.206882\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232726\tvalid_1's binary_logloss: 0.247131\n",
      "[20]\ttraining's binary_logloss: 0.201655\tvalid_1's binary_logloss: 0.223807\n",
      "[30]\ttraining's binary_logloss: 0.184518\tvalid_1's binary_logloss: 0.213417\n",
      "[40]\ttraining's binary_logloss: 0.173809\tvalid_1's binary_logloss: 0.209343\n",
      "[50]\ttraining's binary_logloss: 0.165585\tvalid_1's binary_logloss: 0.208194\n",
      "[60]\ttraining's binary_logloss: 0.159016\tvalid_1's binary_logloss: 0.20866\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.165585\tvalid_1's binary_logloss: 0.208194\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237112\tvalid_1's binary_logloss: 0.242243\n",
      "[20]\ttraining's binary_logloss: 0.205769\tvalid_1's binary_logloss: 0.215113\n",
      "[30]\ttraining's binary_logloss: 0.18915\tvalid_1's binary_logloss: 0.204022\n",
      "[40]\ttraining's binary_logloss: 0.178545\tvalid_1's binary_logloss: 0.199491\n",
      "[50]\ttraining's binary_logloss: 0.16993\tvalid_1's binary_logloss: 0.196617\n",
      "[60]\ttraining's binary_logloss: 0.163213\tvalid_1's binary_logloss: 0.195221\n",
      "[70]\ttraining's binary_logloss: 0.157489\tvalid_1's binary_logloss: 0.194336\n",
      "[80]\ttraining's binary_logloss: 0.151951\tvalid_1's binary_logloss: 0.193993\n",
      "[90]\ttraining's binary_logloss: 0.147313\tvalid_1's binary_logloss: 0.193839\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.147832\tvalid_1's binary_logloss: 0.193748\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23447\tvalid_1's binary_logloss: 0.243145\n",
      "[20]\ttraining's binary_logloss: 0.203684\tvalid_1's binary_logloss: 0.217242\n",
      "[30]\ttraining's binary_logloss: 0.187721\tvalid_1's binary_logloss: 0.206576\n",
      "[40]\ttraining's binary_logloss: 0.177002\tvalid_1's binary_logloss: 0.202052\n",
      "[50]\ttraining's binary_logloss: 0.168549\tvalid_1's binary_logloss: 0.199817\n",
      "[60]\ttraining's binary_logloss: 0.16187\tvalid_1's binary_logloss: 0.199152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\ttraining's binary_logloss: 0.156523\tvalid_1's binary_logloss: 0.19886\n",
      "[80]\ttraining's binary_logloss: 0.151271\tvalid_1's binary_logloss: 0.198862\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.152874\tvalid_1's binary_logloss: 0.198652\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232214\tvalid_1's binary_logloss: 0.246203\n",
      "[20]\ttraining's binary_logloss: 0.20114\tvalid_1's binary_logloss: 0.222997\n",
      "[30]\ttraining's binary_logloss: 0.184849\tvalid_1's binary_logloss: 0.214747\n",
      "[40]\ttraining's binary_logloss: 0.174164\tvalid_1's binary_logloss: 0.210707\n",
      "[50]\ttraining's binary_logloss: 0.166099\tvalid_1's binary_logloss: 0.209271\n",
      "[60]\ttraining's binary_logloss: 0.159232\tvalid_1's binary_logloss: 0.208339\n",
      "[70]\ttraining's binary_logloss: 0.15319\tvalid_1's binary_logloss: 0.20865\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.157992\tvalid_1's binary_logloss: 0.208247\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233444\tvalid_1's binary_logloss: 0.242502\n",
      "[20]\ttraining's binary_logloss: 0.203032\tvalid_1's binary_logloss: 0.219137\n",
      "[30]\ttraining's binary_logloss: 0.185928\tvalid_1's binary_logloss: 0.208863\n",
      "[40]\ttraining's binary_logloss: 0.175133\tvalid_1's binary_logloss: 0.204412\n",
      "[50]\ttraining's binary_logloss: 0.166337\tvalid_1's binary_logloss: 0.202812\n",
      "[60]\ttraining's binary_logloss: 0.158866\tvalid_1's binary_logloss: 0.202331\n",
      "[70]\ttraining's binary_logloss: 0.152781\tvalid_1's binary_logloss: 0.202339\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.154347\tvalid_1's binary_logloss: 0.202103\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234149\tvalid_1's binary_logloss: 0.24422\n",
      "[20]\ttraining's binary_logloss: 0.203226\tvalid_1's binary_logloss: 0.220887\n",
      "[30]\ttraining's binary_logloss: 0.186149\tvalid_1's binary_logloss: 0.210343\n",
      "[40]\ttraining's binary_logloss: 0.175451\tvalid_1's binary_logloss: 0.207408\n",
      "[50]\ttraining's binary_logloss: 0.16726\tvalid_1's binary_logloss: 0.2057\n",
      "[60]\ttraining's binary_logloss: 0.160768\tvalid_1's binary_logloss: 0.205529\n",
      "[70]\ttraining's binary_logloss: 0.154421\tvalid_1's binary_logloss: 0.204405\n",
      "[80]\ttraining's binary_logloss: 0.149431\tvalid_1's binary_logloss: 0.204124\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.150735\tvalid_1's binary_logloss: 0.204056\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234032\tvalid_1's binary_logloss: 0.245475\n",
      "[20]\ttraining's binary_logloss: 0.202326\tvalid_1's binary_logloss: 0.219316\n",
      "[30]\ttraining's binary_logloss: 0.185885\tvalid_1's binary_logloss: 0.210021\n",
      "[40]\ttraining's binary_logloss: 0.175189\tvalid_1's binary_logloss: 0.204637\n",
      "[50]\ttraining's binary_logloss: 0.167414\tvalid_1's binary_logloss: 0.203147\n",
      "[60]\ttraining's binary_logloss: 0.160425\tvalid_1's binary_logloss: 0.201997\n",
      "[70]\ttraining's binary_logloss: 0.154441\tvalid_1's binary_logloss: 0.200786\n",
      "[80]\ttraining's binary_logloss: 0.149121\tvalid_1's binary_logloss: 0.19998\n",
      "[90]\ttraining's binary_logloss: 0.143822\tvalid_1's binary_logloss: 0.200001\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's binary_logloss: 0.147523\tvalid_1's binary_logloss: 0.199791\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234498\tvalid_1's binary_logloss: 0.2448\n",
      "[20]\ttraining's binary_logloss: 0.203505\tvalid_1's binary_logloss: 0.220908\n",
      "[30]\ttraining's binary_logloss: 0.187474\tvalid_1's binary_logloss: 0.210325\n",
      "[40]\ttraining's binary_logloss: 0.17653\tvalid_1's binary_logloss: 0.205653\n",
      "[50]\ttraining's binary_logloss: 0.167923\tvalid_1's binary_logloss: 0.202886\n",
      "[60]\ttraining's binary_logloss: 0.16056\tvalid_1's binary_logloss: 0.201699\n",
      "[70]\ttraining's binary_logloss: 0.154579\tvalid_1's binary_logloss: 0.201073\n",
      "[80]\ttraining's binary_logloss: 0.149583\tvalid_1's binary_logloss: 0.200831\n",
      "[90]\ttraining's binary_logloss: 0.144686\tvalid_1's binary_logloss: 0.200623\n",
      "[100]\ttraining's binary_logloss: 0.139871\tvalid_1's binary_logloss: 0.200537\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.144254\tvalid_1's binary_logloss: 0.200425\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234311\tvalid_1's binary_logloss: 0.246281\n",
      "[20]\ttraining's binary_logloss: 0.202027\tvalid_1's binary_logloss: 0.220062\n",
      "[30]\ttraining's binary_logloss: 0.185615\tvalid_1's binary_logloss: 0.209991\n",
      "[40]\ttraining's binary_logloss: 0.174215\tvalid_1's binary_logloss: 0.205196\n",
      "[50]\ttraining's binary_logloss: 0.166453\tvalid_1's binary_logloss: 0.203782\n",
      "[60]\ttraining's binary_logloss: 0.159466\tvalid_1's binary_logloss: 0.202261\n",
      "[70]\ttraining's binary_logloss: 0.15372\tvalid_1's binary_logloss: 0.201634\n",
      "[80]\ttraining's binary_logloss: 0.148405\tvalid_1's binary_logloss: 0.20207\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.15372\tvalid_1's binary_logloss: 0.201634\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233534\tvalid_1's binary_logloss: 0.244621\n",
      "[20]\ttraining's binary_logloss: 0.201667\tvalid_1's binary_logloss: 0.219854\n",
      "[30]\ttraining's binary_logloss: 0.186043\tvalid_1's binary_logloss: 0.211226\n",
      "[40]\ttraining's binary_logloss: 0.175039\tvalid_1's binary_logloss: 0.206218\n",
      "[50]\ttraining's binary_logloss: 0.166868\tvalid_1's binary_logloss: 0.203968\n",
      "[60]\ttraining's binary_logloss: 0.160252\tvalid_1's binary_logloss: 0.203458\n",
      "[70]\ttraining's binary_logloss: 0.154397\tvalid_1's binary_logloss: 0.203212\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.15775\tvalid_1's binary_logloss: 0.20311\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237038\tvalid_1's binary_logloss: 0.245148\n",
      "[20]\ttraining's binary_logloss: 0.205998\tvalid_1's binary_logloss: 0.219779\n",
      "[30]\ttraining's binary_logloss: 0.190004\tvalid_1's binary_logloss: 0.209913\n",
      "[40]\ttraining's binary_logloss: 0.178153\tvalid_1's binary_logloss: 0.205225\n",
      "[50]\ttraining's binary_logloss: 0.169584\tvalid_1's binary_logloss: 0.203378\n",
      "[60]\ttraining's binary_logloss: 0.162741\tvalid_1's binary_logloss: 0.203037\n",
      "[70]\ttraining's binary_logloss: 0.157082\tvalid_1's binary_logloss: 0.202968\n",
      "[80]\ttraining's binary_logloss: 0.151323\tvalid_1's binary_logloss: 0.202497\n",
      "[90]\ttraining's binary_logloss: 0.146264\tvalid_1's binary_logloss: 0.202227\n",
      "[100]\ttraining's binary_logloss: 0.141907\tvalid_1's binary_logloss: 0.202423\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.145662\tvalid_1's binary_logloss: 0.202121\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234204\tvalid_1's binary_logloss: 0.240948\n",
      "[20]\ttraining's binary_logloss: 0.203484\tvalid_1's binary_logloss: 0.215451\n",
      "[30]\ttraining's binary_logloss: 0.187514\tvalid_1's binary_logloss: 0.205616\n",
      "[40]\ttraining's binary_logloss: 0.177235\tvalid_1's binary_logloss: 0.201098\n",
      "[50]\ttraining's binary_logloss: 0.168992\tvalid_1's binary_logloss: 0.199756\n",
      "[60]\ttraining's binary_logloss: 0.162251\tvalid_1's binary_logloss: 0.199251\n",
      "[70]\ttraining's binary_logloss: 0.156691\tvalid_1's binary_logloss: 0.19915\n",
      "[80]\ttraining's binary_logloss: 0.1514\tvalid_1's binary_logloss: 0.198987\n",
      "[90]\ttraining's binary_logloss: 0.146417\tvalid_1's binary_logloss: 0.198963\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.149036\tvalid_1's binary_logloss: 0.198604\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235606\tvalid_1's binary_logloss: 0.245152\n",
      "[20]\ttraining's binary_logloss: 0.204726\tvalid_1's binary_logloss: 0.221002\n",
      "[30]\ttraining's binary_logloss: 0.187011\tvalid_1's binary_logloss: 0.20855\n",
      "[40]\ttraining's binary_logloss: 0.176417\tvalid_1's binary_logloss: 0.204092\n",
      "[50]\ttraining's binary_logloss: 0.168671\tvalid_1's binary_logloss: 0.20295\n",
      "[60]\ttraining's binary_logloss: 0.161876\tvalid_1's binary_logloss: 0.201326\n",
      "[70]\ttraining's binary_logloss: 0.155808\tvalid_1's binary_logloss: 0.201081\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.156982\tvalid_1's binary_logloss: 0.200991\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234659\tvalid_1's binary_logloss: 0.244294\n",
      "[20]\ttraining's binary_logloss: 0.203199\tvalid_1's binary_logloss: 0.218013\n",
      "[30]\ttraining's binary_logloss: 0.187216\tvalid_1's binary_logloss: 0.20767\n",
      "[40]\ttraining's binary_logloss: 0.177547\tvalid_1's binary_logloss: 0.203756\n",
      "[50]\ttraining's binary_logloss: 0.16921\tvalid_1's binary_logloss: 0.201703\n",
      "[60]\ttraining's binary_logloss: 0.162187\tvalid_1's binary_logloss: 0.200507\n",
      "[70]\ttraining's binary_logloss: 0.15621\tvalid_1's binary_logloss: 0.199494\n",
      "[80]\ttraining's binary_logloss: 0.151011\tvalid_1's binary_logloss: 0.199149\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.153052\tvalid_1's binary_logloss: 0.199097\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237036\tvalid_1's binary_logloss: 0.242165\n",
      "[20]\ttraining's binary_logloss: 0.205324\tvalid_1's binary_logloss: 0.21623\n",
      "[30]\ttraining's binary_logloss: 0.188677\tvalid_1's binary_logloss: 0.204494\n",
      "[40]\ttraining's binary_logloss: 0.178674\tvalid_1's binary_logloss: 0.200711\n",
      "[50]\ttraining's binary_logloss: 0.170756\tvalid_1's binary_logloss: 0.198681\n",
      "[60]\ttraining's binary_logloss: 0.164076\tvalid_1's binary_logloss: 0.19779\n",
      "[70]\ttraining's binary_logloss: 0.158323\tvalid_1's binary_logloss: 0.19706\n",
      "[80]\ttraining's binary_logloss: 0.153011\tvalid_1's binary_logloss: 0.197131\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.153972\tvalid_1's binary_logloss: 0.196885\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's binary_logloss: 0.235279\tvalid_1's binary_logloss: 0.243674\n",
      "[20]\ttraining's binary_logloss: 0.204846\tvalid_1's binary_logloss: 0.217979\n",
      "[30]\ttraining's binary_logloss: 0.188329\tvalid_1's binary_logloss: 0.205869\n",
      "[40]\ttraining's binary_logloss: 0.177678\tvalid_1's binary_logloss: 0.201118\n",
      "[50]\ttraining's binary_logloss: 0.16958\tvalid_1's binary_logloss: 0.199403\n",
      "[60]\ttraining's binary_logloss: 0.163084\tvalid_1's binary_logloss: 0.199306\n",
      "[70]\ttraining's binary_logloss: 0.157077\tvalid_1's binary_logloss: 0.198868\n",
      "[80]\ttraining's binary_logloss: 0.151553\tvalid_1's binary_logloss: 0.198317\n",
      "[90]\ttraining's binary_logloss: 0.145874\tvalid_1's binary_logloss: 0.198568\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.151553\tvalid_1's binary_logloss: 0.198317\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23597\tvalid_1's binary_logloss: 0.24484\n",
      "[20]\ttraining's binary_logloss: 0.205159\tvalid_1's binary_logloss: 0.219096\n",
      "[30]\ttraining's binary_logloss: 0.1878\tvalid_1's binary_logloss: 0.205604\n",
      "[40]\ttraining's binary_logloss: 0.17689\tvalid_1's binary_logloss: 0.200146\n",
      "[50]\ttraining's binary_logloss: 0.168933\tvalid_1's binary_logloss: 0.198434\n",
      "[60]\ttraining's binary_logloss: 0.162319\tvalid_1's binary_logloss: 0.197852\n",
      "[70]\ttraining's binary_logloss: 0.156145\tvalid_1's binary_logloss: 0.197248\n",
      "[80]\ttraining's binary_logloss: 0.150211\tvalid_1's binary_logloss: 0.196184\n",
      "[90]\ttraining's binary_logloss: 0.145095\tvalid_1's binary_logloss: 0.196087\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.149162\tvalid_1's binary_logloss: 0.195953\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235048\tvalid_1's binary_logloss: 0.241985\n",
      "[20]\ttraining's binary_logloss: 0.203956\tvalid_1's binary_logloss: 0.216286\n",
      "[30]\ttraining's binary_logloss: 0.187268\tvalid_1's binary_logloss: 0.20502\n",
      "[40]\ttraining's binary_logloss: 0.177153\tvalid_1's binary_logloss: 0.200918\n",
      "[50]\ttraining's binary_logloss: 0.168976\tvalid_1's binary_logloss: 0.199285\n",
      "[60]\ttraining's binary_logloss: 0.162286\tvalid_1's binary_logloss: 0.198838\n",
      "[70]\ttraining's binary_logloss: 0.156156\tvalid_1's binary_logloss: 0.198577\n",
      "[80]\ttraining's binary_logloss: 0.150933\tvalid_1's binary_logloss: 0.198127\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.151834\tvalid_1's binary_logloss: 0.197987\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233703\tvalid_1's binary_logloss: 0.237415\n",
      "[20]\ttraining's binary_logloss: 0.203708\tvalid_1's binary_logloss: 0.213997\n",
      "[30]\ttraining's binary_logloss: 0.187962\tvalid_1's binary_logloss: 0.204581\n",
      "[40]\ttraining's binary_logloss: 0.177731\tvalid_1's binary_logloss: 0.200651\n",
      "[50]\ttraining's binary_logloss: 0.169418\tvalid_1's binary_logloss: 0.199045\n",
      "[60]\ttraining's binary_logloss: 0.162685\tvalid_1's binary_logloss: 0.198129\n",
      "[70]\ttraining's binary_logloss: 0.156875\tvalid_1's binary_logloss: 0.19777\n",
      "[80]\ttraining's binary_logloss: 0.151376\tvalid_1's binary_logloss: 0.197031\n",
      "[90]\ttraining's binary_logloss: 0.146507\tvalid_1's binary_logloss: 0.197311\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.151376\tvalid_1's binary_logloss: 0.197031\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237853\tvalid_1's binary_logloss: 0.240446\n",
      "[20]\ttraining's binary_logloss: 0.206689\tvalid_1's binary_logloss: 0.214764\n",
      "[30]\ttraining's binary_logloss: 0.189788\tvalid_1's binary_logloss: 0.203653\n",
      "[40]\ttraining's binary_logloss: 0.179268\tvalid_1's binary_logloss: 0.199632\n",
      "[50]\ttraining's binary_logloss: 0.170602\tvalid_1's binary_logloss: 0.197639\n",
      "[60]\ttraining's binary_logloss: 0.16357\tvalid_1's binary_logloss: 0.196391\n",
      "[70]\ttraining's binary_logloss: 0.157594\tvalid_1's binary_logloss: 0.195794\n",
      "[80]\ttraining's binary_logloss: 0.152428\tvalid_1's binary_logloss: 0.195893\n",
      "[90]\ttraining's binary_logloss: 0.14744\tvalid_1's binary_logloss: 0.195689\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's binary_logloss: 0.148797\tvalid_1's binary_logloss: 0.195566\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232498\tvalid_1's binary_logloss: 0.24456\n",
      "[20]\ttraining's binary_logloss: 0.201482\tvalid_1's binary_logloss: 0.220281\n",
      "[30]\ttraining's binary_logloss: 0.184453\tvalid_1's binary_logloss: 0.210499\n",
      "[40]\ttraining's binary_logloss: 0.173625\tvalid_1's binary_logloss: 0.20716\n",
      "[50]\ttraining's binary_logloss: 0.165732\tvalid_1's binary_logloss: 0.20648\n",
      "[60]\ttraining's binary_logloss: 0.159385\tvalid_1's binary_logloss: 0.205986\n",
      "[70]\ttraining's binary_logloss: 0.15347\tvalid_1's binary_logloss: 0.20564\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.154141\tvalid_1's binary_logloss: 0.205579\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23513\tvalid_1's binary_logloss: 0.242885\n",
      "[20]\ttraining's binary_logloss: 0.204528\tvalid_1's binary_logloss: 0.219618\n",
      "[30]\ttraining's binary_logloss: 0.188357\tvalid_1's binary_logloss: 0.209592\n",
      "[40]\ttraining's binary_logloss: 0.17694\tvalid_1's binary_logloss: 0.204846\n",
      "[50]\ttraining's binary_logloss: 0.168889\tvalid_1's binary_logloss: 0.204073\n",
      "[60]\ttraining's binary_logloss: 0.161931\tvalid_1's binary_logloss: 0.202951\n",
      "[70]\ttraining's binary_logloss: 0.156234\tvalid_1's binary_logloss: 0.202715\n",
      "[80]\ttraining's binary_logloss: 0.151416\tvalid_1's binary_logloss: 0.202661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttraining's binary_logloss: 0.146744\tvalid_1's binary_logloss: 0.20319\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.150332\tvalid_1's binary_logloss: 0.202201\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234817\tvalid_1's binary_logloss: 0.244599\n",
      "[20]\ttraining's binary_logloss: 0.203455\tvalid_1's binary_logloss: 0.220712\n",
      "[30]\ttraining's binary_logloss: 0.185589\tvalid_1's binary_logloss: 0.20946\n",
      "[40]\ttraining's binary_logloss: 0.175405\tvalid_1's binary_logloss: 0.206047\n",
      "[50]\ttraining's binary_logloss: 0.166763\tvalid_1's binary_logloss: 0.204255\n",
      "[60]\ttraining's binary_logloss: 0.15968\tvalid_1's binary_logloss: 0.203269\n",
      "[70]\ttraining's binary_logloss: 0.153948\tvalid_1's binary_logloss: 0.202762\n",
      "[80]\ttraining's binary_logloss: 0.148892\tvalid_1's binary_logloss: 0.202727\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.152444\tvalid_1's binary_logloss: 0.20246\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237561\tvalid_1's binary_logloss: 0.241997\n",
      "[20]\ttraining's binary_logloss: 0.204704\tvalid_1's binary_logloss: 0.214525\n",
      "[30]\ttraining's binary_logloss: 0.187559\tvalid_1's binary_logloss: 0.20363\n",
      "[40]\ttraining's binary_logloss: 0.177356\tvalid_1's binary_logloss: 0.199518\n",
      "[50]\ttraining's binary_logloss: 0.16954\tvalid_1's binary_logloss: 0.197893\n",
      "[60]\ttraining's binary_logloss: 0.162302\tvalid_1's binary_logloss: 0.196766\n",
      "[70]\ttraining's binary_logloss: 0.15669\tvalid_1's binary_logloss: 0.196682\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.16162\tvalid_1's binary_logloss: 0.196628\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.231502\tvalid_1's binary_logloss: 0.249195\n",
      "[20]\ttraining's binary_logloss: 0.200781\tvalid_1's binary_logloss: 0.227264\n",
      "[30]\ttraining's binary_logloss: 0.184159\tvalid_1's binary_logloss: 0.218164\n",
      "[40]\ttraining's binary_logloss: 0.173345\tvalid_1's binary_logloss: 0.21437\n",
      "[50]\ttraining's binary_logloss: 0.164494\tvalid_1's binary_logloss: 0.21144\n",
      "[60]\ttraining's binary_logloss: 0.158111\tvalid_1's binary_logloss: 0.211271\n",
      "[70]\ttraining's binary_logloss: 0.152283\tvalid_1's binary_logloss: 0.21143\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.155322\tvalid_1's binary_logloss: 0.211035\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236836\tvalid_1's binary_logloss: 0.24028\n",
      "[20]\ttraining's binary_logloss: 0.204931\tvalid_1's binary_logloss: 0.214215\n",
      "[30]\ttraining's binary_logloss: 0.188721\tvalid_1's binary_logloss: 0.203616\n",
      "[40]\ttraining's binary_logloss: 0.177768\tvalid_1's binary_logloss: 0.198519\n",
      "[50]\ttraining's binary_logloss: 0.170409\tvalid_1's binary_logloss: 0.196837\n",
      "[60]\ttraining's binary_logloss: 0.163499\tvalid_1's binary_logloss: 0.195831\n",
      "[70]\ttraining's binary_logloss: 0.157735\tvalid_1's binary_logloss: 0.195379\n",
      "[80]\ttraining's binary_logloss: 0.152441\tvalid_1's binary_logloss: 0.194905\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.153324\tvalid_1's binary_logloss: 0.194766\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235832\tvalid_1's binary_logloss: 0.239345\n",
      "[20]\ttraining's binary_logloss: 0.205398\tvalid_1's binary_logloss: 0.215714\n",
      "[30]\ttraining's binary_logloss: 0.187551\tvalid_1's binary_logloss: 0.204502\n",
      "[40]\ttraining's binary_logloss: 0.177272\tvalid_1's binary_logloss: 0.200613\n",
      "[50]\ttraining's binary_logloss: 0.168952\tvalid_1's binary_logloss: 0.198927\n",
      "[60]\ttraining's binary_logloss: 0.162136\tvalid_1's binary_logloss: 0.198391\n",
      "[70]\ttraining's binary_logloss: 0.156448\tvalid_1's binary_logloss: 0.198323\n",
      "[80]\ttraining's binary_logloss: 0.151035\tvalid_1's binary_logloss: 0.198104\n",
      "[90]\ttraining's binary_logloss: 0.146312\tvalid_1's binary_logloss: 0.197576\n",
      "[100]\ttraining's binary_logloss: 0.141363\tvalid_1's binary_logloss: 0.197175\n",
      "[110]\ttraining's binary_logloss: 0.136959\tvalid_1's binary_logloss: 0.196968\n",
      "[120]\ttraining's binary_logloss: 0.132891\tvalid_1's binary_logloss: 0.197197\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.136524\tvalid_1's binary_logloss: 0.196892\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236326\tvalid_1's binary_logloss: 0.238325\n",
      "[20]\ttraining's binary_logloss: 0.205963\tvalid_1's binary_logloss: 0.21314\n",
      "[30]\ttraining's binary_logloss: 0.188841\tvalid_1's binary_logloss: 0.20211\n",
      "[40]\ttraining's binary_logloss: 0.178587\tvalid_1's binary_logloss: 0.197726\n",
      "[50]\ttraining's binary_logloss: 0.170269\tvalid_1's binary_logloss: 0.19573\n",
      "[60]\ttraining's binary_logloss: 0.163164\tvalid_1's binary_logloss: 0.194758\n",
      "[70]\ttraining's binary_logloss: 0.157852\tvalid_1's binary_logloss: 0.194261\n",
      "[80]\ttraining's binary_logloss: 0.15239\tvalid_1's binary_logloss: 0.193845\n",
      "[90]\ttraining's binary_logloss: 0.147187\tvalid_1's binary_logloss: 0.193229\n",
      "[100]\ttraining's binary_logloss: 0.14249\tvalid_1's binary_logloss: 0.192746\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.142936\tvalid_1's binary_logloss: 0.192674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235739\tvalid_1's binary_logloss: 0.240243\n",
      "[20]\ttraining's binary_logloss: 0.205852\tvalid_1's binary_logloss: 0.214824\n",
      "[30]\ttraining's binary_logloss: 0.189152\tvalid_1's binary_logloss: 0.203247\n",
      "[40]\ttraining's binary_logloss: 0.178494\tvalid_1's binary_logloss: 0.199016\n",
      "[50]\ttraining's binary_logloss: 0.170153\tvalid_1's binary_logloss: 0.196588\n",
      "[60]\ttraining's binary_logloss: 0.163002\tvalid_1's binary_logloss: 0.195601\n",
      "[70]\ttraining's binary_logloss: 0.156841\tvalid_1's binary_logloss: 0.195293\n",
      "[80]\ttraining's binary_logloss: 0.15157\tvalid_1's binary_logloss: 0.19508\n",
      "[90]\ttraining's binary_logloss: 0.146679\tvalid_1's binary_logloss: 0.19466\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.147078\tvalid_1's binary_logloss: 0.194534\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235321\tvalid_1's binary_logloss: 0.244739\n",
      "[20]\ttraining's binary_logloss: 0.204253\tvalid_1's binary_logloss: 0.220003\n",
      "[30]\ttraining's binary_logloss: 0.188738\tvalid_1's binary_logloss: 0.209749\n",
      "[40]\ttraining's binary_logloss: 0.178492\tvalid_1's binary_logloss: 0.206342\n",
      "[50]\ttraining's binary_logloss: 0.169889\tvalid_1's binary_logloss: 0.203967\n",
      "[60]\ttraining's binary_logloss: 0.16346\tvalid_1's binary_logloss: 0.202841\n",
      "[70]\ttraining's binary_logloss: 0.157594\tvalid_1's binary_logloss: 0.20216\n",
      "[80]\ttraining's binary_logloss: 0.152457\tvalid_1's binary_logloss: 0.202204\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.157594\tvalid_1's binary_logloss: 0.20216\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237084\tvalid_1's binary_logloss: 0.241043\n",
      "[20]\ttraining's binary_logloss: 0.206197\tvalid_1's binary_logloss: 0.216921\n",
      "[30]\ttraining's binary_logloss: 0.188383\tvalid_1's binary_logloss: 0.205372\n",
      "[40]\ttraining's binary_logloss: 0.177347\tvalid_1's binary_logloss: 0.199551\n",
      "[50]\ttraining's binary_logloss: 0.168918\tvalid_1's binary_logloss: 0.197961\n",
      "[60]\ttraining's binary_logloss: 0.161758\tvalid_1's binary_logloss: 0.196592\n",
      "[70]\ttraining's binary_logloss: 0.155767\tvalid_1's binary_logloss: 0.196132\n",
      "[80]\ttraining's binary_logloss: 0.150319\tvalid_1's binary_logloss: 0.195808\n",
      "[90]\ttraining's binary_logloss: 0.145671\tvalid_1's binary_logloss: 0.195662\n",
      "[100]\ttraining's binary_logloss: 0.141149\tvalid_1's binary_logloss: 0.195533\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's binary_logloss: 0.142894\tvalid_1's binary_logloss: 0.195272\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234774\tvalid_1's binary_logloss: 0.242778\n",
      "[20]\ttraining's binary_logloss: 0.203829\tvalid_1's binary_logloss: 0.219359\n",
      "[30]\ttraining's binary_logloss: 0.186709\tvalid_1's binary_logloss: 0.208492\n",
      "[40]\ttraining's binary_logloss: 0.176462\tvalid_1's binary_logloss: 0.20503\n",
      "[50]\ttraining's binary_logloss: 0.168207\tvalid_1's binary_logloss: 0.20313\n",
      "[60]\ttraining's binary_logloss: 0.161338\tvalid_1's binary_logloss: 0.202304\n",
      "[70]\ttraining's binary_logloss: 0.155529\tvalid_1's binary_logloss: 0.201879\n",
      "[80]\ttraining's binary_logloss: 0.149954\tvalid_1's binary_logloss: 0.201269\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.15042\tvalid_1's binary_logloss: 0.201195\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233609\tvalid_1's binary_logloss: 0.246807\n",
      "[20]\ttraining's binary_logloss: 0.201291\tvalid_1's binary_logloss: 0.22133\n",
      "[30]\ttraining's binary_logloss: 0.184969\tvalid_1's binary_logloss: 0.211977\n",
      "[40]\ttraining's binary_logloss: 0.174452\tvalid_1's binary_logloss: 0.209092\n",
      "[50]\ttraining's binary_logloss: 0.166321\tvalid_1's binary_logloss: 0.207588\n",
      "[60]\ttraining's binary_logloss: 0.15947\tvalid_1's binary_logloss: 0.206085\n",
      "[70]\ttraining's binary_logloss: 0.153861\tvalid_1's binary_logloss: 0.205818\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.157719\tvalid_1's binary_logloss: 0.205782\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235635\tvalid_1's binary_logloss: 0.239608\n",
      "[20]\ttraining's binary_logloss: 0.204643\tvalid_1's binary_logloss: 0.214597\n",
      "[30]\ttraining's binary_logloss: 0.188318\tvalid_1's binary_logloss: 0.203921\n",
      "[40]\ttraining's binary_logloss: 0.177846\tvalid_1's binary_logloss: 0.199149\n",
      "[50]\ttraining's binary_logloss: 0.170007\tvalid_1's binary_logloss: 0.197101\n",
      "[60]\ttraining's binary_logloss: 0.16339\tvalid_1's binary_logloss: 0.19643\n",
      "[70]\ttraining's binary_logloss: 0.157748\tvalid_1's binary_logloss: 0.196511\n",
      "[80]\ttraining's binary_logloss: 0.151749\tvalid_1's binary_logloss: 0.195666\n",
      "[90]\ttraining's binary_logloss: 0.14672\tvalid_1's binary_logloss: 0.196009\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.151749\tvalid_1's binary_logloss: 0.195666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1018\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236012\tvalid_1's binary_logloss: 0.243869\n",
      "[20]\ttraining's binary_logloss: 0.203172\tvalid_1's binary_logloss: 0.216735\n",
      "[30]\ttraining's binary_logloss: 0.187135\tvalid_1's binary_logloss: 0.205949\n",
      "[40]\ttraining's binary_logloss: 0.177085\tvalid_1's binary_logloss: 0.202236\n",
      "[50]\ttraining's binary_logloss: 0.169053\tvalid_1's binary_logloss: 0.201075\n",
      "[60]\ttraining's binary_logloss: 0.161894\tvalid_1's binary_logloss: 0.199866\n",
      "[70]\ttraining's binary_logloss: 0.155915\tvalid_1's binary_logloss: 0.199563\n",
      "[80]\ttraining's binary_logloss: 0.150243\tvalid_1's binary_logloss: 0.198703\n",
      "[90]\ttraining's binary_logloss: 0.145301\tvalid_1's binary_logloss: 0.198958\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.150243\tvalid_1's binary_logloss: 0.198703\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233881\tvalid_1's binary_logloss: 0.245015\n",
      "[20]\ttraining's binary_logloss: 0.20179\tvalid_1's binary_logloss: 0.220296\n",
      "[30]\ttraining's binary_logloss: 0.184777\tvalid_1's binary_logloss: 0.210496\n",
      "[40]\ttraining's binary_logloss: 0.174854\tvalid_1's binary_logloss: 0.206853\n",
      "[50]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.20499\n",
      "[60]\ttraining's binary_logloss: 0.160342\tvalid_1's binary_logloss: 0.20489\n",
      "[70]\ttraining's binary_logloss: 0.154152\tvalid_1's binary_logloss: 0.20423\n",
      "[80]\ttraining's binary_logloss: 0.149057\tvalid_1's binary_logloss: 0.203825\n",
      "[90]\ttraining's binary_logloss: 0.144034\tvalid_1's binary_logloss: 0.203879\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.149057\tvalid_1's binary_logloss: 0.203825\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235319\tvalid_1's binary_logloss: 0.243525\n",
      "[20]\ttraining's binary_logloss: 0.202525\tvalid_1's binary_logloss: 0.21912\n",
      "[30]\ttraining's binary_logloss: 0.186343\tvalid_1's binary_logloss: 0.2098\n",
      "[40]\ttraining's binary_logloss: 0.175646\tvalid_1's binary_logloss: 0.206104\n",
      "[50]\ttraining's binary_logloss: 0.168115\tvalid_1's binary_logloss: 0.205149\n",
      "[60]\ttraining's binary_logloss: 0.161529\tvalid_1's binary_logloss: 0.204999\n",
      "[70]\ttraining's binary_logloss: 0.155179\tvalid_1's binary_logloss: 0.204591\n",
      "[80]\ttraining's binary_logloss: 0.149616\tvalid_1's binary_logloss: 0.204005\n",
      "[90]\ttraining's binary_logloss: 0.144856\tvalid_1's binary_logloss: 0.203968\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.146502\tvalid_1's binary_logloss: 0.203593\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237872\tvalid_1's binary_logloss: 0.238333\n",
      "[20]\ttraining's binary_logloss: 0.20689\tvalid_1's binary_logloss: 0.211297\n",
      "[30]\ttraining's binary_logloss: 0.190138\tvalid_1's binary_logloss: 0.200092\n",
      "[40]\ttraining's binary_logloss: 0.179861\tvalid_1's binary_logloss: 0.195539\n",
      "[50]\ttraining's binary_logloss: 0.171504\tvalid_1's binary_logloss: 0.193375\n",
      "[60]\ttraining's binary_logloss: 0.164696\tvalid_1's binary_logloss: 0.192438\n",
      "[70]\ttraining's binary_logloss: 0.158458\tvalid_1's binary_logloss: 0.191246\n",
      "[80]\ttraining's binary_logloss: 0.153064\tvalid_1's binary_logloss: 0.19141\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.155781\tvalid_1's binary_logloss: 0.191116\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233526\tvalid_1's binary_logloss: 0.244454\n",
      "[20]\ttraining's binary_logloss: 0.20285\tvalid_1's binary_logloss: 0.222781\n",
      "[30]\ttraining's binary_logloss: 0.185949\tvalid_1's binary_logloss: 0.21311\n",
      "[40]\ttraining's binary_logloss: 0.174957\tvalid_1's binary_logloss: 0.209418\n",
      "[50]\ttraining's binary_logloss: 0.166538\tvalid_1's binary_logloss: 0.207357\n",
      "[60]\ttraining's binary_logloss: 0.160157\tvalid_1's binary_logloss: 0.207804\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.165267\tvalid_1's binary_logloss: 0.207356\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234885\tvalid_1's binary_logloss: 0.241171\n",
      "[20]\ttraining's binary_logloss: 0.204011\tvalid_1's binary_logloss: 0.217173\n",
      "[30]\ttraining's binary_logloss: 0.187846\tvalid_1's binary_logloss: 0.206942\n",
      "[40]\ttraining's binary_logloss: 0.177006\tvalid_1's binary_logloss: 0.202729\n",
      "[50]\ttraining's binary_logloss: 0.169296\tvalid_1's binary_logloss: 0.200951\n",
      "[60]\ttraining's binary_logloss: 0.162647\tvalid_1's binary_logloss: 0.200663\n",
      "[70]\ttraining's binary_logloss: 0.15651\tvalid_1's binary_logloss: 0.200611\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's binary_logloss: 0.158919\tvalid_1's binary_logloss: 0.200464\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234328\tvalid_1's binary_logloss: 0.245563\n",
      "[20]\ttraining's binary_logloss: 0.20259\tvalid_1's binary_logloss: 0.220818\n",
      "[30]\ttraining's binary_logloss: 0.185509\tvalid_1's binary_logloss: 0.209849\n",
      "[40]\ttraining's binary_logloss: 0.175043\tvalid_1's binary_logloss: 0.206131\n",
      "[50]\ttraining's binary_logloss: 0.167068\tvalid_1's binary_logloss: 0.204273\n",
      "[60]\ttraining's binary_logloss: 0.160314\tvalid_1's binary_logloss: 0.204101\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.162047\tvalid_1's binary_logloss: 0.203909\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.234975\tvalid_1's binary_logloss: 0.241901\n",
      "[20]\ttraining's binary_logloss: 0.203404\tvalid_1's binary_logloss: 0.216174\n",
      "[30]\ttraining's binary_logloss: 0.187516\tvalid_1's binary_logloss: 0.205689\n",
      "[40]\ttraining's binary_logloss: 0.1771\tvalid_1's binary_logloss: 0.201312\n",
      "[50]\ttraining's binary_logloss: 0.169163\tvalid_1's binary_logloss: 0.199942\n",
      "[60]\ttraining's binary_logloss: 0.162686\tvalid_1's binary_logloss: 0.198622\n",
      "[70]\ttraining's binary_logloss: 0.156711\tvalid_1's binary_logloss: 0.197937\n",
      "[80]\ttraining's binary_logloss: 0.151489\tvalid_1's binary_logloss: 0.197775\n",
      "[90]\ttraining's binary_logloss: 0.146677\tvalid_1's binary_logloss: 0.197205\n",
      "[100]\ttraining's binary_logloss: 0.142212\tvalid_1's binary_logloss: 0.196983\n",
      "[110]\ttraining's binary_logloss: 0.137937\tvalid_1's binary_logloss: 0.197192\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's binary_logloss: 0.141307\tvalid_1's binary_logloss: 0.196805\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236236\tvalid_1's binary_logloss: 0.242635\n",
      "[20]\ttraining's binary_logloss: 0.203497\tvalid_1's binary_logloss: 0.215603\n",
      "[30]\ttraining's binary_logloss: 0.187196\tvalid_1's binary_logloss: 0.206439\n",
      "[40]\ttraining's binary_logloss: 0.176581\tvalid_1's binary_logloss: 0.202349\n",
      "[50]\ttraining's binary_logloss: 0.168401\tvalid_1's binary_logloss: 0.200162\n",
      "[60]\ttraining's binary_logloss: 0.161736\tvalid_1's binary_logloss: 0.199453\n",
      "[70]\ttraining's binary_logloss: 0.155813\tvalid_1's binary_logloss: 0.198878\n",
      "[80]\ttraining's binary_logloss: 0.150633\tvalid_1's binary_logloss: 0.198797\n",
      "[90]\ttraining's binary_logloss: 0.145964\tvalid_1's binary_logloss: 0.198939\n",
      "[100]\ttraining's binary_logloss: 0.141391\tvalid_1's binary_logloss: 0.198363\n",
      "[110]\ttraining's binary_logloss: 0.136928\tvalid_1's binary_logloss: 0.198357\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's binary_logloss: 0.139938\tvalid_1's binary_logloss: 0.198089\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233675\tvalid_1's binary_logloss: 0.245783\n",
      "[20]\ttraining's binary_logloss: 0.200831\tvalid_1's binary_logloss: 0.22059\n",
      "[30]\ttraining's binary_logloss: 0.185067\tvalid_1's binary_logloss: 0.210621\n",
      "[40]\ttraining's binary_logloss: 0.17405\tvalid_1's binary_logloss: 0.205876\n",
      "[50]\ttraining's binary_logloss: 0.166233\tvalid_1's binary_logloss: 0.203974\n",
      "[60]\ttraining's binary_logloss: 0.159488\tvalid_1's binary_logloss: 0.203179\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.160849\tvalid_1's binary_logloss: 0.203016\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236761\tvalid_1's binary_logloss: 0.243744\n",
      "[20]\ttraining's binary_logloss: 0.20479\tvalid_1's binary_logloss: 0.219092\n",
      "[30]\ttraining's binary_logloss: 0.189304\tvalid_1's binary_logloss: 0.210705\n",
      "[40]\ttraining's binary_logloss: 0.178452\tvalid_1's binary_logloss: 0.205687\n",
      "[50]\ttraining's binary_logloss: 0.170174\tvalid_1's binary_logloss: 0.202522\n",
      "[60]\ttraining's binary_logloss: 0.163226\tvalid_1's binary_logloss: 0.20185\n",
      "[70]\ttraining's binary_logloss: 0.156917\tvalid_1's binary_logloss: 0.201323\n",
      "[80]\ttraining's binary_logloss: 0.151045\tvalid_1's binary_logloss: 0.201541\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.156917\tvalid_1's binary_logloss: 0.201323\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233036\tvalid_1's binary_logloss: 0.245974\n",
      "[20]\ttraining's binary_logloss: 0.202789\tvalid_1's binary_logloss: 0.222757\n",
      "[30]\ttraining's binary_logloss: 0.18607\tvalid_1's binary_logloss: 0.212059\n",
      "[40]\ttraining's binary_logloss: 0.175681\tvalid_1's binary_logloss: 0.208122\n",
      "[50]\ttraining's binary_logloss: 0.1672\tvalid_1's binary_logloss: 0.20617\n",
      "[60]\ttraining's binary_logloss: 0.160046\tvalid_1's binary_logloss: 0.205473\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.160857\tvalid_1's binary_logloss: 0.205446\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236652\tvalid_1's binary_logloss: 0.241363\n",
      "[20]\ttraining's binary_logloss: 0.204197\tvalid_1's binary_logloss: 0.216685\n",
      "[30]\ttraining's binary_logloss: 0.186953\tvalid_1's binary_logloss: 0.206537\n",
      "[40]\ttraining's binary_logloss: 0.175563\tvalid_1's binary_logloss: 0.201907\n",
      "[50]\ttraining's binary_logloss: 0.167563\tvalid_1's binary_logloss: 0.201131\n",
      "[60]\ttraining's binary_logloss: 0.160918\tvalid_1's binary_logloss: 0.200867\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.16404\tvalid_1's binary_logloss: 0.200659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232541\tvalid_1's binary_logloss: 0.247365\n",
      "[20]\ttraining's binary_logloss: 0.201406\tvalid_1's binary_logloss: 0.224306\n",
      "[30]\ttraining's binary_logloss: 0.184904\tvalid_1's binary_logloss: 0.214471\n",
      "[40]\ttraining's binary_logloss: 0.17446\tvalid_1's binary_logloss: 0.210719\n",
      "[50]\ttraining's binary_logloss: 0.166816\tvalid_1's binary_logloss: 0.209174\n",
      "[60]\ttraining's binary_logloss: 0.160242\tvalid_1's binary_logloss: 0.208741\n",
      "[70]\ttraining's binary_logloss: 0.154226\tvalid_1's binary_logloss: 0.20819\n",
      "[80]\ttraining's binary_logloss: 0.148739\tvalid_1's binary_logloss: 0.207704\n",
      "[90]\ttraining's binary_logloss: 0.144179\tvalid_1's binary_logloss: 0.207788\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's binary_logloss: 0.145559\tvalid_1's binary_logloss: 0.207562\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.235139\tvalid_1's binary_logloss: 0.241823\n",
      "[20]\ttraining's binary_logloss: 0.204894\tvalid_1's binary_logloss: 0.217165\n",
      "[30]\ttraining's binary_logloss: 0.188806\tvalid_1's binary_logloss: 0.20673\n",
      "[40]\ttraining's binary_logloss: 0.177952\tvalid_1's binary_logloss: 0.201401\n",
      "[50]\ttraining's binary_logloss: 0.170111\tvalid_1's binary_logloss: 0.199843\n",
      "[60]\ttraining's binary_logloss: 0.163337\tvalid_1's binary_logloss: 0.199539\n",
      "[70]\ttraining's binary_logloss: 0.157071\tvalid_1's binary_logloss: 0.199264\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.160107\tvalid_1's binary_logloss: 0.198938\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.23311\tvalid_1's binary_logloss: 0.244845\n",
      "[20]\ttraining's binary_logloss: 0.201773\tvalid_1's binary_logloss: 0.222088\n",
      "[30]\ttraining's binary_logloss: 0.185879\tvalid_1's binary_logloss: 0.212491\n",
      "[40]\ttraining's binary_logloss: 0.17537\tvalid_1's binary_logloss: 0.208148\n",
      "[50]\ttraining's binary_logloss: 0.166164\tvalid_1's binary_logloss: 0.205667\n",
      "[60]\ttraining's binary_logloss: 0.159349\tvalid_1's binary_logloss: 0.204902\n",
      "[70]\ttraining's binary_logloss: 0.153598\tvalid_1's binary_logloss: 0.204253\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.155214\tvalid_1's binary_logloss: 0.20412\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237302\tvalid_1's binary_logloss: 0.238128\n",
      "[20]\ttraining's binary_logloss: 0.205477\tvalid_1's binary_logloss: 0.212096\n",
      "[30]\ttraining's binary_logloss: 0.188678\tvalid_1's binary_logloss: 0.201534\n",
      "[40]\ttraining's binary_logloss: 0.178077\tvalid_1's binary_logloss: 0.197321\n",
      "[50]\ttraining's binary_logloss: 0.170364\tvalid_1's binary_logloss: 0.195942\n",
      "[60]\ttraining's binary_logloss: 0.163151\tvalid_1's binary_logloss: 0.194671\n",
      "[70]\ttraining's binary_logloss: 0.1572\tvalid_1's binary_logloss: 0.194592\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.157655\tvalid_1's binary_logloss: 0.194334\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236808\tvalid_1's binary_logloss: 0.241006\n",
      "[20]\ttraining's binary_logloss: 0.205924\tvalid_1's binary_logloss: 0.215658\n",
      "[30]\ttraining's binary_logloss: 0.189205\tvalid_1's binary_logloss: 0.205076\n",
      "[40]\ttraining's binary_logloss: 0.178641\tvalid_1's binary_logloss: 0.200792\n",
      "[50]\ttraining's binary_logloss: 0.170203\tvalid_1's binary_logloss: 0.198976\n",
      "[60]\ttraining's binary_logloss: 0.163514\tvalid_1's binary_logloss: 0.198664\n",
      "[70]\ttraining's binary_logloss: 0.157875\tvalid_1's binary_logloss: 0.198433\n",
      "[80]\ttraining's binary_logloss: 0.152071\tvalid_1's binary_logloss: 0.197825\n",
      "[90]\ttraining's binary_logloss: 0.147526\tvalid_1's binary_logloss: 0.197977\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.152071\tvalid_1's binary_logloss: 0.197825\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233278\tvalid_1's binary_logloss: 0.246235\n",
      "[20]\ttraining's binary_logloss: 0.202345\tvalid_1's binary_logloss: 0.22289\n",
      "[30]\ttraining's binary_logloss: 0.185064\tvalid_1's binary_logloss: 0.212249\n",
      "[40]\ttraining's binary_logloss: 0.174656\tvalid_1's binary_logloss: 0.208299\n",
      "[50]\ttraining's binary_logloss: 0.166853\tvalid_1's binary_logloss: 0.206996\n",
      "[60]\ttraining's binary_logloss: 0.160306\tvalid_1's binary_logloss: 0.205662\n",
      "[70]\ttraining's binary_logloss: 0.15441\tvalid_1's binary_logloss: 0.205304\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.157163\tvalid_1's binary_logloss: 0.204926\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.232134\tvalid_1's binary_logloss: 0.247015\n",
      "[20]\ttraining's binary_logloss: 0.200193\tvalid_1's binary_logloss: 0.223643\n",
      "[30]\ttraining's binary_logloss: 0.183453\tvalid_1's binary_logloss: 0.213725\n",
      "[40]\ttraining's binary_logloss: 0.173318\tvalid_1's binary_logloss: 0.210331\n",
      "[50]\ttraining's binary_logloss: 0.164799\tvalid_1's binary_logloss: 0.208275\n",
      "[60]\ttraining's binary_logloss: 0.158155\tvalid_1's binary_logloss: 0.207701\n",
      "[70]\ttraining's binary_logloss: 0.152536\tvalid_1's binary_logloss: 0.207285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.146228\tvalid_1's binary_logloss: 0.206583\n",
      "[90]\ttraining's binary_logloss: 0.141293\tvalid_1's binary_logloss: 0.20692\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.146228\tvalid_1's binary_logloss: 0.206583\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.237007\tvalid_1's binary_logloss: 0.239776\n",
      "[20]\ttraining's binary_logloss: 0.204416\tvalid_1's binary_logloss: 0.213924\n",
      "[30]\ttraining's binary_logloss: 0.188377\tvalid_1's binary_logloss: 0.203812\n",
      "[40]\ttraining's binary_logloss: 0.177324\tvalid_1's binary_logloss: 0.199541\n",
      "[50]\ttraining's binary_logloss: 0.169665\tvalid_1's binary_logloss: 0.198099\n",
      "[60]\ttraining's binary_logloss: 0.162679\tvalid_1's binary_logloss: 0.197845\n",
      "[70]\ttraining's binary_logloss: 0.156715\tvalid_1's binary_logloss: 0.197245\n",
      "[80]\ttraining's binary_logloss: 0.15095\tvalid_1's binary_logloss: 0.197047\n",
      "[90]\ttraining's binary_logloss: 0.145697\tvalid_1's binary_logloss: 0.197068\n",
      "[100]\ttraining's binary_logloss: 0.141141\tvalid_1's binary_logloss: 0.19708\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.14456\tvalid_1's binary_logloss: 0.196656\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233885\tvalid_1's binary_logloss: 0.243782\n",
      "[20]\ttraining's binary_logloss: 0.202417\tvalid_1's binary_logloss: 0.217996\n",
      "[30]\ttraining's binary_logloss: 0.185718\tvalid_1's binary_logloss: 0.207444\n",
      "[40]\ttraining's binary_logloss: 0.175443\tvalid_1's binary_logloss: 0.203389\n",
      "[50]\ttraining's binary_logloss: 0.167198\tvalid_1's binary_logloss: 0.20231\n",
      "[60]\ttraining's binary_logloss: 0.159726\tvalid_1's binary_logloss: 0.20106\n",
      "[70]\ttraining's binary_logloss: 0.153253\tvalid_1's binary_logloss: 0.200577\n",
      "[80]\ttraining's binary_logloss: 0.147808\tvalid_1's binary_logloss: 0.200437\n",
      "[90]\ttraining's binary_logloss: 0.143055\tvalid_1's binary_logloss: 0.2007\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.146639\tvalid_1's binary_logloss: 0.200381\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.236729\tvalid_1's binary_logloss: 0.239496\n",
      "[20]\ttraining's binary_logloss: 0.20398\tvalid_1's binary_logloss: 0.214708\n",
      "[30]\ttraining's binary_logloss: 0.188106\tvalid_1's binary_logloss: 0.205254\n",
      "[40]\ttraining's binary_logloss: 0.177631\tvalid_1's binary_logloss: 0.201463\n",
      "[50]\ttraining's binary_logloss: 0.168796\tvalid_1's binary_logloss: 0.199374\n",
      "[60]\ttraining's binary_logloss: 0.16164\tvalid_1's binary_logloss: 0.19863\n",
      "[70]\ttraining's binary_logloss: 0.155688\tvalid_1's binary_logloss: 0.198567\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.159724\tvalid_1's binary_logloss: 0.198149\n",
      "[LightGBM] [Info] Number of positive: 2222, number of negative: 16767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 18989, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117015 -> initscore=-2.021005\n",
      "[LightGBM] [Info] Start training from score -2.021005\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.233397\tvalid_1's binary_logloss: 0.244044\n",
      "[20]\ttraining's binary_logloss: 0.20318\tvalid_1's binary_logloss: 0.221744\n",
      "[30]\ttraining's binary_logloss: 0.186621\tvalid_1's binary_logloss: 0.211969\n",
      "[40]\ttraining's binary_logloss: 0.176313\tvalid_1's binary_logloss: 0.20748\n",
      "[50]\ttraining's binary_logloss: 0.168565\tvalid_1's binary_logloss: 0.205717\n",
      "[60]\ttraining's binary_logloss: 0.161507\tvalid_1's binary_logloss: 0.204866\n",
      "[70]\ttraining's binary_logloss: 0.155885\tvalid_1's binary_logloss: 0.204711\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.156776\tvalid_1's binary_logloss: 0.204404\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "org_X_train = X_train.copy()\n",
    "org_y_train = y_train.copy()\n",
    "\n",
    "for i in range(100):\n",
    "    # 訓練データからデータを分割\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(org_X_train, org_y_train, test_size=0.3, random_state=i, stratify=org_y_train)\n",
    "\n",
    "    # 使用モデルはLGB（パラメータチューニング無）\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "#     lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n",
    "#     lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary'\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params, lgb_train,\n",
    "        valid_sets=[lgb_train, lgb_eval],\n",
    "        verbose_eval=10,\n",
    "        num_boost_round=1000,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    pred_df[i] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.634824\n",
       "1        0.592281\n",
       "2        0.000872\n",
       "3        0.001357\n",
       "4        0.104569\n",
       "           ...   \n",
       "18078    0.001817\n",
       "18079    0.061834\n",
       "18080    0.001023\n",
       "18081    0.004060\n",
       "18082    0.009116\n",
       "Length: 18083, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[1] = pred_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv('20200929_001.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
