{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Using cached category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (1.18.5)\n",
      "Requirement already satisfied: patsy>=0.5.1 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\yanai\\appdata\\roaming\\python\\python37\\site-packages (from category_encoders) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "random_state = 1234\n",
    "\n",
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27128 entries, 0 to 27127\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         27128 non-null  int64 \n",
      " 1   age        27128 non-null  int64 \n",
      " 2   job        27128 non-null  object\n",
      " 3   marital    27128 non-null  object\n",
      " 4   education  27128 non-null  object\n",
      " 5   default    27128 non-null  object\n",
      " 6   balance    27128 non-null  int64 \n",
      " 7   housing    27128 non-null  object\n",
      " 8   loan       27128 non-null  object\n",
      " 9   contact    27128 non-null  object\n",
      " 10  day        27128 non-null  int64 \n",
      " 11  month      27128 non-null  object\n",
      " 12  duration   27128 non-null  int64 \n",
      " 13  campaign   27128 non-null  int64 \n",
      " 14  pdays      27128 non-null  int64 \n",
      " 15  previous   27128 non-null  int64 \n",
      " 16  poutcome   27128 non-null  object\n",
      " 17  y          27128 non-null  int64 \n",
      "dtypes: int64(9), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "      <td>27128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13564.500000</td>\n",
       "      <td>40.951010</td>\n",
       "      <td>1355.800870</td>\n",
       "      <td>15.806215</td>\n",
       "      <td>260.711295</td>\n",
       "      <td>2.751769</td>\n",
       "      <td>40.528052</td>\n",
       "      <td>0.579733</td>\n",
       "      <td>0.117001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7831.323388</td>\n",
       "      <td>10.608542</td>\n",
       "      <td>3003.305272</td>\n",
       "      <td>8.337904</td>\n",
       "      <td>260.091727</td>\n",
       "      <td>3.126594</td>\n",
       "      <td>100.382462</td>\n",
       "      <td>2.503653</td>\n",
       "      <td>0.321427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-6847.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6782.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13564.500000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20346.250000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27128.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           age        balance           day      duration  \\\n",
       "count  27128.000000  27128.000000   27128.000000  27128.000000  27128.000000   \n",
       "mean   13564.500000     40.951010    1355.800870     15.806215    260.711295   \n",
       "std     7831.323388     10.608542    3003.305272      8.337904    260.091727   \n",
       "min        1.000000     18.000000   -6847.000000      1.000000      0.000000   \n",
       "25%     6782.750000     33.000000      72.000000      8.000000    104.000000   \n",
       "50%    13564.500000     39.000000     449.000000     16.000000    182.000000   \n",
       "75%    20346.250000     48.000000    1428.000000     21.000000    323.000000   \n",
       "max    27128.000000     95.000000  102127.000000     31.000000   4918.000000   \n",
       "\n",
       "           campaign         pdays      previous             y  \n",
       "count  27128.000000  27128.000000  27128.000000  27128.000000  \n",
       "mean       2.751769     40.528052      0.579733      0.117001  \n",
       "std        3.126594    100.382462      2.503653      0.321427  \n",
       "min        1.000000     -1.000000      0.000000      0.000000  \n",
       "25%        1.000000     -1.000000      0.000000      0.000000  \n",
       "50%        2.000000     -1.000000      0.000000      0.000000  \n",
       "75%        3.000000     -1.000000      0.000000      0.000000  \n",
       "max       63.000000    871.000000    275.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'id'}>,\n",
       "        <AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'balance'}>],\n",
       "       [<AxesSubplot:title={'center':'day'}>,\n",
       "        <AxesSubplot:title={'center':'duration'}>,\n",
       "        <AxesSubplot:title={'center':'campaign'}>],\n",
       "       [<AxesSubplot:title={'center':'pdays'}>,\n",
       "        <AxesSubplot:title={'center':'previous'}>,\n",
       "        <AxesSubplot:title={'center':'y'}>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(14, 10), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         blue-collar\n",
       "1        entrepreneur\n",
       "2          management\n",
       "3             retired\n",
       "4          management\n",
       "             ...     \n",
       "27123     blue-collar\n",
       "27124        services\n",
       "27125     blue-collar\n",
       "27126       housemaid\n",
       "27127        services\n",
       "Name: job, Length: 27128, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAE1CAYAAAALcjBQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAppElEQVR4nO3df/xlVV3v8debwfihIhADIQMOEqKAojAShqmIBoYGqRiWylWuY0T+6Hbtot2bP4rCilQ0MQJhsBJRM0ZFBVFQFMFBUH7HJAgTKKOpoSYKvu8fax048+XMfL8Me+0vc/b7+Xh8H+ec9T1nf875/vjsvdde67Nkm4iIGIaN5vsNREREf5L0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBmTj+X4Ds9lmm228ePHi+X4bEREblMsuu+w7thfObH/QJ/3FixezYsWK+X4bEREbFEnfnNSe7p2IiAGZU9KXtKWkD0u6TtK1kp4iaWtJ50m6od5uNfb8N0haKel6SQeNte8j6cr6vRMlqcWHioiIyeZ6pP9O4FO2HwvsBVwLHAucb3tX4Pz6GEm7A0cAewAHA++RtKBu5yRgKbBr/Tq4o88RERFzMGvSl7QF8DTgVADbP7X9feBQYFl92jLgsHr/UOBM23favhFYCewraXtgC9sXuxT8OWPsNRER0YO5HOk/GlgNnCbpckmnSHoosJ3t2wDq7bb1+TsAt4y9flVt26Hen9l+H5KWSlohacXq1avv1weKiIi1m0vS3xjYGzjJ9pOAH1G7ctZiUj+919F+30b7ZNtLbC9ZuPA+I44iImI9zSXprwJW2b6kPv4wZSfw7dplQ729fez5O469fhFwa21fNKE9IiJ6MmvSt/0t4BZJu9WmA4FrgOXAkbXtSODsen85cISkTSTtTLlge2ntArpD0n511M7Lxl4TERE9mOvkrFcD/yTpF4BvAC+n7DDOknQUcDNwOIDtqyWdRdkx3AUcY/vuup2jgdOBzYBP1q/1tvjYT6zX6246/pAHEjYiYoM1p6Rv+wpgyYRvHbiW5x8HHDehfQWw5/14fxER0aHMyI2IGJAk/YiIAUnSj4gYkCT9iIgBSdKPiBiQJP2IiAFJ0o+IGJAk/YiIAXnQL5f4YJIZwBGxocuRfkTEgCTpR0QMSJJ+RMSAJOlHRAxIkn5ExIAk6UdEDEiSfkTEgCTpR0QMSJJ+RMSAJOlHRAxIkn5ExIAk6UdEDEiSfkTEgCTpR0QMSJJ+RMSAJOlHRAxIkn5ExIDMKelLuknSlZKukLSitm0t6TxJN9Tbrcae/wZJKyVdL+mgsfZ96nZWSjpRkrr/SBERsTb350j/ANtPtL2kPj4WON/2rsD59TGSdgeOAPYADgbeI2lBfc1JwFJg1/p18AP/CBERMVcPpHvnUGBZvb8MOGys/Uzbd9q+EVgJ7Ctpe2AL2xfbNnDG2GsiIqIHc036Bs6VdJmkpbVtO9u3AdTbbWv7DsAtY69dVdt2qPdntkdERE82nuPz9rd9q6RtgfMkXbeO507qp/c62u+7gbJjWQqw0047zfEtRkTEbOZ0pG/71np7O/BRYF/g27XLhnp7e336KmDHsZcvAm6t7YsmtE+Kd7LtJbaXLFy4cO6fJiIi1mnWpC/poZIeProP/DpwFbAcOLI+7Ujg7Hp/OXCEpE0k7Uy5YHtp7QK6Q9J+ddTOy8ZeExERPZhL9852wEfr6MqNgX+2/SlJXwHOknQUcDNwOIDtqyWdBVwD3AUcY/vuuq2jgdOBzYBP1q+IiOjJrEnf9jeAvSa0fxc4cC2vOQ44bkL7CmDP+/82IyKiC5mRGxExIEn6EREDkqQfETEgSfoREQOSpB8RMSBJ+hERA5KkHxExIEn6EREDkqQfETEgSfoREQOSpB8RMSBJ+hERA5KkHxExIHNdOSt6tvjYT6zX6246/pCO30lETJMc6UdEDEiSfkTEgCTpR0QMSJJ+RMSAJOlHRAxIkn5ExIAk6UdEDEiSfkTEgCTpR0QMSJJ+RMSAJOlHRAxIkn5ExIDMOelLWiDpckkfr4+3lnSepBvq7VZjz32DpJWSrpd00Fj7PpKurN87UZK6/TgREbEu9+dI/7XAtWOPjwXOt70rcH59jKTdgSOAPYCDgfdIWlBfcxKwFNi1fh38gN59RETcL3NK+pIWAYcAp4w1Hwosq/eXAYeNtZ9p+07bNwIrgX0lbQ9sYfti2wbOGHtNRET0YK5H+u8A/hj4+VjbdrZvA6i329b2HYBbxp63qrbtUO/PbI+IiJ7MmvQlPRe43fZlc9zmpH56r6N9UsylklZIWrF69eo5ho2IiNnM5Uh/f+A3Jd0EnAk8U9I/At+uXTbU29vr81cBO469fhFwa21fNKH9PmyfbHuJ7SULFy68Hx8nIiLWZdakb/sNthfZXky5QPtZ2y8BlgNH1qcdCZxd7y8HjpC0iaSdKRdsL61dQHdI2q+O2nnZ2GsiIqIHD2SN3OOBsyQdBdwMHA5g+2pJZwHXAHcBx9i+u77maOB0YDPgk/UrIiJ6cr+Svu0LgAvq/e8CB67leccBx01oXwHseX/fZEREdCMzciMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQGZN+pI2lXSppK9JulrSW2r71pLOk3RDvd1q7DVvkLRS0vWSDhpr30fSlfV7J0pSm48VERGTbDyH59wJPNP2DyU9BLhI0ieB5wPn2z5e0rHAscD/kbQ7cASwB/BI4DOSHmP7buAkYCnwZeAc4GDgk51/qrjfFh/7ifV63U3HH9LxO4mIlmY90nfxw/rwIfXLwKHAstq+DDis3j8UONP2nbZvBFYC+0raHtjC9sW2DZwx9pqIiOjBnPr0JS2QdAVwO3Ce7UuA7WzfBlBvt61P3wG4Zezlq2rbDvX+zPaIiOjJnJK+7bttPxFYRDlq33MdT5/UT+91tN93A9JSSSskrVi9evVc3mJERMzB/Rq9Y/v7wAWUvvhv1y4b6u3t9WmrgB3HXrYIuLW2L5rQPinOybaX2F6ycOHC+/MWIyJiHeYyemehpC3r/c2AZwHXAcuBI+vTjgTOrveXA0dI2kTSzsCuwKW1C+gOSfvVUTsvG3tNRET0YC6jd7YHlklaQNlJnGX745IuBs6SdBRwM3A4gO2rJZ0FXAPcBRxTR+4AHA2cDmxGGbWTkTsRET2aNenb/jrwpAnt3wUOXMtrjgOOm9C+AljX9YCIiGgoM3IjIgYkST8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJA5lJlM6JzWZM3Yn7kSD8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJAkvQjIgYkST8iYkBmTfqSdpT0OUnXSrpa0mtr+9aSzpN0Q73dauw1b5C0UtL1kg4aa99H0pX1eydKUpuPFRERk8zlSP8u4I9sPw7YDzhG0u7AscD5tncFzq+Pqd87AtgDOBh4j6QFdVsnAUuBXevXwR1+loiImMWsSd/2bba/Wu/fAVwL7AAcCiyrT1sGHFbvHwqcaftO2zcCK4F9JW0PbGH7YtsGzhh7TURE9OB+9elLWgw8CbgE2M72bVB2DMC29Wk7ALeMvWxVbduh3p/ZHhERPZlz0pf0MOAjwOts/9e6njqhzetonxRrqaQVklasXr16rm8xIiJmMaekL+khlIT/T7b/pTZ/u3bZUG9vr+2rgB3HXr4IuLW2L5rQfh+2T7a9xPaShQsXzvWzRETELOYyekfAqcC1tv927FvLgSPr/SOBs8faj5C0iaSdKRdsL61dQHdI2q9u82Vjr4mIiB7MZWH0/YGXAldKuqK2vRE4HjhL0lHAzcDhALavlnQWcA1l5M8xtu+urzsaOB3YDPhk/YqIiJ7MmvRtX8Tk/niAA9fymuOA4ya0rwD2vD9vMCIiupMZuRERA5KkHxExIEn6EREDkqQfETEgSfoREQOSpB8RMSBJ+hERA5KkHxExIEn6EREDkqQfETEgSfoREQOSpB8RMSBJ+hERA5KkHxExIEn6EREDkqQfETEgSfoREQMyl+USIzZ4i4/9xHq97qbjD+n4nUTMrxzpR0QMSJJ+RMSAJOlHRAxIkn5ExIAk6UdEDEiSfkTEgCTpR0QMSJJ+RMSAzJr0Jb1P0u2Srhpr21rSeZJuqLdbjX3vDZJWSrpe0kFj7ftIurJ+70RJ6v7jRETEuszlSP904OAZbccC59veFTi/PkbS7sARwB71Ne+RtKC+5iRgKbBr/Zq5zYiIaGzWpG/788B/zmg+FFhW7y8DDhtrP9P2nbZvBFYC+0raHtjC9sW2DZwx9pqIiOjJ+vbpb2f7NoB6u21t3wG4Zex5q2rbDvX+zPaIiOhR1xdyJ/XTex3tkzciLZW0QtKK1atXd/bmIiKGbn2T/rdrlw319vbavgrYcex5i4Bba/uiCe0T2T7Z9hLbSxYuXLiebzEiImZa39LKy4EjgePr7dlj7f8s6W+BR1Iu2F5q+25Jd0jaD7gEeBnwrgf0ziMexFLKOR6sZk36kj4APAPYRtIq4E2UZH+WpKOAm4HDAWxfLeks4BrgLuAY23fXTR1NGQm0GfDJ+hURHchOJuZq1qRv+8Vr+daBa3n+ccBxE9pXAHver3cXERGdyozciIgBSdKPiBiQJP2IiAHJwugRcb/lwvGGK0k/Ih70spPpTrp3IiIGJEk/ImJAkvQjIgYkST8iYkCS9CMiBiRJPyJiQDJkMyJihmkeIpoj/YiIAUnSj4gYkCT9iIgBSdKPiBiQJP2IiAFJ0o+IGJAk/YiIAUnSj4gYkCT9iIgBSdKPiBiQJP2IiAFJ0o+IGJAUXIuImGd9FnjLkX5ExIAk6UdEDEjvSV/SwZKul7RS0rF9x4+IGLJek76kBcDfAc8BdgdeLGn3Pt9DRMSQ9X2kvy+w0vY3bP8UOBM4tOf3EBExWH0n/R2AW8Yer6ptERHRA9nuL5h0OHCQ7f9ZH78U2Nf2q2c8bymwtD7cDbh+PcJtA3znAbzdB3O8af5siZd4iddNvEfZXjizse9x+quAHcceLwJunfkk2ycDJz+QQJJW2F7yQLbxYI03zZ8t8RIv8drG67t75yvArpJ2lvQLwBHA8p7fQ0TEYPV6pG/7Lkl/AHwaWAC8z/bVfb6HiIgh670Mg+1zgHN6CPWAuoce5PGm+bMlXuIlXsN4vV7IjYiI+ZUyDBERA5KkHxExIFOT9CUtkPSPPcZ77VzaIvpU/w/+er7fxzSRtMlc2jYUU9WnL+nTwPNqiYfWsb5qe+8ZbZfbflLDmAuA7Ri7AG/75lbxJsRfWudQtNj2/sAVtn8k6SXA3sA7bX+z4zh7r+v7tr/acbznzxLvX7qMV2N+FjjQPfxzS9p6Xd+3/Z8dx+v191djTvpfv09bh/E2AV4ALGbN//W3drH9aVtE5Sbgi5KWAz8aNdr+264CSHox8DvAzjXOyMOB73YVZ0LcVwNvAr4N/Lw2G3hCq5iT3kbDbZ8E7CVpL+CPgVOBM4CndxznhHq7KbAE+Brlcz0BuAR4asfxnldvtwV+FfhsfXwAcAHQedIHLgfOlvQh1vw/aBHrMsrfoYCdgO/V+1sCNwM7dxyvt9+fpF+ilInZTNKTuPfvfwtg867iTHA28APKz/bOrjc+bUn/1vq1ESUJt/Al4DbK1OgTxtrvAL7eKCbAa4HdbDfbsczG9t833Pxdti3pUMoR/qmSjuw6iO0DACSdCSy1fWV9vCfwvxvEe3nd/seB3W3fVh9vT6k428LWlAOQZ46/FRrsYGzvDCDpvcDyOiQbSc8BntUgXp+/v4OA/0GpHDB+4HgH8MaOY41bZPvgVhufqu6daSbpc8Czbd/VU7ymp5gT4l0IfAp4BfBrwGpKd8/jG8W7wvYTZ2vrMN5Vtvcce7wR8PXxtg2ZpMts7zOjrVm5gj5/f5JeYPsjXW93HfFOBt412qF1baqO9CUtpHQN7EE5/QPA9jPX+qL1j/V84G2U03bVL9veoutY1TeACyR9grFTvi67rmZoeoo5wW9Tus1eYftbknYCWl6QvFbSKcA/Uo6CXwJc2zDeBfWa0wdqvCOAz7UIJOm0GmMNtl/RIl71HUn/lzV/ni3PSvv8/X1c0u/Q0wEQpYvqf0i6kfK/N8otnXTlTtWRvqRzgQ9STvN+DzgSWG37/zSItZJy0bhlohiP96ZJ7bbf0ijeVX0fhUp6FLCr7c9I2hxYYPuORrE2BY4GnlabPg+cZPsnLeLVmL81Hs/2RxvFecHYw02B3wJutf2aFvFqzK0p15yeRknCnwfe2vWF3LF4vf3+JH2Kew+A7h612z5hrS96YPEeNam9q0EN05b0L7O9j6Svj/aKki603fXFQCR90fb+XW/3waL1KeaEeK+klNPe2vYuknYF3mv7wIYxNwN2sr0+pbvXJ15vO7UZcTcCPtPijHdCrIfZ/mHrOH3q+wBI0luBLwBfsv2j2Z5/f01V9w7ws3p7m6RDKBd1FzWKtULSB4F/Zc3ulhYjJHrtuqqanmJOcAxlZbVLKIFukLRto1hI+k1K99EvUEZiPZFyZPqbjeLds1MDdqGMCnkv0GynNmZXysiaZiT9KnAK8DBgpzoK61W2f7/jOGfZfpGkK5nchdXi7/NLkh7f1wEQZRTii4ETJd1B2QF83vbZXWx82pL+n0t6BPBHwLsoQ6v+sFGsLYAfA78+1tZkhET1T5Suq+cy1nXVKBaUdYz7dKftn0plVJykjZnwT92hN1F2MhcA2L5C0uKG8XrbqdVEMRpGaeBbQOddnDO8nTLaZTmA7a9Jetq6X7JeRhMgn9tg22vT6wGQ7fcB76tDRl9E6a5eSkcjEqcq6dv+eL37A8o46JaxXt5y+xP8Yh3G+FrbFwIX1hEvnZK0he3/ogxL69OFkt5IGRP9bOD3gY81jHeX7R+MdjI96G2nZrvVcOXZ4t4y4+d599qe+wBi3FZvO520N4teD4DqBerdKXNyvgC8EOhs0tlUJH1J72Id/0AtLmBJegxlQtF2tveU9ATgN23/edexqr66rv6ZchQ1PulmxMCjG8QEOBY4CrgSeBWl/PYpjWIBXFVHZCyo1w9eQ5mD0UpvOzWVzPu7wM62/6yOhPol25e2iFfdUrt4rLJA0mtoOBpK0n6Us/nHUbroFgA/ajF6zvY3JT2Vcj3mtNrV+rCu44z5Rcrn+T7wn8B3uhyqPRUXcmebxGN7WYOYFwKvB/5+VHqh5QUfSc+l7PV35N6uq7fYnoqVxyQ9FPiJ7bvr4wXAJrZ/3Cje5sCfcG/33KeBP281eqdeTD2qxlONd0qLUgmSTqLM2n6m7cdJ2go41/aTu441FnMb4J2UCVkCzgVe22oyoaQVlGGvH6LMzH0Z8Mu2/6RBrDfVGLvZfoykRwIfaj2QQ9LjKF1mf0i56N/JQd5UHOm3SOpzsLntS2eczjabONVn19VIPXtZzJpjk1tdszifkjBGIz82oySOX+06UN2hLLf9LEri78NvAKfa/oceYv2K7b0lXQ5g+3v16Luln9v+3cYx1mB7paQF9UDhNEmtztR+C3gStYvF9q2SmnWh1QO8X6MMR92KUrrjC11tfyqSvqSPse7unRYjMr4jaZdRXEkvpJRn6JSkP7b9V2vrwmo19lrS+yj1TK5mzVo/rZL+puND/Wz/sB6Nd8723ZJ+LOkRtn/QIsYERwDvlPQR4LTG8zt+Vndso7/Nhdz7O2zlEklXAO8DPtXiDGaGH9cd2RWS/oryv/fQRrF+atuSRj/PVnFGnkOZd/BO27d2vfGpSPrA38xDzGMoy5g9VtJ/ADdSZgV2bZQcVjTY9rrsZ3v3HuP9SNLerlUSJe0D/HfDeD8BrpR0HmsWJWuyE7X9EklbUIbinVYTyGnABxqM1T8R+CiwraTjKBcC/2/HMWZ6DOVM7RXAu+tw5tNt/1ujeC+l9Hv/AaX7Y0dK2ZAWzpL098CWdejtK4BmZ2y2j5G0HfBklaqil9q+vavtT0Wf/ri6939MfXi97Z+t6/kdxHsosFEfk2z6JOlU4ATb1/QU78nAmZQL1ADbA79t+7JG8SZeB2rdVVj7vl8CvI6yQ/9l4ETb7+o4zmMpcwAEnN/XzPEa+wBKeYSHUqpgHmv74r7it1Avvt9zPcb2eQ1jHU45kL2gxvs14PW2P9zJ9qcp6Ut6BrCMMrlBlL3/kbY/3yDWlpSLR4tZs8+7VXfLecDhtr9fH28FnGn7oEbxnkYZXfIt+pmchaSHALvVWNe13mH3SdLzKEeIuwDvB5bZvr12YV1re+LU+wcQr9e1FyT9ImVn9lLKUMNTKWP2n0i56NlpieXa7/1nwKMon7F17aveSPoapbji7fXxQsqM6r262P60dO+MnAD8+mhafR1W+QFgn3W+av2cA3yZMsSwdX8pwMJRwod7Ls41m7FK6Zt9KY0/n6Rn2v6s7rvYyK6SOr9wPE8zOgEOB94+8wDE9o8ldVoITWuuvXA3907Sarn2wsWUndlhtleNta9QKbvctXcAzweubHX9YGyS20QNdzAbzejO+S4drnI4bUn/IR6ro2L73+rRYwub2v5fjbY9yd2SdhodranUcWl5mnZzT8NBn04ZnfC8Cd9rceF4PmZ0YvtlkrarR6gw1k9r+/yOw83H2gu71YudD9eM+ju239Yg3i3AVS0vGI8muanUwvkWZac2mgPRcgLcp3RvRVYoFWjP6Wrj09a98z5Konh/bfpdYGM3mD0r6Q8pwws/zpq1d1pVFTyYcuF4NAv3aZRFJD7dKN57KKsffYx+aguNht71QtLbPKP66qS2DuM17aedEavXtRdqzD0p/3dbUz7fakrX6lWN4j2Z0r1zIY1LjUu6xPavzNbWccwXAPtTfpadVmSdtqS/CWVUzVOpPyzgPbY7rwcv6RjgOMqsudEP0bZbzVgdXQTcj/LZLrb9nYaxTpvQbDeqyS7pZsoiKh8EPtt6yJ8mr3t6T3XWBvGa9tPOiHUq5dpIX2svUMfI/4ntz9XHzwD+wnbn8yzq9s+lHHSt0f3oBqXG62f7O8pAA1NGYB3T6rO1Nm1Jv7dZnZL+nTIJplnirXEea/s6rWVBaDdYCHo+qJQ5fh5lPPvelDOoM21f1HGcoyklEB4N/PvYtx5OKWXbZIKRpCs9tgpYnaH7NTdYGUw9r71QY35t5g5sUluH8ZqtyjUh1mLKbOP9KUn/i8DrbN/UKF7TBZqmLel/GXjWqD9R0sMo089bzOpcDhzRYocyI87JtpfWU/aZ7I5LK69tEthYwGYLcYy9h60o/2S/a3tBx9t+BGWW419S6v2M3NGqa67G/WvKhdTxftqvt+pOqjEf6gb12NcS66OUGaujrtWXAEtsH9Yo3vGUM8JzW2x/PqnxAk3TlvT7XDfzo5Ta9p9jzVPo5kmxpbHx6/tTKv19sD4+HLjMdqtS1Uh6OiUZPgf4CvBBN1ybVGsW0doGeLjtGxvGa9ZPOyPOUyhDJh9mu1lt+xkxtwLewppdq2+2/b1G8e6gzAP4af1qNmRTPS8/qcYLNE1b0v8i8GqvOavz3baf0iBW75N7VKoYLmbNsddnNIr1Ocrw15/Vxw+hnDU1qfujUqv8CuAsSl2cpkeomqciWn2QdAllFu5y91AMcNqp5+UnJb0T+CUaLdA0bUM2Xwd8SNIaszpbBLK9TD0utyfp/ZSJPVdwb51yA02SPvBISj/3qMvjYbWtc/Xay2lut9D0JL0U0VrHWO+mk4ncQ217YL7qXiHdp3z0jsD2blA+eubZpqQPAJ/pOs6Ypgs0TVXSt/0VlennzWd11hmWf0NPy+1Rjkp3bz2qZczxwOVj1xKeDry5RSCXAmgHAH0m/V6KaHl+FjTps7b9fNS9AngPtXw0ZejmDykjbJqVjx7TevnJP5p5fUlSZzOapyrpA9Qkf9XoAmjDUG/mvsvtdTrVfIarKKd8nVfynKT2c3+aMiv3Wspwys4r/o35kqR3U64hjBdA63x0Uj1K/Lh6LKJV4+5N6fM2cJHtyxuF+j3KhfAdgFWUEtXHtAjksoobwKju1WMpn+962z9tEbPqrXz0hLO11stPfkzSc1xWsEOlrv6HgE6656Yu6Y9pPZxr0nJ7LY/CtwGukXQpa/bztTp9/p+UmZ2LKF1K+1Gm2rdaiH00wmr8aN8t4tUj/MMo/7j/RTkz/FO3LaL1p5SL4aNT9NMlfcgdr7RWu8re0Wro6TriHkJZ6P3fKWfZO0t6le1PNgrZW/noeThb+wtK4j+E8rd5BqUrqxPTnPQ7K0W6Fn0vt/fmhtue5LWUU+Uv2z6gdps1G+fd6gLxOlwMfN/263uK92LgSa4rc9Uhh18FOk36tatsoaRfaHykPdMJwAG2VwKorDXxCaBV0u+tfLSk820fOFtbV2x/YjRwgnJd7TDbN3S1/alM+nV88sGNw7yasurSnZSx15+m9C02MX4a3ZOf2P6JJCRtUieI7dYqmEr98L8AHmn7OZJ2B55i+9RGIQ8AXiXpm6zZndSqKNlNlJEfo+UYN2HNyWFdx/pinUsy/tmazcgFbh8l/OobNDzwsv1Pki7j3vLRh3U9rl3SpsDmwDZ1SOrotH4LGgxqmDBHZgvKz/HVKsUHOxktNFVJv168OoUy0qTp+OQ6KetP6Gm5vdaz9CZYpVI++l+B8yR9j7Z9+qdTFhUZ/Tz/jdK/3yrpP6fRdtfmTuBqlRLZBp4NXCTpROh8fset9Wsj2hYGG3e1pHMoQ25N6cr6Sv27bVEtdRfgRtt/p1Ly4dmSbvNYJdoOvIoyIvCRwGVwT7XSO4B3dxhnZOZCSW3Wkpiycfq9jU9ey1C1H1B+cX/vjhfYbj1Lb5bYTwceQVkGr0mXgaSv2H6ypMvHfndNJtbNh7XN6xhpMb9DZaUuu4cFfjS5VtOIu57IpLI04xLKvJVPUQoD7mb7N7qMU2P9KeU6yX9J+n+UMiF/1mKQQR+m6kgf+hufTDntWsia0+q/TVm16x8oo1669O35SPjQW9fSj1QW4hhdmNuPshOdCi0n7c0kaQnlrGlUGvgHwCvcaBUyADeoZDuLn9u+q55JvNP2u0YjeRp4oe23qszgfjbl+sVJQJMqm5L2p1zDm7lATCfFHKct6fc5PvlJtp829vhjkj5v+2mSru4qiO5dXGSFyrqj/0oPpY7nwf+irLS0i8rM6oWUs7apoH5Xenof8Pu2v1BjP5WyE2i56tnOlOtci1lzxnireSs/k/Riyup1o7UYWq2dMTpwPAR4r+2zJb25USwoXZp/SOne6fygddqSfm/jk4GFWnNRk50owyqh1ALpyvjiIs1m6T0I7ELpZx8tcP0rTNff5ztovNLTmDtGCR/A9kV1rHlL/0pJVh+jn5XkXk75fz/O9o11p/OPjWL9R53T8SzgbSol3DtbyWqCHzQc6jpdffp9kvQbzBiXTCnZewHwStvvmLc3twFSrWVfj0r/gnIK/UY3XKiiT3Vm84G2mydESW+njDr5AOXA4LeB7wEfgWYT3pouKjKfVNYxPpiyw75B0vbA492owmcdzruAckA3flbfye9tqpK++q+GtwllBuKo5EOnF29nxFoGvNZrLox+QqvP1rfRBVxJf0n55/rn8Yu6Gzr1u9LTpDLcYyG7LcddY/4OpTzBuTRIVBPi3cjk//Vmixj1Zez3N/p8o67ATn5v03T6DGXhjZF7quE1jLcrZcbcpsAT6ljaVgXQnuD7Low+FQmx6vsUum/HUerDbEqp19TMPEx0A3g8ZfDCM7m3e6fJjOpqfMb9ppQhols3itW3Cya0dXZ0PlVH+jOprE70mUZHNm8CnkGpOX8OpT/6IttNLj6qLLf3DNf65JK2Bi50g5WX5kPfp9B9U78rPfU90Q1J11EOTPqcBTzzPVxk+6nzFb8rkv5o7OGmwHOBa7s6q5+2I/2ZWlbDeyGwF3C57ZfXf7RTGsWC0sf9JUkfpuz1X0Q5epwKdbLbv4w9vo2eisv15DOSfr2nndjp9DvRDeBrwJa0L38C3FO8bmQjypH/fFQ07ZztE8YfS/obysi2TkxV0te91fBGM+daVsP7b9s/l3RXnQRzO2Xd1SZsnyFpBeV0WcDzbV/TKl507hjgjyU1X+kJ2Mb2WZLeQAlyl6RW81VGtgOuk/QVeigISDkIGrmLUnriRY1izbfN6TC3TFXSd7/V8FbUMgX/QBlP+0Og8wUcZtga+JFL2eOFknZ2w+X9ojs9/23Ox0S3iYuxtzJP1y16IelK7u3DX0CZs9LZWhNT0ac/41TvPlpPl5a0GNjC9tcbxpja5f2GQOpvpaf6//AuSv31q6gT3Vr+fda4j6KsOfyZeo1mQasSECoL3L8JGE2QvJCyiNEGP4u7/hxH7qLMxr+rs+1PSdIfH6I2/oE6Heo0Ie4O3DvDsgS3P98o1hXU5f3GatN83e2qQkaHJJ1EXenJ9uPqkNtzbXe60pNKjfnXUJL+aAW5691oBbmxuK8ElgJb295Fpdz4e92o/LCkj1B2aKPyFi8F9rL9/LW/KmBKundGp3oqa9b+PveuTvQFSo2Mzkl6G2XSyzWsuWZtk6RPT8v7RTO9rPTkUk//UNtvBzorBzIHx1BWkrukvo8bJG3bMN4utscXLH9LPTCKWUxF0h+zjLIS0on18Yspq860uMBzGKWr5c7ZntiRs9Tz8n7Rqd5WeqLU0u9l6ckxd9r+6ajYoaSNabuS3H9Leqrti2q8/YH/bhhvakxb0t/N9l5jjz9Xx7e38A1Kgae+kv5C4MOMLe9HmcgUG4beVnqix6Unx1wo6Y3AZpKeTTnj/ljDeEcDy2rfPpQyE+ssXx3FVPTpj0g6ndKP+OX6+FeAI91gEZXap7gXcD5rDlHrcjGM8Xhftb33jLb06W9AVJacHK30dL4blcqW9Gjb35itreOYGwFHUQoCirKS3CmtisvVGdsvpBTq25IyOsm2OxvlMq2mIumPDXF6COUo+Ob6+FHANW6ziMrEowp3XDdd0tGUo6ZHs+byeg8Hvmj7JV3Gi/YkLbV9csPtTzpAuMz2Pq1i9k3Sp4DvU9YZvmcOwsyJTXFf05L0H7Wu79v+Zl/vpWv19HUr4C+BY8e+dYft/5yfdxUPxKSk3NF2HwvsAfwVML7g+xbA623v0XXMsdhNF/6YEK/JinhDMBV9+vOR1OuQtL+k1N7ZdOy9dPpHXscd/4ByUTo2MCqLys+87qOJT37gdqPUadmSNddhuAN4ZaOYI00X/pjgS5Ieb/vKHmJNlak40p8Pki6iTA55O+Uf7OWUn2evMxPjwW10VC/p/bZfWtsW2V7VMOZTbF/cavtridlLPf2xrtyNKbW1vkG5pjY6s8g1rlkk6a+nUR+ppCtHlS4lfcH2r833e4sHD0lXAX9NGW31+pnfd4PlLutw0Fdy36ULm629oMYLf4zFmdqu3L5MRffOPPlJHbFwg6Q/AP4DaDkZJTZMv0cpv7Ala3a5QLvlLs+mTEz8DP10tcC9i4SPLhaPih52Okw0Sf2BS9Jff6+jVL97DWVFpAMoizRH3KNOHrqo1tNvWdp43Oa2W1WXXZsLJrSlG+FBKEl//Rl4P2W0wkNq2z8A6VOMe0ga1YL53tj9e7To3gE+Luk3bJ/TYNtr88Ox+/cs/NFj/Jij9OmvJ0nXU/por2RsOn1OP2OcyrrNa+MW/ex1XYnNKXX7f0bb2v1rew+bAMttH9RXzJibHOmvv9W2O1vNJqaT7ZfPQ9hHcG8Z57dK2gnYvuf30OnCH9GdHOmvJ0kHUsbOzyzD0OJ0PTZwfa5b21cZ5xkxJy78YfvdrWLG+smR/vp7OfBYSn/+qHun1WiM2PCdTn/r1vZSxnmG547d73zhj+hOkv7622s0Pj9iDvpct7bPMs5ArmVtSDaa7zewAftyPUWPmIs+162dWcb5IkrXUkT69NeXpGspZV1vJNPAYxZ9r1vbVxnn2PCke2f9HTzfbyA2KLsAzwF2BF5AmcHa7P/P9nXAda22HxuuHOlH9GC04I2kp1K6Wk4A3thHkbKIcenTj+jH6KLtIZTV3c4GWo+oibiPJP2IfvxHXdj+RcA5dcZq/v+id+neieiBpM0p14GutH2DpO2Bx9s+d57fWgxMkn5ExIDk9DIiYkCS9CMiBiRJPyJiQJL0IyIGJEk/ImJA/j+vKI5PuNhchQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['job'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize = (20, 15))\n",
    "\n",
    "cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "for i, col in enumerate(cols):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    df[col].value_counts().plot.bar()\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>apr</td>\n",
       "      <td>939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>feb</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>13</td>\n",
       "      <td>apr</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>25</td>\n",
       "      <td>jan</td>\n",
       "      <td>423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>30</td>\n",
       "      <td>apr</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27123</th>\n",
       "      <td>42</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>2</td>\n",
       "      <td>feb</td>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27124</th>\n",
       "      <td>34</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>15</td>\n",
       "      <td>may</td>\n",
       "      <td>362</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27125</th>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>primary</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8</td>\n",
       "      <td>may</td>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>33</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>12</td>\n",
       "      <td>aug</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27127</th>\n",
       "      <td>29</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>18</td>\n",
       "      <td>may</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27128 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job  marital  education housing loan   contact  day  \\\n",
       "0       39   blue-collar  married  secondary     yes   no  cellular    3   \n",
       "1       51  entrepreneur  married    primary      no   no  cellular   18   \n",
       "2       36    management   single   tertiary      no   no  cellular   13   \n",
       "3       63       retired  married  secondary      no   no  cellular   25   \n",
       "4       31    management   single   tertiary      no   no  cellular   30   \n",
       "...    ...           ...      ...        ...     ...  ...       ...  ...   \n",
       "27123   42   blue-collar  married    primary     yes   no  cellular    2   \n",
       "27124   34      services   single  secondary     yes   no   unknown   15   \n",
       "27125   36   blue-collar   single    primary     yes   no   unknown    8   \n",
       "27126   33     housemaid  married    primary      no   no  cellular   12   \n",
       "27127   29      services   single  secondary     yes   no  cellular   18   \n",
       "\n",
       "      month  duration  campaign  previous poutcome  y  \n",
       "0       apr       939         1         0  unknown  1  \n",
       "1       feb       172        10         0  unknown  1  \n",
       "2       apr       567         1         2  failure  1  \n",
       "3       jan       423         1         0  unknown  1  \n",
       "4       apr       502         1         2  success  1  \n",
       "...     ...       ...       ...       ...      ... ..  \n",
       "27123   feb       279         2         2    other  0  \n",
       "27124   may       362         3         0  unknown  0  \n",
       "27125   may       405         1         0  unknown  0  \n",
       "27126   aug        76         4         0  unknown  0  \n",
       "27127   may       105         1         2  failure  0  \n",
       "\n",
       "[27128 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2 = df2.drop(columns=['id', 'balance', 'pdays', 'default'], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['id', 'age', 'job', 'marital', 'education', 'default', 'balance',\n",
       "        'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign',\n",
       "        'pdays', 'previous', 'poutcome', 'y'],\n",
       "       dtype='object'),\n",
       " Index(['age', 'job', 'marital', 'education', 'housing', 'loan', 'contact',\n",
       "        'day', 'month', 'duration', 'campaign', 'previous', 'poutcome', 'y'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns, df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month\n",
    "month_map={\n",
    "    'jan':1,\n",
    "    'feb':2,\n",
    "    'mar':3,\n",
    "    'apr':4,\n",
    "    'may':5,\n",
    "    'jun':6,\n",
    "    'jul':7,\n",
    "    'aug':8,\n",
    "    'sep':9,\n",
    "    'oct':10,\n",
    "    'nov':11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['month'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        apr\n",
       "1        feb\n",
       "2        apr\n",
       "3        jan\n",
       "4        apr\n",
       "        ... \n",
       "27123    feb\n",
       "27124    may\n",
       "27125    may\n",
       "27126    aug\n",
       "27127    may\n",
       "Name: month, Length: 27128, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.0\n",
       "1        2.0\n",
       "2        4.0\n",
       "3        1.0\n",
       "4        4.0\n",
       "        ... \n",
       "27123    2.0\n",
       "27124    5.0\n",
       "27125    5.0\n",
       "27126    8.0\n",
       "27127    5.0\n",
       "Name: month, Length: 27128, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['month'] = df2['month'].map(month_map)\n",
    "df2['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        apr\n",
       "1        feb\n",
       "2        apr\n",
       "3        jan\n",
       "4        apr\n",
       "        ... \n",
       "27123    feb\n",
       "27124    may\n",
       "27125    may\n",
       "27126    aug\n",
       "27127    may\n",
       "Name: month, Length: 27128, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df['month'])\n",
    "df['dd'] = le.transform(df['month'])\n",
    "\n",
    "###############################\n",
    "# train\n",
    "# le.fit(all_df['month'])\n",
    "# le.transform(train['month'])\n",
    "\n",
    "# # test\n",
    "# le.transform(test['month'])\n",
    "# ###########################3333\n",
    "\n",
    "# le.fit_transform(df['month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-928ce50833fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "df['dd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apr', 'aug', 'dec', 'feb', 'jan']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(le.inverse_transform([ 0,  1,  2,  3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_1</th>\n",
       "      <th>job_2</th>\n",
       "      <th>job_3</th>\n",
       "      <th>job_4</th>\n",
       "      <th>job_5</th>\n",
       "      <th>job_6</th>\n",
       "      <th>job_7</th>\n",
       "      <th>job_8</th>\n",
       "      <th>job_9</th>\n",
       "      <th>...</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_1</th>\n",
       "      <th>poutcome_2</th>\n",
       "      <th>poutcome_3</th>\n",
       "      <th>poutcome_4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27123</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27124</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>362</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27125</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27126</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27127</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27128 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  job_1  job_2  job_3  job_4  job_5  job_6  job_7  job_8  job_9  \\\n",
       "0       39      1      0      0      0      0      0      0      0      0   \n",
       "1       51      0      1      0      0      0      0      0      0      0   \n",
       "2       36      0      0      1      0      0      0      0      0      0   \n",
       "3       63      0      0      0      1      0      0      0      0      0   \n",
       "4       31      0      0      1      0      0      0      0      0      0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "27123   42      1      0      0      0      0      0      0      0      0   \n",
       "27124   34      0      0      0      0      1      0      0      0      0   \n",
       "27125   36      1      0      0      0      0      0      0      0      0   \n",
       "27126   33      0      0      0      0      0      0      0      0      1   \n",
       "27127   29      0      0      0      0      1      0      0      0      0   \n",
       "\n",
       "       ...  day  month  duration  campaign  previous  poutcome_1  poutcome_2  \\\n",
       "0      ...    3    4.0       939         1         0           1           0   \n",
       "1      ...   18    2.0       172        10         0           1           0   \n",
       "2      ...   13    4.0       567         1         2           0           1   \n",
       "3      ...   25    1.0       423         1         0           1           0   \n",
       "4      ...   30    4.0       502         1         2           0           0   \n",
       "...    ...  ...    ...       ...       ...       ...         ...         ...   \n",
       "27123  ...    2    2.0       279         2         2           0           0   \n",
       "27124  ...   15    5.0       362         3         0           1           0   \n",
       "27125  ...    8    5.0       405         1         0           1           0   \n",
       "27126  ...   12    8.0        76         4         0           1           0   \n",
       "27127  ...   18    5.0       105         1         2           0           1   \n",
       "\n",
       "       poutcome_3  poutcome_4  y  \n",
       "0               0           0  1  \n",
       "1               0           0  1  \n",
       "2               0           0  1  \n",
       "3               0           0  1  \n",
       "4               1           0  1  \n",
       "...           ...         ... ..  \n",
       "27123           0           1  0  \n",
       "27124           0           0  0  \n",
       "27125           0           0  0  \n",
       "27126           0           0  0  \n",
       "27127           0           0  0  \n",
       "\n",
       "[27128 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job, marital, education, housing, loan, contact, poutcome\n",
    "cols = ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'poutcome']\n",
    "ce_onehot = ce.OneHotEncoder(cols=cols,handle_unknown='impute')\n",
    "ce_onehot.fit( df2 )\n",
    "df2 = ce_onehot.transform( df2 )\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unknown', 'failure', 'success', 'other'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['poutcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27128x12 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(df['job'].values.reshape(-1, 1))\n",
    "ohe.transform(df['job'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['duration'] = df2['duration'] / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('mytrain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "#import optuna\n",
    "from optuna.integration import lightgbm as lgb_optuna\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "random_state = 1234\n",
    "version = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in d:\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from optuna) (1.18.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from optuna) (20.4)\n",
      "Requirement already satisfied: cmaes>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from optuna) (0.6.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from optuna) (1.3.19)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yanai\\appdata\\roaming\\python\\python37\\site-packages (from optuna) (4.48.2)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from optuna) (0.16.0)\n",
      "Requirement already satisfied: cliff in d:\\anaconda3\\lib\\site-packages (from optuna) (3.4.0)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\yanai\\appdata\\roaming\\python\\python37\\site-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: alembic in d:\\anaconda3\\lib\\site-packages (from optuna) (1.4.3)\n",
      "Requirement already satisfied: colorlog in d:\\anaconda3\\lib\\site-packages (from optuna) (4.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (1.15.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in d:\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.2.2)\n",
      "Requirement already satisfied: cmd2!=0.8.3,>=0.8.0 in d:\\anaconda3\\lib\\site-packages (from cliff->optuna) (1.3.9)\n",
      "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in d:\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.7.2)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.5.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in d:\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.3.1)\n",
      "Requirement already satisfied: python-editor>=0.3 in d:\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in d:\\anaconda3\\lib\\site-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: Mako in d:\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.1.3)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in d:\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in d:\\anaconda3\\lib\\site-packages (from stevedore>=2.0.1->cliff->optuna) (1.7.0)\n",
      "Requirement already satisfied: attrs>=16.3.0 in d:\\anaconda3\\lib\\site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.1.0)\n",
      "Requirement already satisfied: pyreadline; sys_platform == \"win32\" in d:\\anaconda3\\lib\\site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (2.1)\n",
      "Requirement already satisfied: setuptools>=34.4 in d:\\anaconda3\\lib\\site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.6.0.post20200814)\n",
      "Requirement already satisfied: pyperclip>=1.6 in d:\\anaconda3\\lib\\site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in d:\\anaconda3\\lib\\site-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('mytrain.csv')\n",
    "\n",
    "X = df_train.drop( columns=['y'] )\n",
    "y = df_train['y']\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-26 12:10:45,773] A new study created in memory with name: no-name-7c99d2b4-1dd6-441f-92a3-dec7cacb00d9\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.237626 + 0.00176039\n",
      "[40]\tcv_agg's binary_logloss: 0.215991 + 0.00144202\n",
      "[60]\tcv_agg's binary_logloss: 0.209778 + 0.00177675\n",
      "[80]\tcv_agg's binary_logloss: 0.204881 + 0.00233342\n",
      "[100]\tcv_agg's binary_logloss: 0.203336 + 0.00232523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.203323:  14%|######4                                      | 1/7 [00:01<00:08,  1.48s/it][I 2020-09-26 12:10:47,367] Trial 0 finished with value: 0.203322512168848 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.203322512168848.\n",
      "feature_fraction, val_score: 0.203323:  14%|######4                                      | 1/7 [00:01<00:08,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221696 + 0.00307774\n",
      "[40]\tcv_agg's binary_logloss: 0.204701 + 0.00317867\n",
      "[60]\tcv_agg's binary_logloss: 0.202116 + 0.00283991\n",
      "[80]\tcv_agg's binary_logloss: 0.200561 + 0.00292573\n",
      "[100]\tcv_agg's binary_logloss: 0.200474 + 0.00292973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.200348:  29%|############8                                | 2/7 [00:02<00:06,  1.40s/it][I 2020-09-26 12:10:48,579] Trial 1 finished with value: 0.20034791939498997 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.20034791939498997.\n",
      "feature_fraction, val_score: 0.200348:  29%|############8                                | 2/7 [00:02<00:06,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.226003 + 0.00261856\n",
      "[40]\tcv_agg's binary_logloss: 0.207751 + 0.00213135\n",
      "[60]\tcv_agg's binary_logloss: 0.203906 + 0.00213602\n",
      "[80]\tcv_agg's binary_logloss: 0.201383 + 0.00242195\n",
      "[100]\tcv_agg's binary_logloss: 0.200606 + 0.00237127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.200348:  43%|###################2                         | 3/7 [00:04<00:05,  1.39s/it][I 2020-09-26 12:10:49,967] Trial 2 finished with value: 0.2005299043866114 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.20034791939498997.\n",
      "feature_fraction, val_score: 0.200348:  43%|###################2                         | 3/7 [00:04<00:05,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.218074 + 0.00296818\n",
      "[40]\tcv_agg's binary_logloss: 0.204119 + 0.0033036\n",
      "[60]\tcv_agg's binary_logloss: 0.201939 + 0.00276417\n",
      "[80]\tcv_agg's binary_logloss: 0.201783 + 0.00233527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.200348:  57%|#########################7                   | 4/7 [00:05<00:03,  1.29s/it][I 2020-09-26 12:10:51,024] Trial 3 finished with value: 0.20165260356756237 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.20034791939498997.\n",
      "feature_fraction, val_score: 0.200348:  57%|#########################7                   | 4/7 [00:05<00:03,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.218702 + 0.00325619\n",
      "[40]\tcv_agg's binary_logloss: 0.203214 + 0.00254437\n",
      "[60]\tcv_agg's binary_logloss: 0.200856 + 0.0030724\n",
      "[80]\tcv_agg's binary_logloss: 0.200297 + 0.00302145\n",
      "[100]\tcv_agg's binary_logloss: 0.200397 + 0.00332428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.200165:  71%|################################1            | 5/7 [00:06<00:02,  1.29s/it][I 2020-09-26 12:10:52,306] Trial 4 finished with value: 0.2001645495097495 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.2001645495097495.\n",
      "feature_fraction, val_score: 0.200165:  71%|################################1            | 5/7 [00:06<00:02,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220469 + 0.00261315\n",
      "[40]\tcv_agg's binary_logloss: 0.203594 + 0.00281805\n",
      "[60]\tcv_agg's binary_logloss: 0.20114 + 0.00283402\n",
      "[80]\tcv_agg's binary_logloss: 0.200055 + 0.00310897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.199817:  86%|######################################5      | 6/7 [00:07<00:01,  1.28s/it][I 2020-09-26 12:10:53,576] Trial 5 finished with value: 0.199817492351368 and parameters: {'feature_fraction': 0.7}. Best is trial 5 with value: 0.199817492351368.\n",
      "feature_fraction, val_score: 0.199817:  86%|######################################5      | 6/7 [00:07<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.21834 + 0.00310314\n",
      "[40]\tcv_agg's binary_logloss: 0.204073 + 0.0032759\n",
      "[60]\tcv_agg's binary_logloss: 0.201744 + 0.0032656\n",
      "[80]\tcv_agg's binary_logloss: 0.2012 + 0.00308102\n",
      "[100]\tcv_agg's binary_logloss: 0.201148 + 0.00277404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.199817: 100%|#############################################| 7/7 [00:09<00:00,  1.31s/it][I 2020-09-26 12:10:54,933] Trial 6 finished with value: 0.20097922574214033 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 5 with value: 0.199817492351368.\n",
      "feature_fraction, val_score: 0.199817: 100%|#############################################| 7/7 [00:09<00:00,  1.29s/it]\n",
      "num_leaves, val_score: 0.199817:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215548 + 0.00167982\n",
      "[40]\tcv_agg's binary_logloss: 0.207876 + 0.00174201\n",
      "[60]\tcv_agg's binary_logloss: 0.212677 + 0.00157009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199817:   5%|##5                                               | 1/20 [00:03<00:57,  3.02s/it][I 2020-09-26 12:10:57,966] Trial 7 finished with value: 0.20783136806140584 and parameters: {'num_leaves': 211}. Best is trial 7 with value: 0.20783136806140584.\n",
      "num_leaves, val_score: 0.199817:   5%|##5                                               | 1/20 [00:03<00:57,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215653 + 0.00179529\n",
      "[40]\tcv_agg's binary_logloss: 0.207169 + 0.00135466\n",
      "[60]\tcv_agg's binary_logloss: 0.211365 + 0.0015842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199817:  10%|#####                                             | 2/20 [00:05<00:50,  2.82s/it][I 2020-09-26 12:11:00,318] Trial 8 finished with value: 0.20716852940984104 and parameters: {'num_leaves': 184}. Best is trial 8 with value: 0.20716852940984104.\n",
      "num_leaves, val_score: 0.199817:  10%|#####                                             | 2/20 [00:05<00:50,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.229349 + 0.00288557\n",
      "[40]\tcv_agg's binary_logloss: 0.209478 + 0.00379661\n",
      "[60]\tcv_agg's binary_logloss: 0.204818 + 0.00346572\n",
      "[80]\tcv_agg's binary_logloss: 0.202121 + 0.00306184\n",
      "[100]\tcv_agg's binary_logloss: 0.201135 + 0.00336319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199817:  15%|#######5                                          | 3/20 [00:06<00:38,  2.26s/it][I 2020-09-26 12:11:01,257] Trial 9 finished with value: 0.20113466866660254 and parameters: {'num_leaves': 15}. Best is trial 9 with value: 0.20113466866660254.\n",
      "num_leaves, val_score: 0.199817:  15%|#######5                                          | 3/20 [00:06<00:38,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.219812 + 0.00279968\n",
      "[40]\tcv_agg's binary_logloss: 0.203723 + 0.00280438\n",
      "[60]\tcv_agg's binary_logloss: 0.200951 + 0.00255492\n",
      "[80]\tcv_agg's binary_logloss: 0.20002 + 0.00215368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  20%|##########                                        | 4/20 [00:07<00:31,  1.97s/it][I 2020-09-26 12:11:02,567] Trial 10 finished with value: 0.199573162704168 and parameters: {'num_leaves': 32}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  20%|##########                                        | 4/20 [00:07<00:31,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.223455 + 0.00292686\n",
      "[40]\tcv_agg's binary_logloss: 0.205546 + 0.00316379\n",
      "[60]\tcv_agg's binary_logloss: 0.201526 + 0.00260161\n",
      "[80]\tcv_agg's binary_logloss: 0.200003 + 0.00273062\n",
      "[100]\tcv_agg's binary_logloss: 0.199739 + 0.00246007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  25%|############5                                     | 5/20 [00:08<00:25,  1.70s/it][I 2020-09-26 12:11:03,634] Trial 11 finished with value: 0.1996576099236549 and parameters: {'num_leaves': 22}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  25%|############5                                     | 5/20 [00:08<00:25,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.231449 + 0.00306737\n",
      "[40]\tcv_agg's binary_logloss: 0.211334 + 0.00408006\n",
      "[60]\tcv_agg's binary_logloss: 0.205716 + 0.00353275\n",
      "[80]\tcv_agg's binary_logloss: 0.203037 + 0.00356905\n",
      "[100]\tcv_agg's binary_logloss: 0.201842 + 0.00317335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  30%|###############                                   | 6/20 [00:09<00:20,  1.46s/it][I 2020-09-26 12:11:04,516] Trial 12 finished with value: 0.2018419848975233 and parameters: {'num_leaves': 13}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  30%|###############                                   | 6/20 [00:09<00:20,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215693 + 0.00260093\n",
      "[40]\tcv_agg's binary_logloss: 0.203137 + 0.00220519\n",
      "[60]\tcv_agg's binary_logloss: 0.202987 + 0.00210913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  35%|#################5                                | 7/20 [00:11<00:19,  1.49s/it][I 2020-09-26 12:11:06,088] Trial 13 finished with value: 0.20255259004009263 and parameters: {'num_leaves': 77}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  35%|#################5                                | 7/20 [00:11<00:19,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215147 + 0.002693\n",
      "[40]\tcv_agg's binary_logloss: 0.202774 + 0.00304535\n",
      "[60]\tcv_agg's binary_logloss: 0.202988 + 0.00291747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  40%|####################                              | 8/20 [00:12<00:18,  1.51s/it][I 2020-09-26 12:11:07,642] Trial 14 finished with value: 0.2022172769775879 and parameters: {'num_leaves': 76}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  40%|####################                              | 8/20 [00:12<00:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.265491 + 0.00221314\n",
      "[40]\tcv_agg's binary_logloss: 0.247073 + 0.00266006\n",
      "[60]\tcv_agg's binary_logloss: 0.23916 + 0.00245628\n",
      "[80]\tcv_agg's binary_logloss: 0.234156 + 0.00278162\n",
      "[100]\tcv_agg's binary_logloss: 0.230341 + 0.00309592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  45%|######################5                           | 9/20 [00:13<00:13,  1.23s/it][I 2020-09-26 12:11:08,226] Trial 15 finished with value: 0.23034147833882174 and parameters: {'num_leaves': 3}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  45%|######################5                           | 9/20 [00:13<00:13,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215456 + 0.00292109\n",
      "[40]\tcv_agg's binary_logloss: 0.203098 + 0.00274639\n",
      "[60]\tcv_agg's binary_logloss: 0.203109 + 0.00287077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  50%|########################5                        | 10/20 [00:14<00:13,  1.33s/it][I 2020-09-26 12:11:09,784] Trial 16 finished with value: 0.2027173441717232 and parameters: {'num_leaves': 74}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  50%|########################5                        | 10/20 [00:14<00:13,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215161 + 0.00169991\n",
      "[40]\tcv_agg's binary_logloss: 0.205457 + 0.00228914\n",
      "[60]\tcv_agg's binary_logloss: 0.207047 + 0.00238288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  55%|##########################9                      | 11/20 [00:16<00:13,  1.47s/it][I 2020-09-26 12:11:11,569] Trial 17 finished with value: 0.20533583414235138 and parameters: {'num_leaves': 122}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  55%|##########################9                      | 11/20 [00:16<00:13,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.218244 + 0.00268171\n",
      "[40]\tcv_agg's binary_logloss: 0.202836 + 0.00227375\n",
      "[60]\tcv_agg's binary_logloss: 0.201411 + 0.00208405\n",
      "[80]\tcv_agg's binary_logloss: 0.201105 + 0.00236338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  60%|#############################4                   | 12/20 [00:18<00:11,  1.45s/it][I 2020-09-26 12:11:12,974] Trial 18 finished with value: 0.20056939391642273 and parameters: {'num_leaves': 44}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  60%|#############################4                   | 12/20 [00:18<00:11,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215351 + 0.00224864\n",
      "[40]\tcv_agg's binary_logloss: 0.205495 + 0.0022852\n",
      "[60]\tcv_agg's binary_logloss: 0.207777 + 0.00246127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  65%|###############################8                 | 13/20 [00:20<00:11,  1.62s/it][I 2020-09-26 12:11:14,991] Trial 19 finished with value: 0.20535473898098044 and parameters: {'num_leaves': 145}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  65%|###############################8                 | 13/20 [00:20<00:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.219281 + 0.00310684\n",
      "[40]\tcv_agg's binary_logloss: 0.203036 + 0.00272075\n",
      "[60]\tcv_agg's binary_logloss: 0.200804 + 0.00265101\n",
      "[80]\tcv_agg's binary_logloss: 0.200097 + 0.00276533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  70%|##################################3              | 14/20 [00:21<00:08,  1.50s/it][I 2020-09-26 12:11:16,203] Trial 20 finished with value: 0.19986883022316798 and parameters: {'num_leaves': 35}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  70%|##################################3              | 14/20 [00:21<00:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.214874 + 0.00218097\n",
      "[40]\tcv_agg's binary_logloss: 0.209182 + 0.00156404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  75%|####################################7            | 15/20 [00:23<00:09,  1.86s/it][I 2020-09-26 12:11:18,906] Trial 21 finished with value: 0.20893825355764478 and parameters: {'num_leaves': 251}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  75%|####################################7            | 15/20 [00:23<00:09,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.214662 + 0.00279499\n",
      "[40]\tcv_agg's binary_logloss: 0.204269 + 0.0025147\n",
      "[60]\tcv_agg's binary_logloss: 0.205268 + 0.00236488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  80%|#######################################2         | 16/20 [00:25<00:07,  1.78s/it][I 2020-09-26 12:11:20,513] Trial 22 finished with value: 0.2041806802360727 and parameters: {'num_leaves': 112}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  80%|#######################################2         | 16/20 [00:25<00:07,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.217351 + 0.00246665\n",
      "[40]\tcv_agg's binary_logloss: 0.202249 + 0.00231201\n",
      "[60]\tcv_agg's binary_logloss: 0.200889 + 0.00273788\n",
      "[80]\tcv_agg's binary_logloss: 0.201042 + 0.00278567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  85%|#########################################6       | 17/20 [00:26<00:04,  1.65s/it][I 2020-09-26 12:11:21,845] Trial 23 finished with value: 0.200496342242853 and parameters: {'num_leaves': 48}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  85%|#########################################6       | 17/20 [00:26<00:04,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.215074 + 0.00243753\n",
      "[40]\tcv_agg's binary_logloss: 0.204279 + 0.0023557\n",
      "[60]\tcv_agg's binary_logloss: 0.204785 + 0.0019361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  90%|############################################1    | 18/20 [00:28<00:03,  1.63s/it][I 2020-09-26 12:11:23,437] Trial 24 finished with value: 0.204040252938778 and parameters: {'num_leaves': 100}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  90%|############################################1    | 18/20 [00:28<00:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.214773 + 0.00214154\n",
      "[40]\tcv_agg's binary_logloss: 0.205901 + 0.00280276\n",
      "[60]\tcv_agg's binary_logloss: 0.208477 + 0.00245361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199573:  95%|##############################################5  | 19/20 [00:30<00:01,  1.81s/it][I 2020-09-26 12:11:25,665] Trial 25 finished with value: 0.20589774392065877 and parameters: {'num_leaves': 159}. Best is trial 10 with value: 0.199573162704168.\n",
      "num_leaves, val_score: 0.199573:  95%|##############################################5  | 19/20 [00:30<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220384 + 0.00228101\n",
      "[40]\tcv_agg's binary_logloss: 0.20354 + 0.00299875\n",
      "[60]\tcv_agg's binary_logloss: 0.200385 + 0.00298831\n",
      "[80]\tcv_agg's binary_logloss: 0.199749 + 0.00294269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199568: 100%|#################################################| 20/20 [00:31<00:00,  1.62s/it][I 2020-09-26 12:11:26,841] Trial 26 finished with value: 0.1995679942171739 and parameters: {'num_leaves': 29}. Best is trial 26 with value: 0.1995679942171739.\n",
      "num_leaves, val_score: 0.199568: 100%|#################################################| 20/20 [00:31<00:00,  1.60s/it]\n",
      "bagging, val_score: 0.199568:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.222789 + 0.00303733\n",
      "[40]\tcv_agg's binary_logloss: 0.207208 + 0.00332997\n",
      "[60]\tcv_agg's binary_logloss: 0.205947 + 0.00331725\n",
      "[80]\tcv_agg's binary_logloss: 0.205165 + 0.00338979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199568:  10%|#####3                                               | 1/10 [00:01<00:11,  1.25s/it][I 2020-09-26 12:11:28,101] Trial 27 finished with value: 0.2049066630146535 and parameters: {'bagging_fraction': 0.5386271090099395, 'bagging_freq': 5}. Best is trial 27 with value: 0.2049066630146535.\n",
      "bagging, val_score: 0.199568:  10%|#####3                                               | 1/10 [00:01<00:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220921 + 0.0026516\n",
      "[40]\tcv_agg's binary_logloss: 0.203552 + 0.00274431\n",
      "[60]\tcv_agg's binary_logloss: 0.200762 + 0.00286641\n",
      "[80]\tcv_agg's binary_logloss: 0.199589 + 0.00289496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199434:  20%|##########6                                          | 2/10 [00:02<00:09,  1.25s/it][I 2020-09-26 12:11:29,347] Trial 28 finished with value: 0.1994341649996531 and parameters: {'bagging_fraction': 0.9976120698658768, 'bagging_freq': 1}. Best is trial 28 with value: 0.1994341649996531.\n",
      "bagging, val_score: 0.199434:  20%|##########6                                          | 2/10 [00:02<00:09,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220692 + 0.00269201\n",
      "[40]\tcv_agg's binary_logloss: 0.203754 + 0.00281169\n",
      "[60]\tcv_agg's binary_logloss: 0.200858 + 0.00275005\n",
      "[80]\tcv_agg's binary_logloss: 0.199622 + 0.00298485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199434:  30%|###############9                                     | 3/10 [00:03<00:08,  1.23s/it][I 2020-09-26 12:11:30,530] Trial 29 finished with value: 0.19951072655632635 and parameters: {'bagging_fraction': 0.999646402126131, 'bagging_freq': 1}. Best is trial 28 with value: 0.1994341649996531.\n",
      "bagging, val_score: 0.199434:  30%|###############9                                     | 3/10 [00:03<00:08,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220655 + 0.00309113\n",
      "[40]\tcv_agg's binary_logloss: 0.203666 + 0.00327988\n",
      "[60]\tcv_agg's binary_logloss: 0.200783 + 0.00305395\n",
      "[80]\tcv_agg's binary_logloss: 0.199616 + 0.00356554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199434:  40%|#####################2                               | 4/10 [00:04<00:07,  1.24s/it][I 2020-09-26 12:11:31,788] Trial 30 finished with value: 0.19945033309338872 and parameters: {'bagging_fraction': 0.9838122207533433, 'bagging_freq': 1}. Best is trial 28 with value: 0.1994341649996531.\n",
      "bagging, val_score: 0.199434:  40%|#####################2                               | 4/10 [00:04<00:07,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220828 + 0.00241392\n",
      "[40]\tcv_agg's binary_logloss: 0.203882 + 0.00302708\n",
      "[60]\tcv_agg's binary_logloss: 0.200649 + 0.00283696\n",
      "[80]\tcv_agg's binary_logloss: 0.199436 + 0.0029773\n",
      "[100]\tcv_agg's binary_logloss: 0.199255 + 0.00293847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199105:  50%|##########################5                          | 5/10 [00:06<00:06,  1.24s/it][I 2020-09-26 12:11:33,020] Trial 31 finished with value: 0.19910537315076954 and parameters: {'bagging_fraction': 0.9989938983437786, 'bagging_freq': 1}. Best is trial 31 with value: 0.19910537315076954.\n",
      "bagging, val_score: 0.199105:  50%|##########################5                          | 5/10 [00:06<00:06,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220744 + 0.00285209\n",
      "[40]\tcv_agg's binary_logloss: 0.203857 + 0.00243272\n",
      "[60]\tcv_agg's binary_logloss: 0.200846 + 0.00236885\n",
      "[80]\tcv_agg's binary_logloss: 0.199666 + 0.00236876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199105:  60%|###############################8                     | 6/10 [00:07<00:04,  1.23s/it][I 2020-09-26 12:11:34,247] Trial 32 finished with value: 0.19954148995642018 and parameters: {'bagging_fraction': 0.9922899475356188, 'bagging_freq': 1}. Best is trial 31 with value: 0.19910537315076954.\n",
      "bagging, val_score: 0.199105:  60%|###############################8                     | 6/10 [00:07<00:04,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221076 + 0.00318186\n",
      "[40]\tcv_agg's binary_logloss: 0.204127 + 0.00347494\n",
      "[60]\tcv_agg's binary_logloss: 0.201594 + 0.00316047\n",
      "[80]\tcv_agg's binary_logloss: 0.200389 + 0.00356718\n",
      "[100]\tcv_agg's binary_logloss: 0.200311 + 0.00385002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199105:  70%|#####################################                | 7/10 [00:08<00:03,  1.25s/it][I 2020-09-26 12:11:35,532] Trial 33 finished with value: 0.20002894373574373 and parameters: {'bagging_fraction': 0.9755142025903074, 'bagging_freq': 1}. Best is trial 31 with value: 0.19910537315076954.\n",
      "bagging, val_score: 0.199105:  70%|#####################################                | 7/10 [00:08<00:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220506 + 0.00237496\n",
      "[40]\tcv_agg's binary_logloss: 0.203975 + 0.00280747\n",
      "[60]\tcv_agg's binary_logloss: 0.200826 + 0.00219793\n",
      "[80]\tcv_agg's binary_logloss: 0.199515 + 0.00203029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199105:  80%|##########################################4          | 8/10 [00:09<00:02,  1.25s/it][I 2020-09-26 12:11:36,789] Trial 34 finished with value: 0.19936760154164457 and parameters: {'bagging_fraction': 0.9916592506585541, 'bagging_freq': 1}. Best is trial 31 with value: 0.19910537315076954.\n",
      "bagging, val_score: 0.199105:  80%|##########################################4          | 8/10 [00:09<00:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220602 + 0.00249383\n",
      "[40]\tcv_agg's binary_logloss: 0.204164 + 0.00241154\n",
      "[60]\tcv_agg's binary_logloss: 0.200872 + 0.00209612\n",
      "[80]\tcv_agg's binary_logloss: 0.200304 + 0.00192942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199105:  90%|###############################################7     | 9/10 [00:11<00:01,  1.25s/it][I 2020-09-26 12:11:38,052] Trial 35 finished with value: 0.20002734198465189 and parameters: {'bagging_fraction': 0.9868109661947531, 'bagging_freq': 1}. Best is trial 31 with value: 0.19910537315076954.\n",
      "bagging, val_score: 0.199105:  90%|###############################################7     | 9/10 [00:11<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221218 + 0.0023477\n",
      "[40]\tcv_agg's binary_logloss: 0.204149 + 0.00247658\n",
      "[60]\tcv_agg's binary_logloss: 0.201918 + 0.0025942\n",
      "[80]\tcv_agg's binary_logloss: 0.200684 + 0.00245085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199105: 100%|####################################################| 10/10 [00:12<00:00,  1.30s/it][I 2020-09-26 12:11:39,459] Trial 36 finished with value: 0.200451516672889 and parameters: {'bagging_fraction': 0.8340728748226867, 'bagging_freq': 3}. Best is trial 31 with value: 0.19910537315076954.\n",
      "bagging, val_score: 0.199105: 100%|####################################################| 10/10 [00:12<00:00,  1.26s/it]\n",
      "feature_fraction_stage2, val_score: 0.199105:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.219073 + 0.00298724\n",
      "[40]\tcv_agg's binary_logloss: 0.203032 + 0.00232167\n",
      "[60]\tcv_agg's binary_logloss: 0.200408 + 0.00272681\n",
      "[80]\tcv_agg's binary_logloss: 0.199179 + 0.00288448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.199105:  17%|######3                               | 1/6 [00:01<00:06,  1.29s/it][I 2020-09-26 12:11:40,761] Trial 37 finished with value: 0.199164264484632 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.199164264484632.\n",
      "feature_fraction_stage2, val_score: 0.199105:  17%|######3                               | 1/6 [00:01<00:06,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221842 + 0.00232934\n",
      "[40]\tcv_agg's binary_logloss: 0.204682 + 0.00289183\n",
      "[60]\tcv_agg's binary_logloss: 0.201774 + 0.00263212\n",
      "[80]\tcv_agg's binary_logloss: 0.200114 + 0.00241543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.199105:  33%|############6                         | 2/6 [00:02<00:05,  1.25s/it][I 2020-09-26 12:11:41,913] Trial 38 finished with value: 0.1998525677866792 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.199164264484632.\n",
      "feature_fraction_stage2, val_score: 0.199105:  33%|############6                         | 2/6 [00:02<00:05,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.219439 + 0.0033013\n",
      "[40]\tcv_agg's binary_logloss: 0.202927 + 0.00269005\n",
      "[60]\tcv_agg's binary_logloss: 0.200118 + 0.00310654\n",
      "[80]\tcv_agg's binary_logloss: 0.199458 + 0.0027639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.199105:  50%|###################                   | 3/6 [00:03<00:03,  1.22s/it][I 2020-09-26 12:11:43,073] Trial 39 finished with value: 0.19929232169756822 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.199164264484632.\n",
      "feature_fraction_stage2, val_score: 0.199105:  50%|###################                   | 3/6 [00:03<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.222143 + 0.00297615\n",
      "[40]\tcv_agg's binary_logloss: 0.204725 + 0.00283861\n",
      "[60]\tcv_agg's binary_logloss: 0.201838 + 0.00272984\n",
      "[80]\tcv_agg's binary_logloss: 0.199889 + 0.00321738\n",
      "[100]\tcv_agg's binary_logloss: 0.199627 + 0.00309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.199105:  67%|#########################3            | 4/6 [00:04<00:02,  1.22s/it][I 2020-09-26 12:11:44,295] Trial 40 finished with value: 0.19952688652144732 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.199164264484632.\n",
      "feature_fraction_stage2, val_score: 0.199105:  67%|#########################3            | 4/6 [00:04<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220201 + 0.00308785\n",
      "[40]\tcv_agg's binary_logloss: 0.203564 + 0.00276256\n",
      "[60]\tcv_agg's binary_logloss: 0.200716 + 0.00223694\n",
      "[80]\tcv_agg's binary_logloss: 0.199591 + 0.0021906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.199105:  83%|###############################6      | 5/6 [00:06<00:01,  1.21s/it][I 2020-09-26 12:11:45,475] Trial 41 finished with value: 0.19944927866403703 and parameters: {'feature_fraction': 0.716}. Best is trial 37 with value: 0.199164264484632.\n",
      "feature_fraction_stage2, val_score: 0.199105:  83%|###############################6      | 5/6 [00:06<00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220828 + 0.00241392\n",
      "[40]\tcv_agg's binary_logloss: 0.203882 + 0.00302708\n",
      "[60]\tcv_agg's binary_logloss: 0.200649 + 0.00283696\n",
      "[80]\tcv_agg's binary_logloss: 0.199436 + 0.0029773\n",
      "[100]\tcv_agg's binary_logloss: 0.199255 + 0.00293847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.199105: 100%|######################################| 6/6 [00:07<00:00,  1.19s/it][I 2020-09-26 12:11:46,632] Trial 42 finished with value: 0.19910537315076954 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 42 with value: 0.19910537315076954.\n",
      "feature_fraction_stage2, val_score: 0.199105: 100%|######################################| 6/6 [00:07<00:00,  1.19s/it]\n",
      "regularization_factors, val_score: 0.199105:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220966 + 0.00235998\n",
      "[40]\tcv_agg's binary_logloss: 0.203992 + 0.00297485\n",
      "[60]\tcv_agg's binary_logloss: 0.200722 + 0.00266166\n",
      "[80]\tcv_agg's binary_logloss: 0.199872 + 0.00318651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:   5%|#9                                    | 1/20 [00:01<00:22,  1.18s/it][I 2020-09-26 12:11:47,819] Trial 43 finished with value: 0.19969940019357352 and parameters: {'lambda_l1': 0.00015086187775610103, 'lambda_l2': 1.5920748777871013e-06}. Best is trial 43 with value: 0.19969940019357352.\n",
      "regularization_factors, val_score: 0.199105:   5%|#9                                    | 1/20 [00:01<00:22,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.224725 + 0.00284127\n",
      "[40]\tcv_agg's binary_logloss: 0.206582 + 0.00284691\n",
      "[60]\tcv_agg's binary_logloss: 0.202415 + 0.00252291\n",
      "[80]\tcv_agg's binary_logloss: 0.200321 + 0.00217608\n",
      "[100]\tcv_agg's binary_logloss: 0.199196 + 0.0020672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  10%|###8                                  | 2/20 [00:02<00:21,  1.21s/it][I 2020-09-26 12:11:49,117] Trial 44 finished with value: 0.19918666285845382 and parameters: {'lambda_l1': 2.9356417557452734, 'lambda_l2': 2.175408503764047}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  10%|###8                                  | 2/20 [00:02<00:21,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.228039 + 0.0025786\n",
      "[40]\tcv_agg's binary_logloss: 0.208863 + 0.00263978\n",
      "[60]\tcv_agg's binary_logloss: 0.204209 + 0.00264402\n",
      "[80]\tcv_agg's binary_logloss: 0.201051 + 0.00253279\n",
      "[100]\tcv_agg's binary_logloss: 0.200029 + 0.00260415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  15%|#####7                                | 3/20 [00:03<00:21,  1.25s/it][I 2020-09-26 12:11:50,455] Trial 45 finished with value: 0.20002899216660217 and parameters: {'lambda_l1': 1.8188560261432503, 'lambda_l2': 9.935848682718285}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  15%|#####7                                | 3/20 [00:03<00:21,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.227992 + 0.00249619\n",
      "[40]\tcv_agg's binary_logloss: 0.208805 + 0.00318197\n",
      "[60]\tcv_agg's binary_logloss: 0.203962 + 0.00273977\n",
      "[80]\tcv_agg's binary_logloss: 0.200747 + 0.00279574\n",
      "[100]\tcv_agg's binary_logloss: 0.199293 + 0.00270123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  20%|#######6                              | 4/20 [00:05<00:20,  1.27s/it][I 2020-09-26 12:11:51,768] Trial 46 finished with value: 0.19929257018256566 and parameters: {'lambda_l1': 2.928853585878741, 'lambda_l2': 8.010653440088772}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  20%|#######6                              | 4/20 [00:05<00:20,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220644 + 0.00272356\n",
      "[40]\tcv_agg's binary_logloss: 0.203979 + 0.00288856\n",
      "[60]\tcv_agg's binary_logloss: 0.200764 + 0.00303897\n",
      "[80]\tcv_agg's binary_logloss: 0.199628 + 0.00338963\n",
      "[100]\tcv_agg's binary_logloss: 0.199331 + 0.00288221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  25%|#########5                            | 5/20 [00:06<00:18,  1.24s/it][I 2020-09-26 12:11:52,948] Trial 47 finished with value: 0.19933122687081065 and parameters: {'lambda_l1': 2.174955276394934e-08, 'lambda_l2': 0.006254004616894754}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  25%|#########5                            | 5/20 [00:06<00:18,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220662 + 0.00278115\n",
      "[40]\tcv_agg's binary_logloss: 0.203827 + 0.00275683\n",
      "[60]\tcv_agg's binary_logloss: 0.201093 + 0.00278174\n",
      "[80]\tcv_agg's binary_logloss: 0.200149 + 0.00293213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  30%|###########4                          | 6/20 [00:07<00:16,  1.21s/it][I 2020-09-26 12:11:54,069] Trial 48 finished with value: 0.19984099599088895 and parameters: {'lambda_l1': 0.0022424046663302587, 'lambda_l2': 0.007919365773274597}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  30%|###########4                          | 6/20 [00:07<00:16,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220895 + 0.00225664\n",
      "[40]\tcv_agg's binary_logloss: 0.204217 + 0.00303384\n",
      "[60]\tcv_agg's binary_logloss: 0.200758 + 0.00255407\n",
      "[80]\tcv_agg's binary_logloss: 0.199766 + 0.00289666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  35%|#############3                        | 7/20 [00:08<00:15,  1.18s/it][I 2020-09-26 12:11:55,190] Trial 49 finished with value: 0.19961980381122574 and parameters: {'lambda_l1': 0.0015466176589904069, 'lambda_l2': 1.1147185341993515e-08}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  35%|#############3                        | 7/20 [00:08<00:15,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tcv_agg's binary_logloss: 0.22918 + 0.00230663\n",
      "[40]\tcv_agg's binary_logloss: 0.211332 + 0.00292566\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tcv_agg's binary_logloss: 0.206552 + 0.00293194\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tcv_agg's binary_logloss: 0.203125 + 0.00295022\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tcv_agg's binary_logloss: 0.201355 + 0.0027146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  40%|###############2                      | 8/20 [00:10<00:15,  1.29s/it][I 2020-09-26 12:11:56,731] Trial 50 finished with value: 0.20135450735996252 and parameters: {'lambda_l1': 9.242336258319066, 'lambda_l2': 0.4754781097561588}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  40%|###############2                      | 8/20 [00:10<00:15,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.226532 + 0.0022568\n",
      "[40]\tcv_agg's binary_logloss: 0.207337 + 0.00252967\n",
      "[60]\tcv_agg's binary_logloss: 0.203241 + 0.00251053\n",
      "[80]\tcv_agg's binary_logloss: 0.2007 + 0.00244887\n",
      "[100]\tcv_agg's binary_logloss: 0.199858 + 0.00207513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  45%|#################1                    | 9/20 [00:11<00:14,  1.28s/it][I 2020-09-26 12:11:57,989] Trial 51 finished with value: 0.1997968853007942 and parameters: {'lambda_l1': 0.8208339811940774, 'lambda_l2': 8.563118262906444}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  45%|#################1                    | 9/20 [00:11<00:14,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221419 + 0.00277665\n",
      "[40]\tcv_agg's binary_logloss: 0.204307 + 0.00283315\n",
      "[60]\tcv_agg's binary_logloss: 0.20089 + 0.00244934\n",
      "[80]\tcv_agg's binary_logloss: 0.200063 + 0.00257804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  50%|##################5                  | 10/20 [00:12<00:12,  1.23s/it][I 2020-09-26 12:11:59,103] Trial 52 finished with value: 0.19977615091395107 and parameters: {'lambda_l1': 0.1260082255706776, 'lambda_l2': 0.29331318180215465}. Best is trial 44 with value: 0.19918666285845382.\n",
      "regularization_factors, val_score: 0.199105:  50%|##################5                  | 10/20 [00:12<00:12,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.225089 + 0.00187591\n",
      "[40]\tcv_agg's binary_logloss: 0.206126 + 0.00206716\n",
      "[60]\tcv_agg's binary_logloss: 0.202166 + 0.00186927\n",
      "[80]\tcv_agg's binary_logloss: 0.199624 + 0.00201546\n",
      "[100]\tcv_agg's binary_logloss: 0.199192 + 0.00181597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  55%|####################3                | 11/20 [00:13<00:11,  1.24s/it][I 2020-09-26 12:12:00,359] Trial 53 finished with value: 0.19912213158086672 and parameters: {'lambda_l1': 0.06022078573154176, 'lambda_l2': 6.219365942584445}. Best is trial 53 with value: 0.19912213158086672.\n",
      "regularization_factors, val_score: 0.199105:  55%|####################3                | 11/20 [00:13<00:11,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220907 + 0.00246881\n",
      "[40]\tcv_agg's binary_logloss: 0.203984 + 0.00216626\n",
      "[60]\tcv_agg's binary_logloss: 0.200554 + 0.00241033\n",
      "[80]\tcv_agg's binary_logloss: 0.19938 + 0.00269102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  60%|######################2              | 12/20 [00:14<00:09,  1.21s/it][I 2020-09-26 12:12:01,497] Trial 54 finished with value: 0.1991815602718592 and parameters: {'lambda_l1': 0.07159142365806107, 'lambda_l2': 0.11473077094248052}. Best is trial 53 with value: 0.19912213158086672.\n",
      "regularization_factors, val_score: 0.199105:  60%|######################2              | 12/20 [00:14<00:09,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221214 + 0.00299788\n",
      "[40]\tcv_agg's binary_logloss: 0.204005 + 0.00296092\n",
      "[60]\tcv_agg's binary_logloss: 0.201091 + 0.00269432\n",
      "[80]\tcv_agg's binary_logloss: 0.199692 + 0.00295206\n",
      "[100]\tcv_agg's binary_logloss: 0.19983 + 0.00256775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  65%|########################             | 13/20 [00:16<00:08,  1.20s/it][I 2020-09-26 12:12:02,667] Trial 55 finished with value: 0.1995085493280148 and parameters: {'lambda_l1': 0.03544883684565225, 'lambda_l2': 0.18401558367738766}. Best is trial 53 with value: 0.19912213158086672.\n",
      "regularization_factors, val_score: 0.199105:  65%|########################             | 13/20 [00:16<00:08,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.22166 + 0.00228741\n",
      "[40]\tcv_agg's binary_logloss: 0.203818 + 0.00225595\n",
      "[60]\tcv_agg's binary_logloss: 0.200795 + 0.00249876\n",
      "[80]\tcv_agg's binary_logloss: 0.199839 + 0.00302983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  70%|#########################9           | 14/20 [00:17<00:07,  1.18s/it][I 2020-09-26 12:12:03,821] Trial 56 finished with value: 0.19964639477733961 and parameters: {'lambda_l1': 0.03282116590283201, 'lambda_l2': 0.6776272318896638}. Best is trial 53 with value: 0.19912213158086672.\n",
      "regularization_factors, val_score: 0.199105:  70%|#########################9           | 14/20 [00:17<00:07,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220612 + 0.00277201\n",
      "[40]\tcv_agg's binary_logloss: 0.203821 + 0.00312767\n",
      "[60]\tcv_agg's binary_logloss: 0.200843 + 0.00291793\n",
      "[80]\tcv_agg's binary_logloss: 0.199838 + 0.00296837\n",
      "[100]\tcv_agg's binary_logloss: 0.199759 + 0.00299454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199105:  75%|###########################7         | 15/20 [00:18<00:05,  1.18s/it][I 2020-09-26 12:12:04,978] Trial 57 finished with value: 0.19974131873210668 and parameters: {'lambda_l1': 2.2402421228853447e-05, 'lambda_l2': 0.005342816574759356}. Best is trial 53 with value: 0.19912213158086672.\n",
      "regularization_factors, val_score: 0.199105:  75%|###########################7         | 15/20 [00:18<00:05,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220628 + 0.00230285\n",
      "[40]\tcv_agg's binary_logloss: 0.203263 + 0.00302672\n",
      "[60]\tcv_agg's binary_logloss: 0.200524 + 0.0020971\n",
      "[80]\tcv_agg's binary_logloss: 0.199025 + 0.00182564\n",
      "[100]\tcv_agg's binary_logloss: 0.198914 + 0.0019087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.198718:  80%|#############################6       | 16/20 [00:19<00:04,  1.18s/it][I 2020-09-26 12:12:06,160] Trial 58 finished with value: 0.19871777698583684 and parameters: {'lambda_l1': 0.13626152279599965, 'lambda_l2': 3.45010317440551e-05}. Best is trial 58 with value: 0.19871777698583684.\n",
      "regularization_factors, val_score: 0.198718:  80%|#############################6       | 16/20 [00:19<00:04,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220533 + 0.00274367\n",
      "[40]\tcv_agg's binary_logloss: 0.204048 + 0.00318996\n",
      "[60]\tcv_agg's binary_logloss: 0.200697 + 0.00278745\n",
      "[80]\tcv_agg's binary_logloss: 0.200066 + 0.00274777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.198718:  85%|###############################4     | 17/20 [00:20<00:03,  1.16s/it][I 2020-09-26 12:12:07,276] Trial 59 finished with value: 0.19979607170978303 and parameters: {'lambda_l1': 0.009005428908644687, 'lambda_l2': 1.985896521848682e-05}. Best is trial 58 with value: 0.19871777698583684.\n",
      "regularization_factors, val_score: 0.198718:  85%|###############################4     | 17/20 [00:20<00:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220622 + 0.0026607\n",
      "[40]\tcv_agg's binary_logloss: 0.203688 + 0.00317571\n",
      "[60]\tcv_agg's binary_logloss: 0.200493 + 0.00301995\n",
      "[80]\tcv_agg's binary_logloss: 0.199213 + 0.00322303\n",
      "[100]\tcv_agg's binary_logloss: 0.19917 + 0.00302232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.198718:  90%|#################################3   | 18/20 [00:21<00:02,  1.16s/it][I 2020-09-26 12:12:08,453] Trial 60 finished with value: 0.19903151132302188 and parameters: {'lambda_l1': 0.2239098242174187, 'lambda_l2': 1.4827144992861232e-05}. Best is trial 58 with value: 0.19871777698583684.\n",
      "regularization_factors, val_score: 0.198718:  90%|#################################3   | 18/20 [00:21<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.22023 + 0.00208083\n",
      "[40]\tcv_agg's binary_logloss: 0.203814 + 0.00246321\n",
      "[60]\tcv_agg's binary_logloss: 0.200415 + 0.00175653\n",
      "[80]\tcv_agg's binary_logloss: 0.198997 + 0.00198448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.198718:  95%|###################################1 | 19/20 [00:22<00:01,  1.16s/it][I 2020-09-26 12:12:09,597] Trial 61 finished with value: 0.19879288441176732 and parameters: {'lambda_l1': 0.16714221052425662, 'lambda_l2': 9.557990537405981e-06}. Best is trial 58 with value: 0.19871777698583684.\n",
      "regularization_factors, val_score: 0.198718:  95%|###################################1 | 19/20 [00:22<00:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220728 + 0.00299765\n",
      "[40]\tcv_agg's binary_logloss: 0.204002 + 0.00255984\n",
      "[60]\tcv_agg's binary_logloss: 0.20126 + 0.00244843\n",
      "[80]\tcv_agg's binary_logloss: 0.19959 + 0.00304944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.198718: 100%|#####################################| 20/20 [00:24<00:00,  1.16s/it][I 2020-09-26 12:12:10,752] Trial 62 finished with value: 0.1994609661699483 and parameters: {'lambda_l1': 0.35984578810928725, 'lambda_l2': 7.5717697472188646e-06}. Best is trial 58 with value: 0.19871777698583684.\n",
      "regularization_factors, val_score: 0.198718: 100%|#####################################| 20/20 [00:24<00:00,  1.21s/it]\n",
      "min_data_in_leaf, val_score: 0.198718:   0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221236 + 0.00264823\n",
      "[40]\tcv_agg's binary_logloss: 0.204752 + 0.00281018\n",
      "[60]\tcv_agg's binary_logloss: 0.201434 + 0.00215082\n",
      "[80]\tcv_agg's binary_logloss: 0.199717 + 0.00270164\n",
      "[100]\tcv_agg's binary_logloss: 0.199462 + 0.00250232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.198718:  20%|#########                                    | 1/5 [00:01<00:04,  1.17s/it][I 2020-09-26 12:12:11,935] Trial 63 finished with value: 0.19940931340667709 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.19940931340667709.\n",
      "min_data_in_leaf, val_score: 0.198718:  20%|#########                                    | 1/5 [00:01<00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.220589 + 0.00243815\n",
      "[40]\tcv_agg's binary_logloss: 0.203672 + 0.0028995\n",
      "[60]\tcv_agg's binary_logloss: 0.201187 + 0.00261372\n",
      "[80]\tcv_agg's binary_logloss: 0.200012 + 0.00278166\n",
      "[100]\tcv_agg's binary_logloss: 0.199845 + 0.00263545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.198718:  40%|##################                           | 2/5 [00:02<00:03,  1.17s/it][I 2020-09-26 12:12:13,101] Trial 64 finished with value: 0.19972500040763017 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.19940931340667709.\n",
      "min_data_in_leaf, val_score: 0.198718:  40%|##################                           | 2/5 [00:02<00:03,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221035 + 0.00265483\n",
      "[40]\tcv_agg's binary_logloss: 0.204247 + 0.00295564\n",
      "[60]\tcv_agg's binary_logloss: 0.201077 + 0.00230017\n",
      "[80]\tcv_agg's binary_logloss: 0.200063 + 0.00239285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.198718:  60%|###########################                  | 3/5 [00:03<00:02,  1.16s/it][I 2020-09-26 12:12:14,250] Trial 65 finished with value: 0.19974548253483554 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.19940931340667709.\n",
      "min_data_in_leaf, val_score: 0.198718:  60%|###########################                  | 3/5 [00:03<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.221452 + 0.00257427\n",
      "[40]\tcv_agg's binary_logloss: 0.204072 + 0.00281574\n",
      "[60]\tcv_agg's binary_logloss: 0.200637 + 0.00263177\n",
      "[80]\tcv_agg's binary_logloss: 0.19939 + 0.0027896\n",
      "[100]\tcv_agg's binary_logloss: 0.199803 + 0.00234092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.198718:  80%|####################################         | 4/5 [00:04<00:01,  1.19s/it][I 2020-09-26 12:12:15,494] Trial 66 finished with value: 0.19925002891970064 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 0.19925002891970064.\n",
      "min_data_in_leaf, val_score: 0.198718:  80%|####################################         | 4/5 [00:04<00:01,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[20]\tcv_agg's binary_logloss: 0.222925 + 0.00227568\n",
      "[40]\tcv_agg's binary_logloss: 0.204664 + 0.0027099\n",
      "[60]\tcv_agg's binary_logloss: 0.2012 + 0.00254125\n",
      "[80]\tcv_agg's binary_logloss: 0.199978 + 0.0027835\n",
      "[100]\tcv_agg's binary_logloss: 0.199861 + 0.00260536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.198718: 100%|#############################################| 5/5 [00:05<00:00,  1.21s/it][I 2020-09-26 12:12:16,741] Trial 67 finished with value: 0.19973330316098892 and parameters: {'min_child_samples': 100}. Best is trial 66 with value: 0.19925002891970064.\n",
      "min_data_in_leaf, val_score: 0.198718: 100%|#############################################| 5/5 [00:05<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score =  0.19871777698583684\n",
      "Best params=  {'objective': 'binary', 'metric': 'binary_logloss', 'random_state': 1234, 'verbosity': 0, 'feature_pre_filter': False, 'lambda_l1': 0.13626152279599965, 'lambda_l2': 3.45010317440551e-05, 'num_leaves': 29, 'feature_fraction': 0.7, 'bagging_fraction': 0.9989938983437786, 'bagging_freq': 1, 'min_child_samples': 20}\n"
     ]
    }
   ],
   "source": [
    "def build():\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    lgb_train = lgb_optuna.Dataset(X_train, y_train)\n",
    "\n",
    "    lgbm_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'random_state':random_state,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    tunecv = lgb_optuna.LightGBMTunerCV(\n",
    "        lgbm_params,\n",
    "        lgb_train,\n",
    "        num_boost_round=100,\n",
    "        early_stopping_rounds=20,\n",
    "        seed = random_state,\n",
    "        verbose_eval=20,\n",
    "        folds=kf\n",
    "    )\n",
    "\n",
    "    tunecv.run()\n",
    "\n",
    "    print( 'Best score = ',tunecv.best_score)\n",
    "    print( 'Best params= ',tunecv.best_params)\n",
    "\n",
    "    return tunecv\n",
    "\n",
    "tunecv = build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "AUC:  0.9303244394607155\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset( X_train, y_train )\n",
    "eval_data = lgb.Dataset(X_holdout, label=y_holdout, reference= train_data)\n",
    "clf = lgb.train( tunecv.best_params, \n",
    "                train_data,\n",
    "                valid_sets=eval_data,\n",
    "                num_boost_round=50,\n",
    "                verbose_eval=0\n",
    "               )\n",
    "y_pred = clf.predict( X_holdout )\n",
    "print('AUC: ', roc_auc_score(y_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  D  \n",
      "   3417-05D0 \n",
      "\n",
      " D:\\PythonTraining\\Signate\\ \n",
      "\n",
      "2020/09/26  12:14    <DIR>          .\n",
      "2020/09/26  12:14    <DIR>          ..\n",
      "2020/09/26  10:06    <DIR>          .ipynb_checkpoints\n",
      "2020/09/05  13:25         6,180,211 20200905_001.ipynb\n",
      "2020/09/26  11:40         2,591,582 mytrain.csv\n",
      "2020/09/05  09:57           205,890 submit_sample.csv\n",
      "2020/09/05  09:57         1,523,536 test.csv\n",
      "2020/09/05  09:57         2,345,067 train.csv\n",
      "2020/09/26  12:14           322,202 Untitled.ipynb\n",
      "               6           13,168,488 \n",
      "               3   958,166,949,888 \n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('submit_sample.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1028</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>feb</td>\n",
       "      <td>1294</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>426</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>jun</td>\n",
       "      <td>1029</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>-572</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>jun</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-476</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>27</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>62</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>31</td>\n",
       "      <td>jul</td>\n",
       "      <td>404</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>18079</td>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>32</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>6</td>\n",
       "      <td>may</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>18080</td>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1557</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>5</td>\n",
       "      <td>feb</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18080</th>\n",
       "      <td>18081</td>\n",
       "      <td>33</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1713</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>8</td>\n",
       "      <td>may</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>18082</td>\n",
       "      <td>37</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-251</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>12</td>\n",
       "      <td>may</td>\n",
       "      <td>146</td>\n",
       "      <td>3</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>18083</td>\n",
       "      <td>34</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>56</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>aug</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18083 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  age            job  marital  education default  balance housing  \\\n",
       "0          1   30     management   single   tertiary      no     1028      no   \n",
       "1          2   39  self-employed   single   tertiary      no      426      no   \n",
       "2          3   38     technician   single   tertiary      no     -572     yes   \n",
       "3          4   34     technician   single  secondary      no     -476     yes   \n",
       "4          5   37   entrepreneur  married    primary      no       62      no   \n",
       "...      ...  ...            ...      ...        ...     ...      ...     ...   \n",
       "18078  18079   30     management  married   tertiary      no       32     yes   \n",
       "18079  18080   35     management  married   tertiary      no     1557     yes   \n",
       "18080  18081   33      housemaid  married    primary      no     1713     yes   \n",
       "18081  18082   37    blue-collar  married  secondary      no     -251     yes   \n",
       "18082  18083   34     technician  married  secondary      no       56      no   \n",
       "\n",
       "      loan   contact  day month  duration  campaign  pdays  previous poutcome  \n",
       "0       no  cellular    4   feb      1294         2     -1         0  unknown  \n",
       "1       no   unknown   18   jun      1029         1     -1         0  unknown  \n",
       "2      yes   unknown    5   jun        26        24     -1         0  unknown  \n",
       "3       no   unknown   27   may        92         4     -1         0  unknown  \n",
       "4       no  cellular   31   jul       404         2     -1         0  unknown  \n",
       "...    ...       ...  ...   ...       ...       ...    ...       ...      ...  \n",
       "18078   no   unknown    6   may       122         3     -1         0  unknown  \n",
       "18079  yes  cellular    5   feb       225         1    268         1  failure  \n",
       "18080   no   unknown    8   may        22         1     -1         0  unknown  \n",
       "18081   no  cellular   12   may       146         3    370         1  failure  \n",
       "18082   no  cellular   19   aug        91         2     -1         0  unknown  \n",
       "\n",
       "[18083 rows x 17 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_1</th>\n",
       "      <th>job_2</th>\n",
       "      <th>job_3</th>\n",
       "      <th>job_4</th>\n",
       "      <th>job_5</th>\n",
       "      <th>job_6</th>\n",
       "      <th>job_7</th>\n",
       "      <th>job_8</th>\n",
       "      <th>job_9</th>\n",
       "      <th>job_10</th>\n",
       "      <th>job_11</th>\n",
       "      <th>job_12</th>\n",
       "      <th>marital_1</th>\n",
       "      <th>marital_2</th>\n",
       "      <th>marital_3</th>\n",
       "      <th>education_1</th>\n",
       "      <th>education_2</th>\n",
       "      <th>education_3</th>\n",
       "      <th>education_4</th>\n",
       "      <th>housing_1</th>\n",
       "      <th>housing_2</th>\n",
       "      <th>loan_1</th>\n",
       "      <th>loan_2</th>\n",
       "      <th>contact_1</th>\n",
       "      <th>contact_2</th>\n",
       "      <th>contact_3</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_1</th>\n",
       "      <th>poutcome_2</th>\n",
       "      <th>poutcome_3</th>\n",
       "      <th>poutcome_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.359444</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.285833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.112222</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18080</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.040556</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.025278</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18083 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  job_1  job_2  job_3  job_4  job_5  job_6  job_7  job_8  job_9  \\\n",
       "0       30      1      0      0      0      0      0      0      0      0   \n",
       "1       39      0      1      0      0      0      0      0      0      0   \n",
       "2       38      0      0      1      0      0      0      0      0      0   \n",
       "3       34      0      0      1      0      0      0      0      0      0   \n",
       "4       37      0      0      0      1      0      0      0      0      0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "18078   30      1      0      0      0      0      0      0      0      0   \n",
       "18079   35      1      0      0      0      0      0      0      0      0   \n",
       "18080   33      0      0      0      0      0      0      1      0      0   \n",
       "18081   37      0      0      0      0      0      1      0      0      0   \n",
       "18082   34      0      0      1      0      0      0      0      0      0   \n",
       "\n",
       "       job_10  job_11  job_12  marital_1  marital_2  marital_3  education_1  \\\n",
       "0           0       0       0          1          0          0            1   \n",
       "1           0       0       0          1          0          0            1   \n",
       "2           0       0       0          1          0          0            1   \n",
       "3           0       0       0          1          0          0            0   \n",
       "4           0       0       0          0          1          0            0   \n",
       "...       ...     ...     ...        ...        ...        ...          ...   \n",
       "18078       0       0       0          0          1          0            1   \n",
       "18079       0       0       0          0          1          0            1   \n",
       "18080       0       0       0          0          1          0            0   \n",
       "18081       0       0       0          0          1          0            0   \n",
       "18082       0       0       0          0          1          0            0   \n",
       "\n",
       "       education_2  education_3  education_4  housing_1  housing_2  loan_1  \\\n",
       "0                0            0            0          1          0       1   \n",
       "1                0            0            0          1          0       1   \n",
       "2                0            0            0          0          1       0   \n",
       "3                1            0            0          0          1       1   \n",
       "4                0            1            0          1          0       1   \n",
       "...            ...          ...          ...        ...        ...     ...   \n",
       "18078            0            0            0          0          1       1   \n",
       "18079            0            0            0          0          1       0   \n",
       "18080            0            1            0          0          1       1   \n",
       "18081            1            0            0          0          1       1   \n",
       "18082            1            0            0          1          0       1   \n",
       "\n",
       "       loan_2  contact_1  contact_2  contact_3  day  month  duration  \\\n",
       "0           0          1          0          0    4    2.0  0.359444   \n",
       "1           0          0          1          0   18    6.0  0.285833   \n",
       "2           1          0          1          0    5    6.0  0.007222   \n",
       "3           0          0          1          0   27    5.0  0.025556   \n",
       "4           0          1          0          0   31    7.0  0.112222   \n",
       "...       ...        ...        ...        ...  ...    ...       ...   \n",
       "18078       0          0          1          0    6    5.0  0.033889   \n",
       "18079       1          1          0          0    5    2.0  0.062500   \n",
       "18080       0          0          1          0    8    5.0  0.006111   \n",
       "18081       0          1          0          0   12    5.0  0.040556   \n",
       "18082       0          1          0          0   19    8.0  0.025278   \n",
       "\n",
       "       campaign  previous  poutcome_1  poutcome_2  poutcome_3  poutcome_4  \n",
       "0             2         0           1           0           0           0  \n",
       "1             1         0           1           0           0           0  \n",
       "2            24         0           1           0           0           0  \n",
       "3             4         0           1           0           0           0  \n",
       "4             2         0           1           0           0           0  \n",
       "...         ...       ...         ...         ...         ...         ...  \n",
       "18078         3         0           1           0           0           0  \n",
       "18079         1         1           0           0           1           0  \n",
       "18080         1         0           1           0           0           0  \n",
       "18081         3         1           0           0           1           0  \n",
       "18082         2         0           1           0           0           0  \n",
       "\n",
       "[18083 rows x 36 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(columns=['id', 'balance', 'pdays', 'default'], axis=1)\n",
    "\n",
    "# monthmap\n",
    "test['month'] = test['month'].map(month_map)\n",
    "\n",
    "# OneHotEncoding\n",
    "# job, marital, education, housing, loan, contact, poutcome\n",
    "cols = ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'poutcome']\n",
    "ce_onehot = ce.OneHotEncoder(cols=cols,handle_unknown='impute')\n",
    "ce_onehot.fit(test)\n",
    "test = ce_onehot.transform(test)\n",
    "\n",
    "test['duration'] = test['duration'] / 3600\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58717342, 0.50900656, 0.00315642, ..., 0.00417826, 0.23154331,\n",
       "       0.01230096])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[1] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('20200926_001.csv', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
