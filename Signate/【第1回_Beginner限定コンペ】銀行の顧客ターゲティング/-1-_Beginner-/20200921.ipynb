{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataの読み込み\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submit_df = pd.read_csv('submit_sample.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27100, 18), (18050, 17), (18050, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの量の確認\n",
    "train_df.shape,test_df.shape,submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータがわかるようにダミーの目的変数を代入\n",
    "test_df['y']=-999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練データ、テストデータを結合\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "del train_df,test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカラムの前処理\n",
    "categorical_features = ['job', 'marital', 'education','default','housing','loan','contact','month','poutcome']\n",
    "for col in categorical_features:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(all_df[col])\n",
    "    lbl.transform(all_df[col])\n",
    "    all_df[col]=lbl.transform(all_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータの分割\n",
    "train_df = all_df[all_df['y']!=-999]\n",
    "test_df = all_df[all_df['y']==-999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['y']\n",
    "X_train = train_df.drop(['y','id'], axis=1)\n",
    "X_test = test_df.drop(['y','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データからデータを分割\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210006\tvalid_1's binary_logloss: 0.220314\n",
      "[20]\ttraining's binary_logloss: 0.191481\tvalid_1's binary_logloss: 0.209446\n",
      "[30]\ttraining's binary_logloss: 0.179046\tvalid_1's binary_logloss: 0.204832\n",
      "[40]\ttraining's binary_logloss: 0.169484\tvalid_1's binary_logloss: 0.203141\n",
      "[50]\ttraining's binary_logloss: 0.162016\tvalid_1's binary_logloss: 0.202679\n",
      "[60]\ttraining's binary_logloss: 0.154898\tvalid_1's binary_logloss: 0.202955\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.160553\tvalid_1's binary_logloss: 0.202594\n"
     ]
    }
   ],
   "source": [
    "# 使用モデルはLGB（パラメータチューニング無）\n",
    "lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary'\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params, lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_eval],\n",
    "    verbose_eval=10,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77141049, 0.14898476, 0.03111194, ..., 0.08560213, 0.00740139,\n",
       "       0.15052081])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まずは、いったんこれで算出した結果がどうなるか可視化してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## まずは訓練データで検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03580811, 0.22393526, 0.0240319 , ..., 0.4426737 , 0.01564351,\n",
       "       0.03028361])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "y_pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_valid[0:100]\n",
    "y_valid = y_valid[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cafbfba208>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "plt.scatter(list(range(len(y_pred))), y_pred, color='red')\n",
    "plt.scatter(list(range(len(y_valid))), y_valid.values, alpha=0.3, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9094736842105263"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからが今回学習するところ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_origin = train_df['y']\n",
    "X_train_origin = train_df.drop(['y','id'], axis=1)\n",
    "X_test_origin = test_df.drop(['y','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210006\tvalid_1's binary_logloss: 0.220314\n",
      "[20]\ttraining's binary_logloss: 0.191481\tvalid_1's binary_logloss: 0.209446\n",
      "[30]\ttraining's binary_logloss: 0.179046\tvalid_1's binary_logloss: 0.204832\n",
      "[40]\ttraining's binary_logloss: 0.169484\tvalid_1's binary_logloss: 0.203141\n",
      "[50]\ttraining's binary_logloss: 0.162016\tvalid_1's binary_logloss: 0.202679\n",
      "[60]\ttraining's binary_logloss: 0.154898\tvalid_1's binary_logloss: 0.202955\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.160553\tvalid_1's binary_logloss: 0.202594\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 726\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208699\tvalid_1's binary_logloss: 0.222504\n",
      "[20]\ttraining's binary_logloss: 0.191079\tvalid_1's binary_logloss: 0.212557\n",
      "[30]\ttraining's binary_logloss: 0.17858\tvalid_1's binary_logloss: 0.207992\n",
      "[40]\ttraining's binary_logloss: 0.169107\tvalid_1's binary_logloss: 0.205794\n",
      "[50]\ttraining's binary_logloss: 0.161464\tvalid_1's binary_logloss: 0.205105\n",
      "[60]\ttraining's binary_logloss: 0.155361\tvalid_1's binary_logloss: 0.204983\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.159614\tvalid_1's binary_logloss: 0.204793\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208588\tvalid_1's binary_logloss: 0.222533\n",
      "[20]\ttraining's binary_logloss: 0.19035\tvalid_1's binary_logloss: 0.212752\n",
      "[30]\ttraining's binary_logloss: 0.178144\tvalid_1's binary_logloss: 0.208589\n",
      "[40]\ttraining's binary_logloss: 0.168703\tvalid_1's binary_logloss: 0.207158\n",
      "[50]\ttraining's binary_logloss: 0.160566\tvalid_1's binary_logloss: 0.207011\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.166154\tvalid_1's binary_logloss: 0.206755\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210779\tvalid_1's binary_logloss: 0.218938\n",
      "[20]\ttraining's binary_logloss: 0.192099\tvalid_1's binary_logloss: 0.208185\n",
      "[30]\ttraining's binary_logloss: 0.179907\tvalid_1's binary_logloss: 0.203074\n",
      "[40]\ttraining's binary_logloss: 0.170268\tvalid_1's binary_logloss: 0.20111\n",
      "[50]\ttraining's binary_logloss: 0.163151\tvalid_1's binary_logloss: 0.201178\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.166446\tvalid_1's binary_logloss: 0.200794\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210453\tvalid_1's binary_logloss: 0.218673\n",
      "[20]\ttraining's binary_logloss: 0.192904\tvalid_1's binary_logloss: 0.208874\n",
      "[30]\ttraining's binary_logloss: 0.180234\tvalid_1's binary_logloss: 0.203829\n",
      "[40]\ttraining's binary_logloss: 0.170951\tvalid_1's binary_logloss: 0.201631\n",
      "[50]\ttraining's binary_logloss: 0.163705\tvalid_1's binary_logloss: 0.200809\n",
      "[60]\ttraining's binary_logloss: 0.157407\tvalid_1's binary_logloss: 0.200731\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.158693\tvalid_1's binary_logloss: 0.200474\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209973\tvalid_1's binary_logloss: 0.219765\n",
      "[20]\ttraining's binary_logloss: 0.1916\tvalid_1's binary_logloss: 0.208337\n",
      "[30]\ttraining's binary_logloss: 0.179301\tvalid_1's binary_logloss: 0.204748\n",
      "[40]\ttraining's binary_logloss: 0.170135\tvalid_1's binary_logloss: 0.203218\n",
      "[50]\ttraining's binary_logloss: 0.162867\tvalid_1's binary_logloss: 0.202875\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.164244\tvalid_1's binary_logloss: 0.202809\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208545\tvalid_1's binary_logloss: 0.222258\n",
      "[20]\ttraining's binary_logloss: 0.190329\tvalid_1's binary_logloss: 0.211194\n",
      "[30]\ttraining's binary_logloss: 0.17835\tvalid_1's binary_logloss: 0.207069\n",
      "[40]\ttraining's binary_logloss: 0.16933\tvalid_1's binary_logloss: 0.20437\n",
      "[50]\ttraining's binary_logloss: 0.162059\tvalid_1's binary_logloss: 0.204062\n",
      "[60]\ttraining's binary_logloss: 0.155744\tvalid_1's binary_logloss: 0.204121\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.157619\tvalid_1's binary_logloss: 0.203831\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211334\tvalid_1's binary_logloss: 0.217361\n",
      "[20]\ttraining's binary_logloss: 0.192577\tvalid_1's binary_logloss: 0.206724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's binary_logloss: 0.180189\tvalid_1's binary_logloss: 0.202609\n",
      "[40]\ttraining's binary_logloss: 0.170985\tvalid_1's binary_logloss: 0.201685\n",
      "[50]\ttraining's binary_logloss: 0.162804\tvalid_1's binary_logloss: 0.200903\n",
      "[60]\ttraining's binary_logloss: 0.156578\tvalid_1's binary_logloss: 0.201061\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.160195\tvalid_1's binary_logloss: 0.200638\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210243\tvalid_1's binary_logloss: 0.218513\n",
      "[20]\ttraining's binary_logloss: 0.192431\tvalid_1's binary_logloss: 0.208194\n",
      "[30]\ttraining's binary_logloss: 0.180542\tvalid_1's binary_logloss: 0.202114\n",
      "[40]\ttraining's binary_logloss: 0.171411\tvalid_1's binary_logloss: 0.19996\n",
      "[50]\ttraining's binary_logloss: 0.163608\tvalid_1's binary_logloss: 0.199166\n",
      "[60]\ttraining's binary_logloss: 0.156666\tvalid_1's binary_logloss: 0.198676\n",
      "[70]\ttraining's binary_logloss: 0.150563\tvalid_1's binary_logloss: 0.199949\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.156666\tvalid_1's binary_logloss: 0.198676\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209164\tvalid_1's binary_logloss: 0.220685\n",
      "[20]\ttraining's binary_logloss: 0.190065\tvalid_1's binary_logloss: 0.209628\n",
      "[30]\ttraining's binary_logloss: 0.178055\tvalid_1's binary_logloss: 0.205239\n",
      "[40]\ttraining's binary_logloss: 0.169008\tvalid_1's binary_logloss: 0.203602\n",
      "[50]\ttraining's binary_logloss: 0.16102\tvalid_1's binary_logloss: 0.203179\n",
      "[60]\ttraining's binary_logloss: 0.154605\tvalid_1's binary_logloss: 0.203123\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.157833\tvalid_1's binary_logloss: 0.202878\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211324\tvalid_1's binary_logloss: 0.216761\n",
      "[20]\ttraining's binary_logloss: 0.192744\tvalid_1's binary_logloss: 0.205671\n",
      "[30]\ttraining's binary_logloss: 0.180275\tvalid_1's binary_logloss: 0.201214\n",
      "[40]\ttraining's binary_logloss: 0.171402\tvalid_1's binary_logloss: 0.198989\n",
      "[50]\ttraining's binary_logloss: 0.163656\tvalid_1's binary_logloss: 0.199358\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.168926\tvalid_1's binary_logloss: 0.198985\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210026\tvalid_1's binary_logloss: 0.220113\n",
      "[20]\ttraining's binary_logloss: 0.191886\tvalid_1's binary_logloss: 0.210982\n",
      "[30]\ttraining's binary_logloss: 0.179245\tvalid_1's binary_logloss: 0.205914\n",
      "[40]\ttraining's binary_logloss: 0.169845\tvalid_1's binary_logloss: 0.204261\n",
      "[50]\ttraining's binary_logloss: 0.162454\tvalid_1's binary_logloss: 0.20396\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.166473\tvalid_1's binary_logloss: 0.203834\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210641\tvalid_1's binary_logloss: 0.217305\n",
      "[20]\ttraining's binary_logloss: 0.191321\tvalid_1's binary_logloss: 0.206147\n",
      "[30]\ttraining's binary_logloss: 0.179261\tvalid_1's binary_logloss: 0.201194\n",
      "[40]\ttraining's binary_logloss: 0.170309\tvalid_1's binary_logloss: 0.199402\n",
      "[50]\ttraining's binary_logloss: 0.162488\tvalid_1's binary_logloss: 0.199219\n",
      "[60]\ttraining's binary_logloss: 0.156347\tvalid_1's binary_logloss: 0.198759\n",
      "[70]\ttraining's binary_logloss: 0.149639\tvalid_1's binary_logloss: 0.198576\n",
      "[80]\ttraining's binary_logloss: 0.144231\tvalid_1's binary_logloss: 0.198137\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.144681\tvalid_1's binary_logloss: 0.198074\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210107\tvalid_1's binary_logloss: 0.218749\n",
      "[20]\ttraining's binary_logloss: 0.191996\tvalid_1's binary_logloss: 0.209175\n",
      "[30]\ttraining's binary_logloss: 0.17938\tvalid_1's binary_logloss: 0.204591\n",
      "[40]\ttraining's binary_logloss: 0.170383\tvalid_1's binary_logloss: 0.20354\n",
      "[50]\ttraining's binary_logloss: 0.162899\tvalid_1's binary_logloss: 0.20327\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.167384\tvalid_1's binary_logloss: 0.20305\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208864\tvalid_1's binary_logloss: 0.218931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.190549\tvalid_1's binary_logloss: 0.209608\n",
      "[30]\ttraining's binary_logloss: 0.178634\tvalid_1's binary_logloss: 0.205281\n",
      "[40]\ttraining's binary_logloss: 0.169678\tvalid_1's binary_logloss: 0.203225\n",
      "[50]\ttraining's binary_logloss: 0.162141\tvalid_1's binary_logloss: 0.202603\n",
      "[60]\ttraining's binary_logloss: 0.155986\tvalid_1's binary_logloss: 0.202407\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.157741\tvalid_1's binary_logloss: 0.202151\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20994\tvalid_1's binary_logloss: 0.217276\n",
      "[20]\ttraining's binary_logloss: 0.191378\tvalid_1's binary_logloss: 0.207808\n",
      "[30]\ttraining's binary_logloss: 0.179347\tvalid_1's binary_logloss: 0.203152\n",
      "[40]\ttraining's binary_logloss: 0.170522\tvalid_1's binary_logloss: 0.201781\n",
      "[50]\ttraining's binary_logloss: 0.163194\tvalid_1's binary_logloss: 0.201353\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.163846\tvalid_1's binary_logloss: 0.201099\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209255\tvalid_1's binary_logloss: 0.218889\n",
      "[20]\ttraining's binary_logloss: 0.190319\tvalid_1's binary_logloss: 0.208944\n",
      "[30]\ttraining's binary_logloss: 0.178018\tvalid_1's binary_logloss: 0.205418\n",
      "[40]\ttraining's binary_logloss: 0.168878\tvalid_1's binary_logloss: 0.203234\n",
      "[50]\ttraining's binary_logloss: 0.161359\tvalid_1's binary_logloss: 0.202806\n",
      "[60]\ttraining's binary_logloss: 0.155481\tvalid_1's binary_logloss: 0.203047\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.160161\tvalid_1's binary_logloss: 0.202683\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209798\tvalid_1's binary_logloss: 0.21791\n",
      "[20]\ttraining's binary_logloss: 0.19122\tvalid_1's binary_logloss: 0.20745\n",
      "[30]\ttraining's binary_logloss: 0.179427\tvalid_1's binary_logloss: 0.203849\n",
      "[40]\ttraining's binary_logloss: 0.170049\tvalid_1's binary_logloss: 0.20184\n",
      "[50]\ttraining's binary_logloss: 0.16283\tvalid_1's binary_logloss: 0.201611\n",
      "[60]\ttraining's binary_logloss: 0.156107\tvalid_1's binary_logloss: 0.201518\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.159777\tvalid_1's binary_logloss: 0.201224\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209277\tvalid_1's binary_logloss: 0.22054\n",
      "[20]\ttraining's binary_logloss: 0.190412\tvalid_1's binary_logloss: 0.210682\n",
      "[30]\ttraining's binary_logloss: 0.177825\tvalid_1's binary_logloss: 0.206701\n",
      "[40]\ttraining's binary_logloss: 0.168468\tvalid_1's binary_logloss: 0.20602\n",
      "[50]\ttraining's binary_logloss: 0.161689\tvalid_1's binary_logloss: 0.205745\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.162925\tvalid_1's binary_logloss: 0.205693\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209862\tvalid_1's binary_logloss: 0.220886\n",
      "[20]\ttraining's binary_logloss: 0.191054\tvalid_1's binary_logloss: 0.210986\n",
      "[30]\ttraining's binary_logloss: 0.178055\tvalid_1's binary_logloss: 0.20712\n",
      "[40]\ttraining's binary_logloss: 0.16907\tvalid_1's binary_logloss: 0.205799\n",
      "[50]\ttraining's binary_logloss: 0.161178\tvalid_1's binary_logloss: 0.206086\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.164277\tvalid_1's binary_logloss: 0.205684\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209832\tvalid_1's binary_logloss: 0.220075\n",
      "[20]\ttraining's binary_logloss: 0.191075\tvalid_1's binary_logloss: 0.209873\n",
      "[30]\ttraining's binary_logloss: 0.178297\tvalid_1's binary_logloss: 0.205337\n",
      "[40]\ttraining's binary_logloss: 0.168836\tvalid_1's binary_logloss: 0.203299\n",
      "[50]\ttraining's binary_logloss: 0.160879\tvalid_1's binary_logloss: 0.203493\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.163903\tvalid_1's binary_logloss: 0.202995\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210083\tvalid_1's binary_logloss: 0.21997\n",
      "[20]\ttraining's binary_logloss: 0.191264\tvalid_1's binary_logloss: 0.208221\n",
      "[30]\ttraining's binary_logloss: 0.179433\tvalid_1's binary_logloss: 0.204095\n",
      "[40]\ttraining's binary_logloss: 0.170323\tvalid_1's binary_logloss: 0.202286\n",
      "[50]\ttraining's binary_logloss: 0.162982\tvalid_1's binary_logloss: 0.201617\n",
      "[60]\ttraining's binary_logloss: 0.156826\tvalid_1's binary_logloss: 0.20206\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.162982\tvalid_1's binary_logloss: 0.201617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210308\tvalid_1's binary_logloss: 0.218143\n",
      "[20]\ttraining's binary_logloss: 0.191813\tvalid_1's binary_logloss: 0.206901\n",
      "[30]\ttraining's binary_logloss: 0.179851\tvalid_1's binary_logloss: 0.202308\n",
      "[40]\ttraining's binary_logloss: 0.170884\tvalid_1's binary_logloss: 0.201084\n",
      "[50]\ttraining's binary_logloss: 0.163317\tvalid_1's binary_logloss: 0.201118\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.164727\tvalid_1's binary_logloss: 0.2008\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20865\tvalid_1's binary_logloss: 0.220163\n",
      "[20]\ttraining's binary_logloss: 0.1898\tvalid_1's binary_logloss: 0.209892\n",
      "[30]\ttraining's binary_logloss: 0.177588\tvalid_1's binary_logloss: 0.20582\n",
      "[40]\ttraining's binary_logloss: 0.168471\tvalid_1's binary_logloss: 0.204308\n",
      "[50]\ttraining's binary_logloss: 0.160562\tvalid_1's binary_logloss: 0.203761\n",
      "[60]\ttraining's binary_logloss: 0.153867\tvalid_1's binary_logloss: 0.203717\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.157768\tvalid_1's binary_logloss: 0.203614\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.206619\tvalid_1's binary_logloss: 0.224076\n",
      "[20]\ttraining's binary_logloss: 0.188516\tvalid_1's binary_logloss: 0.214987\n",
      "[30]\ttraining's binary_logloss: 0.176563\tvalid_1's binary_logloss: 0.211239\n",
      "[40]\ttraining's binary_logloss: 0.167124\tvalid_1's binary_logloss: 0.209361\n",
      "[50]\ttraining's binary_logloss: 0.159946\tvalid_1's binary_logloss: 0.209122\n",
      "[60]\ttraining's binary_logloss: 0.152808\tvalid_1's binary_logloss: 0.208851\n",
      "[70]\ttraining's binary_logloss: 0.146777\tvalid_1's binary_logloss: 0.208885\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.148483\tvalid_1's binary_logloss: 0.208738\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209402\tvalid_1's binary_logloss: 0.21948\n",
      "[20]\ttraining's binary_logloss: 0.191532\tvalid_1's binary_logloss: 0.208742\n",
      "[30]\ttraining's binary_logloss: 0.179845\tvalid_1's binary_logloss: 0.205134\n",
      "[40]\ttraining's binary_logloss: 0.170535\tvalid_1's binary_logloss: 0.203327\n",
      "[50]\ttraining's binary_logloss: 0.162898\tvalid_1's binary_logloss: 0.202829\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.164485\tvalid_1's binary_logloss: 0.20268\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210373\tvalid_1's binary_logloss: 0.219987\n",
      "[20]\ttraining's binary_logloss: 0.192471\tvalid_1's binary_logloss: 0.208776\n",
      "[30]\ttraining's binary_logloss: 0.180233\tvalid_1's binary_logloss: 0.203048\n",
      "[40]\ttraining's binary_logloss: 0.17097\tvalid_1's binary_logloss: 0.20106\n",
      "[50]\ttraining's binary_logloss: 0.163437\tvalid_1's binary_logloss: 0.200413\n",
      "[60]\ttraining's binary_logloss: 0.156759\tvalid_1's binary_logloss: 0.200186\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.158657\tvalid_1's binary_logloss: 0.199995\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20845\tvalid_1's binary_logloss: 0.22045\n",
      "[20]\ttraining's binary_logloss: 0.18989\tvalid_1's binary_logloss: 0.210725\n",
      "[30]\ttraining's binary_logloss: 0.17781\tvalid_1's binary_logloss: 0.206909\n",
      "[40]\ttraining's binary_logloss: 0.168564\tvalid_1's binary_logloss: 0.205388\n",
      "[50]\ttraining's binary_logloss: 0.16082\tvalid_1's binary_logloss: 0.205098\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.163783\tvalid_1's binary_logloss: 0.204756\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209475\tvalid_1's binary_logloss: 0.219399\n",
      "[20]\ttraining's binary_logloss: 0.190943\tvalid_1's binary_logloss: 0.208835\n",
      "[30]\ttraining's binary_logloss: 0.178745\tvalid_1's binary_logloss: 0.204398\n",
      "[40]\ttraining's binary_logloss: 0.169391\tvalid_1's binary_logloss: 0.203267\n",
      "[50]\ttraining's binary_logloss: 0.161168\tvalid_1's binary_logloss: 0.202549\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.161998\tvalid_1's binary_logloss: 0.202312\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208757\tvalid_1's binary_logloss: 0.22073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.191171\tvalid_1's binary_logloss: 0.20999\n",
      "[30]\ttraining's binary_logloss: 0.178757\tvalid_1's binary_logloss: 0.205895\n",
      "[40]\ttraining's binary_logloss: 0.169616\tvalid_1's binary_logloss: 0.203519\n",
      "[50]\ttraining's binary_logloss: 0.162311\tvalid_1's binary_logloss: 0.20297\n",
      "[60]\ttraining's binary_logloss: 0.156141\tvalid_1's binary_logloss: 0.202119\n",
      "[70]\ttraining's binary_logloss: 0.150304\tvalid_1's binary_logloss: 0.202006\n",
      "[80]\ttraining's binary_logloss: 0.145193\tvalid_1's binary_logloss: 0.201992\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.149218\tvalid_1's binary_logloss: 0.201848\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 725\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211719\tvalid_1's binary_logloss: 0.216036\n",
      "[20]\ttraining's binary_logloss: 0.193723\tvalid_1's binary_logloss: 0.205599\n",
      "[30]\ttraining's binary_logloss: 0.181646\tvalid_1's binary_logloss: 0.200707\n",
      "[40]\ttraining's binary_logloss: 0.172375\tvalid_1's binary_logloss: 0.198653\n",
      "[50]\ttraining's binary_logloss: 0.164703\tvalid_1's binary_logloss: 0.198153\n",
      "[60]\ttraining's binary_logloss: 0.158404\tvalid_1's binary_logloss: 0.197725\n",
      "[70]\ttraining's binary_logloss: 0.15185\tvalid_1's binary_logloss: 0.197089\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.152429\tvalid_1's binary_logloss: 0.197085\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211599\tvalid_1's binary_logloss: 0.21726\n",
      "[20]\ttraining's binary_logloss: 0.193388\tvalid_1's binary_logloss: 0.206335\n",
      "[30]\ttraining's binary_logloss: 0.181004\tvalid_1's binary_logloss: 0.200738\n",
      "[40]\ttraining's binary_logloss: 0.171652\tvalid_1's binary_logloss: 0.199612\n",
      "[50]\ttraining's binary_logloss: 0.164188\tvalid_1's binary_logloss: 0.199096\n",
      "[60]\ttraining's binary_logloss: 0.157988\tvalid_1's binary_logloss: 0.199478\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.164188\tvalid_1's binary_logloss: 0.199096\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209421\tvalid_1's binary_logloss: 0.221246\n",
      "[20]\ttraining's binary_logloss: 0.191603\tvalid_1's binary_logloss: 0.210767\n",
      "[30]\ttraining's binary_logloss: 0.179395\tvalid_1's binary_logloss: 0.205864\n",
      "[40]\ttraining's binary_logloss: 0.170803\tvalid_1's binary_logloss: 0.203823\n",
      "[50]\ttraining's binary_logloss: 0.163126\tvalid_1's binary_logloss: 0.203758\n",
      "[60]\ttraining's binary_logloss: 0.157051\tvalid_1's binary_logloss: 0.203572\n",
      "[70]\ttraining's binary_logloss: 0.151582\tvalid_1's binary_logloss: 0.203932\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.154859\tvalid_1's binary_logloss: 0.203479\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208761\tvalid_1's binary_logloss: 0.220209\n",
      "[20]\ttraining's binary_logloss: 0.189693\tvalid_1's binary_logloss: 0.210615\n",
      "[30]\ttraining's binary_logloss: 0.177619\tvalid_1's binary_logloss: 0.206942\n",
      "[40]\ttraining's binary_logloss: 0.168614\tvalid_1's binary_logloss: 0.205048\n",
      "[50]\ttraining's binary_logloss: 0.161571\tvalid_1's binary_logloss: 0.204585\n",
      "[60]\ttraining's binary_logloss: 0.155143\tvalid_1's binary_logloss: 0.204993\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.160942\tvalid_1's binary_logloss: 0.204528\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.207659\tvalid_1's binary_logloss: 0.22259\n",
      "[20]\ttraining's binary_logloss: 0.189427\tvalid_1's binary_logloss: 0.21223\n",
      "[30]\ttraining's binary_logloss: 0.177919\tvalid_1's binary_logloss: 0.207727\n",
      "[40]\ttraining's binary_logloss: 0.168517\tvalid_1's binary_logloss: 0.206552\n",
      "[50]\ttraining's binary_logloss: 0.160781\tvalid_1's binary_logloss: 0.206122\n",
      "[60]\ttraining's binary_logloss: 0.154078\tvalid_1's binary_logloss: 0.205429\n",
      "[70]\ttraining's binary_logloss: 0.148138\tvalid_1's binary_logloss: 0.205833\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.154078\tvalid_1's binary_logloss: 0.205429\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210925\tvalid_1's binary_logloss: 0.218605\n",
      "[20]\ttraining's binary_logloss: 0.19178\tvalid_1's binary_logloss: 0.207234\n",
      "[30]\ttraining's binary_logloss: 0.179488\tvalid_1's binary_logloss: 0.201828\n",
      "[40]\ttraining's binary_logloss: 0.170246\tvalid_1's binary_logloss: 0.200325\n",
      "[50]\ttraining's binary_logloss: 0.163097\tvalid_1's binary_logloss: 0.199262\n",
      "[60]\ttraining's binary_logloss: 0.156113\tvalid_1's binary_logloss: 0.199102\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.159563\tvalid_1's binary_logloss: 0.198884\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209776\tvalid_1's binary_logloss: 0.219412\n",
      "[20]\ttraining's binary_logloss: 0.191648\tvalid_1's binary_logloss: 0.209312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's binary_logloss: 0.179175\tvalid_1's binary_logloss: 0.204495\n",
      "[40]\ttraining's binary_logloss: 0.17006\tvalid_1's binary_logloss: 0.202312\n",
      "[50]\ttraining's binary_logloss: 0.162457\tvalid_1's binary_logloss: 0.202313\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.165728\tvalid_1's binary_logloss: 0.20183\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208743\tvalid_1's binary_logloss: 0.220266\n",
      "[20]\ttraining's binary_logloss: 0.191161\tvalid_1's binary_logloss: 0.209486\n",
      "[30]\ttraining's binary_logloss: 0.179539\tvalid_1's binary_logloss: 0.20532\n",
      "[40]\ttraining's binary_logloss: 0.170401\tvalid_1's binary_logloss: 0.204171\n",
      "[50]\ttraining's binary_logloss: 0.163082\tvalid_1's binary_logloss: 0.203258\n",
      "[60]\ttraining's binary_logloss: 0.155977\tvalid_1's binary_logloss: 0.203091\n",
      "[70]\ttraining's binary_logloss: 0.149876\tvalid_1's binary_logloss: 0.203628\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.155977\tvalid_1's binary_logloss: 0.203091\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.207175\tvalid_1's binary_logloss: 0.223517\n",
      "[20]\ttraining's binary_logloss: 0.188785\tvalid_1's binary_logloss: 0.214106\n",
      "[30]\ttraining's binary_logloss: 0.176634\tvalid_1's binary_logloss: 0.20968\n",
      "[40]\ttraining's binary_logloss: 0.167476\tvalid_1's binary_logloss: 0.207748\n",
      "[50]\ttraining's binary_logloss: 0.160124\tvalid_1's binary_logloss: 0.207435\n",
      "[60]\ttraining's binary_logloss: 0.15354\tvalid_1's binary_logloss: 0.207227\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.155478\tvalid_1's binary_logloss: 0.207038\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210179\tvalid_1's binary_logloss: 0.220088\n",
      "[20]\ttraining's binary_logloss: 0.19218\tvalid_1's binary_logloss: 0.208183\n",
      "[30]\ttraining's binary_logloss: 0.180316\tvalid_1's binary_logloss: 0.203618\n",
      "[40]\ttraining's binary_logloss: 0.171074\tvalid_1's binary_logloss: 0.2015\n",
      "[50]\ttraining's binary_logloss: 0.163322\tvalid_1's binary_logloss: 0.200542\n",
      "[60]\ttraining's binary_logloss: 0.156785\tvalid_1's binary_logloss: 0.200026\n",
      "[70]\ttraining's binary_logloss: 0.151424\tvalid_1's binary_logloss: 0.200266\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.155606\tvalid_1's binary_logloss: 0.199669\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210739\tvalid_1's binary_logloss: 0.219344\n",
      "[20]\ttraining's binary_logloss: 0.191671\tvalid_1's binary_logloss: 0.208754\n",
      "[30]\ttraining's binary_logloss: 0.17874\tvalid_1's binary_logloss: 0.203633\n",
      "[40]\ttraining's binary_logloss: 0.169064\tvalid_1's binary_logloss: 0.202137\n",
      "[50]\ttraining's binary_logloss: 0.1617\tvalid_1's binary_logloss: 0.20179\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.165154\tvalid_1's binary_logloss: 0.201673\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209304\tvalid_1's binary_logloss: 0.21968\n",
      "[20]\ttraining's binary_logloss: 0.191065\tvalid_1's binary_logloss: 0.209626\n",
      "[30]\ttraining's binary_logloss: 0.179365\tvalid_1's binary_logloss: 0.205957\n",
      "[40]\ttraining's binary_logloss: 0.170129\tvalid_1's binary_logloss: 0.20417\n",
      "[50]\ttraining's binary_logloss: 0.163067\tvalid_1's binary_logloss: 0.203756\n",
      "[60]\ttraining's binary_logloss: 0.15654\tvalid_1's binary_logloss: 0.203872\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.161453\tvalid_1's binary_logloss: 0.203548\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20989\tvalid_1's binary_logloss: 0.218485\n",
      "[20]\ttraining's binary_logloss: 0.191593\tvalid_1's binary_logloss: 0.20774\n",
      "[30]\ttraining's binary_logloss: 0.179486\tvalid_1's binary_logloss: 0.202671\n",
      "[40]\ttraining's binary_logloss: 0.170065\tvalid_1's binary_logloss: 0.200928\n",
      "[50]\ttraining's binary_logloss: 0.162909\tvalid_1's binary_logloss: 0.200668\n",
      "[60]\ttraining's binary_logloss: 0.156568\tvalid_1's binary_logloss: 0.20083\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.162233\tvalid_1's binary_logloss: 0.200571\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.206905\tvalid_1's binary_logloss: 0.223326\n",
      "[20]\ttraining's binary_logloss: 0.188606\tvalid_1's binary_logloss: 0.214608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's binary_logloss: 0.1762\tvalid_1's binary_logloss: 0.210828\n",
      "[40]\ttraining's binary_logloss: 0.166764\tvalid_1's binary_logloss: 0.209182\n",
      "[50]\ttraining's binary_logloss: 0.158762\tvalid_1's binary_logloss: 0.208814\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.159347\tvalid_1's binary_logloss: 0.208679\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208483\tvalid_1's binary_logloss: 0.221931\n",
      "[20]\ttraining's binary_logloss: 0.189821\tvalid_1's binary_logloss: 0.211549\n",
      "[30]\ttraining's binary_logloss: 0.177894\tvalid_1's binary_logloss: 0.207012\n",
      "[40]\ttraining's binary_logloss: 0.168757\tvalid_1's binary_logloss: 0.206064\n",
      "[50]\ttraining's binary_logloss: 0.16118\tvalid_1's binary_logloss: 0.205703\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.165718\tvalid_1's binary_logloss: 0.205575\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208002\tvalid_1's binary_logloss: 0.221837\n",
      "[20]\ttraining's binary_logloss: 0.18899\tvalid_1's binary_logloss: 0.211302\n",
      "[30]\ttraining's binary_logloss: 0.176881\tvalid_1's binary_logloss: 0.207449\n",
      "[40]\ttraining's binary_logloss: 0.167908\tvalid_1's binary_logloss: 0.205925\n",
      "[50]\ttraining's binary_logloss: 0.160064\tvalid_1's binary_logloss: 0.206381\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.167908\tvalid_1's binary_logloss: 0.205925\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208223\tvalid_1's binary_logloss: 0.221525\n",
      "[20]\ttraining's binary_logloss: 0.189905\tvalid_1's binary_logloss: 0.211691\n",
      "[30]\ttraining's binary_logloss: 0.17777\tvalid_1's binary_logloss: 0.207821\n",
      "[40]\ttraining's binary_logloss: 0.168633\tvalid_1's binary_logloss: 0.206052\n",
      "[50]\ttraining's binary_logloss: 0.160946\tvalid_1's binary_logloss: 0.205793\n",
      "[60]\ttraining's binary_logloss: 0.154067\tvalid_1's binary_logloss: 0.206008\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.159325\tvalid_1's binary_logloss: 0.205625\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.207858\tvalid_1's binary_logloss: 0.222443\n",
      "[20]\ttraining's binary_logloss: 0.189684\tvalid_1's binary_logloss: 0.212837\n",
      "[30]\ttraining's binary_logloss: 0.178054\tvalid_1's binary_logloss: 0.209188\n",
      "[40]\ttraining's binary_logloss: 0.168535\tvalid_1's binary_logloss: 0.207241\n",
      "[50]\ttraining's binary_logloss: 0.160249\tvalid_1's binary_logloss: 0.206527\n",
      "[60]\ttraining's binary_logloss: 0.153442\tvalid_1's binary_logloss: 0.206176\n",
      "[70]\ttraining's binary_logloss: 0.147821\tvalid_1's binary_logloss: 0.205858\n",
      "[80]\ttraining's binary_logloss: 0.142581\tvalid_1's binary_logloss: 0.205971\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.146095\tvalid_1's binary_logloss: 0.205552\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211242\tvalid_1's binary_logloss: 0.215622\n",
      "[20]\ttraining's binary_logloss: 0.194036\tvalid_1's binary_logloss: 0.204571\n",
      "[30]\ttraining's binary_logloss: 0.181509\tvalid_1's binary_logloss: 0.199472\n",
      "[40]\ttraining's binary_logloss: 0.172226\tvalid_1's binary_logloss: 0.19697\n",
      "[50]\ttraining's binary_logloss: 0.164562\tvalid_1's binary_logloss: 0.195848\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.166088\tvalid_1's binary_logloss: 0.195698\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209588\tvalid_1's binary_logloss: 0.219425\n",
      "[20]\ttraining's binary_logloss: 0.191299\tvalid_1's binary_logloss: 0.209631\n",
      "[30]\ttraining's binary_logloss: 0.179963\tvalid_1's binary_logloss: 0.205419\n",
      "[40]\ttraining's binary_logloss: 0.170647\tvalid_1's binary_logloss: 0.203132\n",
      "[50]\ttraining's binary_logloss: 0.163242\tvalid_1's binary_logloss: 0.202389\n",
      "[60]\ttraining's binary_logloss: 0.157019\tvalid_1's binary_logloss: 0.201741\n",
      "[70]\ttraining's binary_logloss: 0.151103\tvalid_1's binary_logloss: 0.200841\n",
      "[80]\ttraining's binary_logloss: 0.145596\tvalid_1's binary_logloss: 0.201003\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.150493\tvalid_1's binary_logloss: 0.200807\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210919\tvalid_1's binary_logloss: 0.217379\n",
      "[20]\ttraining's binary_logloss: 0.192392\tvalid_1's binary_logloss: 0.206563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's binary_logloss: 0.179897\tvalid_1's binary_logloss: 0.201109\n",
      "[40]\ttraining's binary_logloss: 0.170484\tvalid_1's binary_logloss: 0.198969\n",
      "[50]\ttraining's binary_logloss: 0.163002\tvalid_1's binary_logloss: 0.198578\n",
      "[60]\ttraining's binary_logloss: 0.156408\tvalid_1's binary_logloss: 0.198555\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.158394\tvalid_1's binary_logloss: 0.19849\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209672\tvalid_1's binary_logloss: 0.219983\n",
      "[20]\ttraining's binary_logloss: 0.191287\tvalid_1's binary_logloss: 0.209254\n",
      "[30]\ttraining's binary_logloss: 0.17903\tvalid_1's binary_logloss: 0.204384\n",
      "[40]\ttraining's binary_logloss: 0.169774\tvalid_1's binary_logloss: 0.202082\n",
      "[50]\ttraining's binary_logloss: 0.161894\tvalid_1's binary_logloss: 0.201229\n",
      "[60]\ttraining's binary_logloss: 0.155633\tvalid_1's binary_logloss: 0.20095\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.156208\tvalid_1's binary_logloss: 0.200886\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211037\tvalid_1's binary_logloss: 0.216681\n",
      "[20]\ttraining's binary_logloss: 0.192536\tvalid_1's binary_logloss: 0.205772\n",
      "[30]\ttraining's binary_logloss: 0.180233\tvalid_1's binary_logloss: 0.201377\n",
      "[40]\ttraining's binary_logloss: 0.171178\tvalid_1's binary_logloss: 0.199971\n",
      "[50]\ttraining's binary_logloss: 0.163259\tvalid_1's binary_logloss: 0.199405\n",
      "[60]\ttraining's binary_logloss: 0.157417\tvalid_1's binary_logloss: 0.199392\n",
      "[70]\ttraining's binary_logloss: 0.152114\tvalid_1's binary_logloss: 0.199088\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.153084\tvalid_1's binary_logloss: 0.198887\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209038\tvalid_1's binary_logloss: 0.22012\n",
      "[20]\ttraining's binary_logloss: 0.190065\tvalid_1's binary_logloss: 0.209461\n",
      "[30]\ttraining's binary_logloss: 0.177813\tvalid_1's binary_logloss: 0.205512\n",
      "[40]\ttraining's binary_logloss: 0.168987\tvalid_1's binary_logloss: 0.204258\n",
      "[50]\ttraining's binary_logloss: 0.16183\tvalid_1's binary_logloss: 0.204002\n",
      "[60]\ttraining's binary_logloss: 0.156231\tvalid_1's binary_logloss: 0.20435\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.160005\tvalid_1's binary_logloss: 0.203923\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209343\tvalid_1's binary_logloss: 0.220002\n",
      "[20]\ttraining's binary_logloss: 0.190887\tvalid_1's binary_logloss: 0.209416\n",
      "[30]\ttraining's binary_logloss: 0.178327\tvalid_1's binary_logloss: 0.204589\n",
      "[40]\ttraining's binary_logloss: 0.169175\tvalid_1's binary_logloss: 0.203098\n",
      "[50]\ttraining's binary_logloss: 0.161807\tvalid_1's binary_logloss: 0.202736\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.163619\tvalid_1's binary_logloss: 0.202531\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209258\tvalid_1's binary_logloss: 0.221123\n",
      "[20]\ttraining's binary_logloss: 0.190314\tvalid_1's binary_logloss: 0.211136\n",
      "[30]\ttraining's binary_logloss: 0.178683\tvalid_1's binary_logloss: 0.207229\n",
      "[40]\ttraining's binary_logloss: 0.169522\tvalid_1's binary_logloss: 0.205959\n",
      "[50]\ttraining's binary_logloss: 0.161577\tvalid_1's binary_logloss: 0.205921\n",
      "[60]\ttraining's binary_logloss: 0.155497\tvalid_1's binary_logloss: 0.205527\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.156019\tvalid_1's binary_logloss: 0.205485\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208988\tvalid_1's binary_logloss: 0.220014\n",
      "[20]\ttraining's binary_logloss: 0.19029\tvalid_1's binary_logloss: 0.21037\n",
      "[30]\ttraining's binary_logloss: 0.1782\tvalid_1's binary_logloss: 0.206829\n",
      "[40]\ttraining's binary_logloss: 0.169008\tvalid_1's binary_logloss: 0.205047\n",
      "[50]\ttraining's binary_logloss: 0.161389\tvalid_1's binary_logloss: 0.204812\n",
      "[60]\ttraining's binary_logloss: 0.154862\tvalid_1's binary_logloss: 0.204116\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.156262\tvalid_1's binary_logloss: 0.203954\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208973\tvalid_1's binary_logloss: 0.221581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.190518\tvalid_1's binary_logloss: 0.211007\n",
      "[30]\ttraining's binary_logloss: 0.178267\tvalid_1's binary_logloss: 0.20548\n",
      "[40]\ttraining's binary_logloss: 0.168581\tvalid_1's binary_logloss: 0.20384\n",
      "[50]\ttraining's binary_logloss: 0.160873\tvalid_1's binary_logloss: 0.203263\n",
      "[60]\ttraining's binary_logloss: 0.154568\tvalid_1's binary_logloss: 0.203404\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.158954\tvalid_1's binary_logloss: 0.203153\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211479\tvalid_1's binary_logloss: 0.217773\n",
      "[20]\ttraining's binary_logloss: 0.192911\tvalid_1's binary_logloss: 0.205624\n",
      "[30]\ttraining's binary_logloss: 0.180803\tvalid_1's binary_logloss: 0.200359\n",
      "[40]\ttraining's binary_logloss: 0.171765\tvalid_1's binary_logloss: 0.198135\n",
      "[50]\ttraining's binary_logloss: 0.164675\tvalid_1's binary_logloss: 0.197425\n",
      "[60]\ttraining's binary_logloss: 0.15823\tvalid_1's binary_logloss: 0.19729\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.159522\tvalid_1's binary_logloss: 0.197202\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209096\tvalid_1's binary_logloss: 0.221681\n",
      "[20]\ttraining's binary_logloss: 0.191082\tvalid_1's binary_logloss: 0.21159\n",
      "[30]\ttraining's binary_logloss: 0.178498\tvalid_1's binary_logloss: 0.207265\n",
      "[40]\ttraining's binary_logloss: 0.169265\tvalid_1's binary_logloss: 0.205609\n",
      "[50]\ttraining's binary_logloss: 0.161317\tvalid_1's binary_logloss: 0.205415\n",
      "[60]\ttraining's binary_logloss: 0.154735\tvalid_1's binary_logloss: 0.205513\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.159889\tvalid_1's binary_logloss: 0.205282\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208318\tvalid_1's binary_logloss: 0.220462\n",
      "[20]\ttraining's binary_logloss: 0.189428\tvalid_1's binary_logloss: 0.211751\n",
      "[30]\ttraining's binary_logloss: 0.17696\tvalid_1's binary_logloss: 0.208863\n",
      "[40]\ttraining's binary_logloss: 0.167669\tvalid_1's binary_logloss: 0.207861\n",
      "[50]\ttraining's binary_logloss: 0.159978\tvalid_1's binary_logloss: 0.208248\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.16277\tvalid_1's binary_logloss: 0.207768\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210555\tvalid_1's binary_logloss: 0.218975\n",
      "[20]\ttraining's binary_logloss: 0.19194\tvalid_1's binary_logloss: 0.207274\n",
      "[30]\ttraining's binary_logloss: 0.180009\tvalid_1's binary_logloss: 0.202603\n",
      "[40]\ttraining's binary_logloss: 0.17053\tvalid_1's binary_logloss: 0.200723\n",
      "[50]\ttraining's binary_logloss: 0.163099\tvalid_1's binary_logloss: 0.200432\n",
      "[60]\ttraining's binary_logloss: 0.156517\tvalid_1's binary_logloss: 0.200792\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.162443\tvalid_1's binary_logloss: 0.200361\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208669\tvalid_1's binary_logloss: 0.220097\n",
      "[20]\ttraining's binary_logloss: 0.190103\tvalid_1's binary_logloss: 0.2111\n",
      "[30]\ttraining's binary_logloss: 0.178636\tvalid_1's binary_logloss: 0.206525\n",
      "[40]\ttraining's binary_logloss: 0.169473\tvalid_1's binary_logloss: 0.204577\n",
      "[50]\ttraining's binary_logloss: 0.161834\tvalid_1's binary_logloss: 0.203941\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.166365\tvalid_1's binary_logloss: 0.203895\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.207896\tvalid_1's binary_logloss: 0.221601\n",
      "[20]\ttraining's binary_logloss: 0.189185\tvalid_1's binary_logloss: 0.212148\n",
      "[30]\ttraining's binary_logloss: 0.176509\tvalid_1's binary_logloss: 0.207729\n",
      "[40]\ttraining's binary_logloss: 0.167504\tvalid_1's binary_logloss: 0.206429\n",
      "[50]\ttraining's binary_logloss: 0.160229\tvalid_1's binary_logloss: 0.206291\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.165034\tvalid_1's binary_logloss: 0.206005\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210245\tvalid_1's binary_logloss: 0.216737\n",
      "[20]\ttraining's binary_logloss: 0.191343\tvalid_1's binary_logloss: 0.205672\n",
      "[30]\ttraining's binary_logloss: 0.178966\tvalid_1's binary_logloss: 0.201368\n",
      "[40]\ttraining's binary_logloss: 0.169899\tvalid_1's binary_logloss: 0.199803\n",
      "[50]\ttraining's binary_logloss: 0.16266\tvalid_1's binary_logloss: 0.1999\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.164593\tvalid_1's binary_logloss: 0.199716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210925\tvalid_1's binary_logloss: 0.217336\n",
      "[20]\ttraining's binary_logloss: 0.192875\tvalid_1's binary_logloss: 0.206809\n",
      "[30]\ttraining's binary_logloss: 0.18075\tvalid_1's binary_logloss: 0.201899\n",
      "[40]\ttraining's binary_logloss: 0.171806\tvalid_1's binary_logloss: 0.200376\n",
      "[50]\ttraining's binary_logloss: 0.163882\tvalid_1's binary_logloss: 0.19965\n",
      "[60]\ttraining's binary_logloss: 0.157024\tvalid_1's binary_logloss: 0.199506\n",
      "[70]\ttraining's binary_logloss: 0.150918\tvalid_1's binary_logloss: 0.199842\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.155393\tvalid_1's binary_logloss: 0.199379\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208192\tvalid_1's binary_logloss: 0.223834\n",
      "[20]\ttraining's binary_logloss: 0.189764\tvalid_1's binary_logloss: 0.213684\n",
      "[30]\ttraining's binary_logloss: 0.177502\tvalid_1's binary_logloss: 0.209765\n",
      "[40]\ttraining's binary_logloss: 0.168047\tvalid_1's binary_logloss: 0.208741\n",
      "[50]\ttraining's binary_logloss: 0.160298\tvalid_1's binary_logloss: 0.208371\n",
      "[60]\ttraining's binary_logloss: 0.153307\tvalid_1's binary_logloss: 0.208545\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.155186\tvalid_1's binary_logloss: 0.208224\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209145\tvalid_1's binary_logloss: 0.219031\n",
      "[20]\ttraining's binary_logloss: 0.190666\tvalid_1's binary_logloss: 0.208746\n",
      "[30]\ttraining's binary_logloss: 0.178695\tvalid_1's binary_logloss: 0.205216\n",
      "[40]\ttraining's binary_logloss: 0.169426\tvalid_1's binary_logloss: 0.203404\n",
      "[50]\ttraining's binary_logloss: 0.161806\tvalid_1's binary_logloss: 0.202986\n",
      "[60]\ttraining's binary_logloss: 0.155491\tvalid_1's binary_logloss: 0.203215\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.15813\tvalid_1's binary_logloss: 0.20292\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209851\tvalid_1's binary_logloss: 0.220889\n",
      "[20]\ttraining's binary_logloss: 0.191789\tvalid_1's binary_logloss: 0.210222\n",
      "[30]\ttraining's binary_logloss: 0.179716\tvalid_1's binary_logloss: 0.206035\n",
      "[40]\ttraining's binary_logloss: 0.17007\tvalid_1's binary_logloss: 0.203866\n",
      "[50]\ttraining's binary_logloss: 0.162237\tvalid_1's binary_logloss: 0.203211\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.166067\tvalid_1's binary_logloss: 0.20298\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211372\tvalid_1's binary_logloss: 0.218764\n",
      "[20]\ttraining's binary_logloss: 0.192402\tvalid_1's binary_logloss: 0.207909\n",
      "[30]\ttraining's binary_logloss: 0.180273\tvalid_1's binary_logloss: 0.202575\n",
      "[40]\ttraining's binary_logloss: 0.171035\tvalid_1's binary_logloss: 0.200508\n",
      "[50]\ttraining's binary_logloss: 0.163672\tvalid_1's binary_logloss: 0.200154\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.166417\tvalid_1's binary_logloss: 0.199861\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211802\tvalid_1's binary_logloss: 0.214625\n",
      "[20]\ttraining's binary_logloss: 0.194104\tvalid_1's binary_logloss: 0.202967\n",
      "[30]\ttraining's binary_logloss: 0.181885\tvalid_1's binary_logloss: 0.196638\n",
      "[40]\ttraining's binary_logloss: 0.17283\tvalid_1's binary_logloss: 0.194516\n",
      "[50]\ttraining's binary_logloss: 0.165253\tvalid_1's binary_logloss: 0.193802\n",
      "[60]\ttraining's binary_logloss: 0.158799\tvalid_1's binary_logloss: 0.193546\n",
      "[70]\ttraining's binary_logloss: 0.152542\tvalid_1's binary_logloss: 0.193355\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.154299\tvalid_1's binary_logloss: 0.193211\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209227\tvalid_1's binary_logloss: 0.221984\n",
      "[20]\ttraining's binary_logloss: 0.190163\tvalid_1's binary_logloss: 0.210557\n",
      "[30]\ttraining's binary_logloss: 0.178211\tvalid_1's binary_logloss: 0.205711\n",
      "[40]\ttraining's binary_logloss: 0.169504\tvalid_1's binary_logloss: 0.203943\n",
      "[50]\ttraining's binary_logloss: 0.162097\tvalid_1's binary_logloss: 0.203603\n",
      "[60]\ttraining's binary_logloss: 0.155754\tvalid_1's binary_logloss: 0.203425\n",
      "[70]\ttraining's binary_logloss: 0.149936\tvalid_1's binary_logloss: 0.20371\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.154026\tvalid_1's binary_logloss: 0.203352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211247\tvalid_1's binary_logloss: 0.216875\n",
      "[20]\ttraining's binary_logloss: 0.192282\tvalid_1's binary_logloss: 0.2069\n",
      "[30]\ttraining's binary_logloss: 0.179636\tvalid_1's binary_logloss: 0.202946\n",
      "[40]\ttraining's binary_logloss: 0.169926\tvalid_1's binary_logloss: 0.201332\n",
      "[50]\ttraining's binary_logloss: 0.162584\tvalid_1's binary_logloss: 0.200732\n",
      "[60]\ttraining's binary_logloss: 0.155685\tvalid_1's binary_logloss: 0.20085\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.157032\tvalid_1's binary_logloss: 0.200705\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209074\tvalid_1's binary_logloss: 0.220253\n",
      "[20]\ttraining's binary_logloss: 0.190825\tvalid_1's binary_logloss: 0.210744\n",
      "[30]\ttraining's binary_logloss: 0.178863\tvalid_1's binary_logloss: 0.206293\n",
      "[40]\ttraining's binary_logloss: 0.169785\tvalid_1's binary_logloss: 0.205115\n",
      "[50]\ttraining's binary_logloss: 0.162162\tvalid_1's binary_logloss: 0.205134\n",
      "[60]\ttraining's binary_logloss: 0.155625\tvalid_1's binary_logloss: 0.20483\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.156154\tvalid_1's binary_logloss: 0.204687\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208446\tvalid_1's binary_logloss: 0.221479\n",
      "[20]\ttraining's binary_logloss: 0.190118\tvalid_1's binary_logloss: 0.211925\n",
      "[30]\ttraining's binary_logloss: 0.17804\tvalid_1's binary_logloss: 0.207695\n",
      "[40]\ttraining's binary_logloss: 0.168301\tvalid_1's binary_logloss: 0.205993\n",
      "[50]\ttraining's binary_logloss: 0.160347\tvalid_1's binary_logloss: 0.205561\n",
      "[60]\ttraining's binary_logloss: 0.153747\tvalid_1's binary_logloss: 0.20565\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.15628\tvalid_1's binary_logloss: 0.205308\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210297\tvalid_1's binary_logloss: 0.218398\n",
      "[20]\ttraining's binary_logloss: 0.19226\tvalid_1's binary_logloss: 0.208589\n",
      "[30]\ttraining's binary_logloss: 0.180043\tvalid_1's binary_logloss: 0.204257\n",
      "[40]\ttraining's binary_logloss: 0.170775\tvalid_1's binary_logloss: 0.202378\n",
      "[50]\ttraining's binary_logloss: 0.163237\tvalid_1's binary_logloss: 0.201654\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.164487\tvalid_1's binary_logloss: 0.201596\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210298\tvalid_1's binary_logloss: 0.218484\n",
      "[20]\ttraining's binary_logloss: 0.191616\tvalid_1's binary_logloss: 0.209185\n",
      "[30]\ttraining's binary_logloss: 0.179342\tvalid_1's binary_logloss: 0.203132\n",
      "[40]\ttraining's binary_logloss: 0.170211\tvalid_1's binary_logloss: 0.20184\n",
      "[50]\ttraining's binary_logloss: 0.162087\tvalid_1's binary_logloss: 0.201424\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.165257\tvalid_1's binary_logloss: 0.201024\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209056\tvalid_1's binary_logloss: 0.222138\n",
      "[20]\ttraining's binary_logloss: 0.190121\tvalid_1's binary_logloss: 0.21176\n",
      "[30]\ttraining's binary_logloss: 0.178548\tvalid_1's binary_logloss: 0.207568\n",
      "[40]\ttraining's binary_logloss: 0.169633\tvalid_1's binary_logloss: 0.206083\n",
      "[50]\ttraining's binary_logloss: 0.1618\tvalid_1's binary_logloss: 0.205036\n",
      "[60]\ttraining's binary_logloss: 0.155213\tvalid_1's binary_logloss: 0.205697\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.161109\tvalid_1's binary_logloss: 0.204948\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208454\tvalid_1's binary_logloss: 0.221976\n",
      "[20]\ttraining's binary_logloss: 0.189776\tvalid_1's binary_logloss: 0.211945\n",
      "[30]\ttraining's binary_logloss: 0.177583\tvalid_1's binary_logloss: 0.20755\n",
      "[40]\ttraining's binary_logloss: 0.167995\tvalid_1's binary_logloss: 0.205658\n",
      "[50]\ttraining's binary_logloss: 0.160138\tvalid_1's binary_logloss: 0.205046\n",
      "[60]\ttraining's binary_logloss: 0.153383\tvalid_1's binary_logloss: 0.204694\n",
      "[70]\ttraining's binary_logloss: 0.148069\tvalid_1's binary_logloss: 0.204602\n",
      "[80]\ttraining's binary_logloss: 0.143011\tvalid_1's binary_logloss: 0.205098\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.1475\tvalid_1's binary_logloss: 0.204566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209317\tvalid_1's binary_logloss: 0.219869\n",
      "[20]\ttraining's binary_logloss: 0.190289\tvalid_1's binary_logloss: 0.209938\n",
      "[30]\ttraining's binary_logloss: 0.178045\tvalid_1's binary_logloss: 0.205823\n",
      "[40]\ttraining's binary_logloss: 0.168396\tvalid_1's binary_logloss: 0.204973\n",
      "[50]\ttraining's binary_logloss: 0.160335\tvalid_1's binary_logloss: 0.204572\n",
      "[60]\ttraining's binary_logloss: 0.153529\tvalid_1's binary_logloss: 0.204846\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.15963\tvalid_1's binary_logloss: 0.204414\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208602\tvalid_1's binary_logloss: 0.221042\n",
      "[20]\ttraining's binary_logloss: 0.189966\tvalid_1's binary_logloss: 0.21173\n",
      "[30]\ttraining's binary_logloss: 0.177639\tvalid_1's binary_logloss: 0.208015\n",
      "[40]\ttraining's binary_logloss: 0.168168\tvalid_1's binary_logloss: 0.205641\n",
      "[50]\ttraining's binary_logloss: 0.160942\tvalid_1's binary_logloss: 0.2057\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.165083\tvalid_1's binary_logloss: 0.205581\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 726\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208454\tvalid_1's binary_logloss: 0.221409\n",
      "[20]\ttraining's binary_logloss: 0.19001\tvalid_1's binary_logloss: 0.210956\n",
      "[30]\ttraining's binary_logloss: 0.177963\tvalid_1's binary_logloss: 0.206879\n",
      "[40]\ttraining's binary_logloss: 0.168673\tvalid_1's binary_logloss: 0.205274\n",
      "[50]\ttraining's binary_logloss: 0.161074\tvalid_1's binary_logloss: 0.205413\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.166321\tvalid_1's binary_logloss: 0.205037\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210427\tvalid_1's binary_logloss: 0.217758\n",
      "[20]\ttraining's binary_logloss: 0.191905\tvalid_1's binary_logloss: 0.205958\n",
      "[30]\ttraining's binary_logloss: 0.179821\tvalid_1's binary_logloss: 0.201408\n",
      "[40]\ttraining's binary_logloss: 0.171006\tvalid_1's binary_logloss: 0.199678\n",
      "[50]\ttraining's binary_logloss: 0.162916\tvalid_1's binary_logloss: 0.198531\n",
      "[60]\ttraining's binary_logloss: 0.156388\tvalid_1's binary_logloss: 0.198647\n",
      "[70]\ttraining's binary_logloss: 0.150756\tvalid_1's binary_logloss: 0.198287\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.154054\tvalid_1's binary_logloss: 0.198148\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208132\tvalid_1's binary_logloss: 0.223053\n",
      "[20]\ttraining's binary_logloss: 0.189163\tvalid_1's binary_logloss: 0.213959\n",
      "[30]\ttraining's binary_logloss: 0.176824\tvalid_1's binary_logloss: 0.210996\n",
      "[40]\ttraining's binary_logloss: 0.167792\tvalid_1's binary_logloss: 0.209937\n",
      "[50]\ttraining's binary_logloss: 0.159691\tvalid_1's binary_logloss: 0.209837\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.166986\tvalid_1's binary_logloss: 0.209683\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209355\tvalid_1's binary_logloss: 0.220125\n",
      "[20]\ttraining's binary_logloss: 0.191578\tvalid_1's binary_logloss: 0.209347\n",
      "[30]\ttraining's binary_logloss: 0.179035\tvalid_1's binary_logloss: 0.205051\n",
      "[40]\ttraining's binary_logloss: 0.170209\tvalid_1's binary_logloss: 0.203\n",
      "[50]\ttraining's binary_logloss: 0.162787\tvalid_1's binary_logloss: 0.202915\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.167675\tvalid_1's binary_logloss: 0.202703\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.211871\tvalid_1's binary_logloss: 0.21634\n",
      "[20]\ttraining's binary_logloss: 0.193372\tvalid_1's binary_logloss: 0.204719\n",
      "[30]\ttraining's binary_logloss: 0.181423\tvalid_1's binary_logloss: 0.200253\n",
      "[40]\ttraining's binary_logloss: 0.172444\tvalid_1's binary_logloss: 0.198362\n",
      "[50]\ttraining's binary_logloss: 0.165095\tvalid_1's binary_logloss: 0.198225\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.168321\tvalid_1's binary_logloss: 0.197904\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 733\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.207307\tvalid_1's binary_logloss: 0.224072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.189194\tvalid_1's binary_logloss: 0.214868\n",
      "[30]\ttraining's binary_logloss: 0.177015\tvalid_1's binary_logloss: 0.211002\n",
      "[40]\ttraining's binary_logloss: 0.167883\tvalid_1's binary_logloss: 0.209158\n",
      "[50]\ttraining's binary_logloss: 0.160507\tvalid_1's binary_logloss: 0.208785\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.162531\tvalid_1's binary_logloss: 0.208419\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.207964\tvalid_1's binary_logloss: 0.222934\n",
      "[20]\ttraining's binary_logloss: 0.189\tvalid_1's binary_logloss: 0.214267\n",
      "[30]\ttraining's binary_logloss: 0.176466\tvalid_1's binary_logloss: 0.210327\n",
      "[40]\ttraining's binary_logloss: 0.167117\tvalid_1's binary_logloss: 0.207685\n",
      "[50]\ttraining's binary_logloss: 0.159413\tvalid_1's binary_logloss: 0.207059\n",
      "[60]\ttraining's binary_logloss: 0.152843\tvalid_1's binary_logloss: 0.207627\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.159413\tvalid_1's binary_logloss: 0.207059\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209899\tvalid_1's binary_logloss: 0.220401\n",
      "[20]\ttraining's binary_logloss: 0.191846\tvalid_1's binary_logloss: 0.210253\n",
      "[30]\ttraining's binary_logloss: 0.179681\tvalid_1's binary_logloss: 0.205117\n",
      "[40]\ttraining's binary_logloss: 0.170373\tvalid_1's binary_logloss: 0.203793\n",
      "[50]\ttraining's binary_logloss: 0.162713\tvalid_1's binary_logloss: 0.203474\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.164144\tvalid_1's binary_logloss: 0.203084\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.210227\tvalid_1's binary_logloss: 0.220007\n",
      "[20]\ttraining's binary_logloss: 0.19222\tvalid_1's binary_logloss: 0.209729\n",
      "[30]\ttraining's binary_logloss: 0.180457\tvalid_1's binary_logloss: 0.20522\n",
      "[40]\ttraining's binary_logloss: 0.171287\tvalid_1's binary_logloss: 0.203063\n",
      "[50]\ttraining's binary_logloss: 0.163705\tvalid_1's binary_logloss: 0.202806\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.16504\tvalid_1's binary_logloss: 0.202593\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 729\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209732\tvalid_1's binary_logloss: 0.219515\n",
      "[20]\ttraining's binary_logloss: 0.191327\tvalid_1's binary_logloss: 0.209612\n",
      "[30]\ttraining's binary_logloss: 0.178919\tvalid_1's binary_logloss: 0.205074\n",
      "[40]\ttraining's binary_logloss: 0.169878\tvalid_1's binary_logloss: 0.204143\n",
      "[50]\ttraining's binary_logloss: 0.162866\tvalid_1's binary_logloss: 0.203839\n",
      "[60]\ttraining's binary_logloss: 0.156694\tvalid_1's binary_logloss: 0.203342\n",
      "[70]\ttraining's binary_logloss: 0.150977\tvalid_1's binary_logloss: 0.20357\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.155161\tvalid_1's binary_logloss: 0.203026\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209359\tvalid_1's binary_logloss: 0.219211\n",
      "[20]\ttraining's binary_logloss: 0.191318\tvalid_1's binary_logloss: 0.209133\n",
      "[30]\ttraining's binary_logloss: 0.178666\tvalid_1's binary_logloss: 0.204441\n",
      "[40]\ttraining's binary_logloss: 0.169269\tvalid_1's binary_logloss: 0.204269\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.170073\tvalid_1's binary_logloss: 0.203987\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20956\tvalid_1's binary_logloss: 0.219787\n",
      "[20]\ttraining's binary_logloss: 0.191542\tvalid_1's binary_logloss: 0.210004\n",
      "[30]\ttraining's binary_logloss: 0.179994\tvalid_1's binary_logloss: 0.205269\n",
      "[40]\ttraining's binary_logloss: 0.170821\tvalid_1's binary_logloss: 0.203126\n",
      "[50]\ttraining's binary_logloss: 0.163467\tvalid_1's binary_logloss: 0.202613\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.165625\tvalid_1's binary_logloss: 0.202361\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209102\tvalid_1's binary_logloss: 0.219731\n",
      "[20]\ttraining's binary_logloss: 0.190859\tvalid_1's binary_logloss: 0.210058\n",
      "[30]\ttraining's binary_logloss: 0.178097\tvalid_1's binary_logloss: 0.205758\n",
      "[40]\ttraining's binary_logloss: 0.168852\tvalid_1's binary_logloss: 0.203547\n",
      "[50]\ttraining's binary_logloss: 0.161408\tvalid_1's binary_logloss: 0.203222\n",
      "[60]\ttraining's binary_logloss: 0.154709\tvalid_1's binary_logloss: 0.203281\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.160791\tvalid_1's binary_logloss: 0.202943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209023\tvalid_1's binary_logloss: 0.219478\n",
      "[20]\ttraining's binary_logloss: 0.190182\tvalid_1's binary_logloss: 0.210315\n",
      "[30]\ttraining's binary_logloss: 0.178173\tvalid_1's binary_logloss: 0.20626\n",
      "[40]\ttraining's binary_logloss: 0.169258\tvalid_1's binary_logloss: 0.205209\n",
      "[50]\ttraining's binary_logloss: 0.162092\tvalid_1's binary_logloss: 0.205646\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.168412\tvalid_1's binary_logloss: 0.205034\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 726\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20801\tvalid_1's binary_logloss: 0.220682\n",
      "[20]\ttraining's binary_logloss: 0.189212\tvalid_1's binary_logloss: 0.211953\n",
      "[30]\ttraining's binary_logloss: 0.177094\tvalid_1's binary_logloss: 0.207921\n",
      "[40]\ttraining's binary_logloss: 0.167778\tvalid_1's binary_logloss: 0.206299\n",
      "[50]\ttraining's binary_logloss: 0.159909\tvalid_1's binary_logloss: 0.206218\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.160709\tvalid_1's binary_logloss: 0.206106\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.209649\tvalid_1's binary_logloss: 0.220762\n",
      "[20]\ttraining's binary_logloss: 0.190981\tvalid_1's binary_logloss: 0.210618\n",
      "[30]\ttraining's binary_logloss: 0.179147\tvalid_1's binary_logloss: 0.205654\n",
      "[40]\ttraining's binary_logloss: 0.170031\tvalid_1's binary_logloss: 0.203719\n",
      "[50]\ttraining's binary_logloss: 0.16246\tvalid_1's binary_logloss: 0.203022\n",
      "[60]\ttraining's binary_logloss: 0.155981\tvalid_1's binary_logloss: 0.202676\n",
      "[70]\ttraining's binary_logloss: 0.149694\tvalid_1's binary_logloss: 0.202606\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's binary_logloss: 0.150832\tvalid_1's binary_logloss: 0.202463\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.20907\tvalid_1's binary_logloss: 0.22096\n",
      "[20]\ttraining's binary_logloss: 0.190721\tvalid_1's binary_logloss: 0.210136\n",
      "[30]\ttraining's binary_logloss: 0.178245\tvalid_1's binary_logloss: 0.205798\n",
      "[40]\ttraining's binary_logloss: 0.169327\tvalid_1's binary_logloss: 0.204113\n",
      "[50]\ttraining's binary_logloss: 0.161734\tvalid_1's binary_logloss: 0.203878\n",
      "[60]\ttraining's binary_logloss: 0.154745\tvalid_1's binary_logloss: 0.203861\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.156298\tvalid_1's binary_logloss: 0.203636\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208763\tvalid_1's binary_logloss: 0.219329\n",
      "[20]\ttraining's binary_logloss: 0.190427\tvalid_1's binary_logloss: 0.20926\n",
      "[30]\ttraining's binary_logloss: 0.17844\tvalid_1's binary_logloss: 0.205619\n",
      "[40]\ttraining's binary_logloss: 0.168752\tvalid_1's binary_logloss: 0.20427\n",
      "[50]\ttraining's binary_logloss: 0.160881\tvalid_1's binary_logloss: 0.204307\n",
      "[60]\ttraining's binary_logloss: 0.154368\tvalid_1's binary_logloss: 0.204001\n",
      "[70]\ttraining's binary_logloss: 0.148739\tvalid_1's binary_logloss: 0.204597\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's binary_logloss: 0.154368\tvalid_1's binary_logloss: 0.204001\n",
      "[LightGBM] [Info] Number of positive: 1478, number of negative: 17492\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 731\n",
      "[LightGBM] [Info] Number of data points in the train set: 18970, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.077912 -> initscore=-2.471054\n",
      "[LightGBM] [Info] Start training from score -2.471054\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's binary_logloss: 0.208609\tvalid_1's binary_logloss: 0.219859\n",
      "[20]\ttraining's binary_logloss: 0.190439\tvalid_1's binary_logloss: 0.210102\n",
      "[30]\ttraining's binary_logloss: 0.178759\tvalid_1's binary_logloss: 0.205453\n",
      "[40]\ttraining's binary_logloss: 0.169436\tvalid_1's binary_logloss: 0.204319\n",
      "[50]\ttraining's binary_logloss: 0.161737\tvalid_1's binary_logloss: 0.202904\n",
      "[60]\ttraining's binary_logloss: 0.155123\tvalid_1's binary_logloss: 0.202724\n",
      "[70]\ttraining's binary_logloss: 0.149119\tvalid_1's binary_logloss: 0.202902\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.153054\tvalid_1's binary_logloss: 0.202647\n"
     ]
    }
   ],
   "source": [
    "output_df = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    #訓練データからテストデータを分割\n",
    "    X_train , X_valid , y_train , y_valid = train_test_split(X_train_origin,y_train_origin,test_size = 0.3 , random_state = i , stratify=y_train_origin)\n",
    "    #使用モデルはLGB（パラメーターチューニングなし）\n",
    "    lgb_train = lgb.Dataset(X_train,y_train,categorical_feature = categorical_features)\n",
    "    lgb_eval = lgb.Dataset(X_valid , y_valid , reference = lgb_train , categorical_feature = categorical_features)\n",
    "    params = {\n",
    "        \"objective\":\"binary\"\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,lgb_train,\n",
    "        valid_sets=[lgb_train,lgb_eval],\n",
    "        verbose_eval = 10,\n",
    "        num_boost_round = 1000,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test_origin,num_iteration=model.best_iteration)\n",
    "    output_df[i] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.826259\n",
       "1        0.073341\n",
       "2        0.031332\n",
       "3        0.004073\n",
       "4        0.042300\n",
       "           ...   \n",
       "18045    0.018109\n",
       "18046    0.008078\n",
       "18047    0.081957\n",
       "18048    0.008301\n",
       "18049    0.104220\n",
       "Length: 18050, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## これは単に100回、random_stateを変更しながら繰り返してLightGBMを実行した結果の平均値をTEST結果とした。これでAUCが<<0.854>>となったらしい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからはさらに上を目指すためにやったこと、、、らしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows' ,500)\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_org = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        nov\n",
       "1        aug\n",
       "2        nov\n",
       "3        may\n",
       "4        apr\n",
       "        ... \n",
       "27095    may\n",
       "27096    may\n",
       "27097    jun\n",
       "27098    may\n",
       "27099    may\n",
       "Name: month, Length: 27100, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthはdayと結合するつもりなので数字に直しました\n",
    "#今回のデータに12月は存在しません\n",
    "month_dict = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12}\n",
    "train_df[\"month\"] = train_df[\"month\"].map(month_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        11\n",
       "1         8\n",
       "2        11\n",
       "3         5\n",
       "4         4\n",
       "         ..\n",
       "27095     5\n",
       "27096     5\n",
       "27097     6\n",
       "27098     5\n",
       "27099     5\n",
       "Name: month, Length: 27100, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#年齢\n",
    "#age\n",
    "#60歳以上の扱いに悩んだので丸めました\n",
    "#～59歳までは十代ごとに、60歳ちょうど、60歳より上に変換\n",
    "age_list = list(train_df[\"age\"])\n",
    "\n",
    "new_age_list = []\n",
    "\n",
    "for i in range(len(age_list)):\n",
    "    if age_list[i] == 60:\n",
    "        new_age_list.append(60)\n",
    "    elif age_list[i] > 60:\n",
    "        new_age_list.append(70)\n",
    "    else:\n",
    "        new_age_list.append(int(age_list[i]/10)*10)\n",
    "train_df[\"age_round\"] = new_age_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        30\n",
       " 1        20\n",
       " 2        30\n",
       " 3        30\n",
       " 4        40\n",
       "          ..\n",
       " 27095    30\n",
       " 27096    30\n",
       " 27097    30\n",
       " 27098    30\n",
       " 27099    30\n",
       " Name: age_round, Length: 27100, dtype: int64,\n",
       " 0        31\n",
       " 1        29\n",
       " 2        35\n",
       " 3        31\n",
       " 4        48\n",
       "          ..\n",
       " 27095    37\n",
       " 27096    35\n",
       " 27097    35\n",
       " 27098    30\n",
       " 27099    34\n",
       " Name: age, Length: 27100, dtype: int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"age_round\"], train_df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>age_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "      <td>27100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13549.500000</td>\n",
       "      <td>36.073284</td>\n",
       "      <td>47682.901771</td>\n",
       "      <td>16.747565</td>\n",
       "      <td>6.001919</td>\n",
       "      <td>229.325387</td>\n",
       "      <td>1.775830</td>\n",
       "      <td>432.482399</td>\n",
       "      <td>0.085720</td>\n",
       "      <td>0.077934</td>\n",
       "      <td>32.493358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7823.240484</td>\n",
       "      <td>7.816417</td>\n",
       "      <td>31650.760036</td>\n",
       "      <td>8.569588</td>\n",
       "      <td>2.137665</td>\n",
       "      <td>204.939958</td>\n",
       "      <td>0.950045</td>\n",
       "      <td>252.150648</td>\n",
       "      <td>0.365889</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>7.323010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-6847.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6774.750000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>20015.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13549.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>47624.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20324.250000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>75330.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27099.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>102121.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3076.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>870.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           age        balance           day         month  \\\n",
       "count  27100.000000  27100.000000   27100.000000  27100.000000  27100.000000   \n",
       "mean   13549.500000     36.073284   47682.901771     16.747565      6.001919   \n",
       "std     7823.240484      7.816417   31650.760036      8.569588      2.137665   \n",
       "min        0.000000     22.000000   -6847.000000      1.000000      1.000000   \n",
       "25%     6774.750000     31.000000   20015.750000      8.000000      5.000000   \n",
       "50%    13549.500000     33.000000   47624.000000     17.000000      5.000000   \n",
       "75%    20324.250000     37.000000   75330.000000     26.000000      7.000000   \n",
       "max    27099.000000     90.000000  102121.000000     31.000000     11.000000   \n",
       "\n",
       "           duration      campaign         pdays      previous             y  \\\n",
       "count  27100.000000  27100.000000  27100.000000  27100.000000  27100.000000   \n",
       "mean     229.325387      1.775830    432.482399      0.085720      0.077934   \n",
       "std      204.939958      0.950045    252.150648      0.365889      0.268072   \n",
       "min        0.000000      1.000000     -1.000000      0.000000      0.000000   \n",
       "25%      121.000000      1.000000    214.000000      0.000000      0.000000   \n",
       "50%      158.000000      1.000000    432.000000      0.000000      0.000000   \n",
       "75%      345.000000      2.000000    650.000000      0.000000      0.000000   \n",
       "max     3076.000000      5.000000    870.000000      3.000000      1.000000   \n",
       "\n",
       "          age_round  \n",
       "count  27100.000000  \n",
       "mean      32.493358  \n",
       "std        7.323010  \n",
       "min       20.000000  \n",
       "25%       30.000000  \n",
       "50%       30.000000  \n",
       "75%       30.000000  \n",
       "max       70.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col_list = [\"age\",\"balance\",\"duration\",\"campaign\",\"pdays\",\"previous\"]\n",
    "\n",
    "categorical_col_list  = [categorical_feature for categorical_feature in train_df.columns if categorical_feature not in numeric_col_list]\n",
    "categorical_col_list.remove(\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： age\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24988.0</td>\n",
       "      <td>35.876341</td>\n",
       "      <td>7.564353</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112.0</td>\n",
       "      <td>38.403409</td>\n",
       "      <td>10.056032</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count       mean        std   min   25%   50%   75%   max\n",
       "y                                                             \n",
       "0  24988.0  35.876341   7.564353  24.0  31.0  33.0  37.0  90.0\n",
       "1   2112.0  38.403409  10.056032  22.0  31.0  34.0  46.0  60.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： balance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24988.0</td>\n",
       "      <td>47691.172203</td>\n",
       "      <td>31668.085023</td>\n",
       "      <td>-6847.0</td>\n",
       "      <td>19984.0</td>\n",
       "      <td>47721.0</td>\n",
       "      <td>75322.75</td>\n",
       "      <td>102121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112.0</td>\n",
       "      <td>47585.050663</td>\n",
       "      <td>31452.346082</td>\n",
       "      <td>-6757.0</td>\n",
       "      <td>20342.5</td>\n",
       "      <td>46582.5</td>\n",
       "      <td>75423.25</td>\n",
       "      <td>102101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count          mean           std     min      25%      50%       75%  \\\n",
       "y                                                                            \n",
       "0  24988.0  47691.172203  31668.085023 -6847.0  19984.0  47721.0  75322.75   \n",
       "1   2112.0  47585.050663  31452.346082 -6757.0  20342.5  46582.5  75423.25   \n",
       "\n",
       "        max  \n",
       "y            \n",
       "0  102121.0  \n",
       "1  102101.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： duration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24988.0</td>\n",
       "      <td>231.131423</td>\n",
       "      <td>204.385639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>3076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112.0</td>\n",
       "      <td>207.957386</td>\n",
       "      <td>210.263042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1347.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count        mean         std  min    25%    50%    75%     max\n",
       "y                                                                   \n",
       "0  24988.0  231.131423  204.385639  0.0  121.0  158.0  345.0  3076.0\n",
       "1   2112.0  207.957386  210.263042  0.0  101.0  158.0  177.0  1347.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： campaign\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24988.0</td>\n",
       "      <td>1.784296</td>\n",
       "      <td>0.953880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112.0</td>\n",
       "      <td>1.675663</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std  min  25%  50%  75%  max\n",
       "y                                                      \n",
       "0  24988.0  1.784296  0.953880  1.0  1.0  1.0  2.0  5.0\n",
       "1   2112.0  1.675663  0.897607  1.0  1.0  1.0  2.0  4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： pdays\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24988.0</td>\n",
       "      <td>432.490916</td>\n",
       "      <td>252.018980</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112.0</td>\n",
       "      <td>432.381629</td>\n",
       "      <td>253.763276</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>217.5</td>\n",
       "      <td>428.0</td>\n",
       "      <td>649.5</td>\n",
       "      <td>870.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count        mean         std  min    25%    50%    75%    max\n",
       "y                                                                  \n",
       "0  24988.0  432.490916  252.018980 -1.0  214.0  433.0  650.0  870.0\n",
       "1   2112.0  432.381629  253.763276 -1.0  217.5  428.0  649.5  870.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： previous\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24988.0</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.310772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112.0</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.717175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std  min  25%  50%  75%  max\n",
       "y                                                      \n",
       "0  24988.0  0.065672  0.310772  0.0  0.0  0.0  0.0  3.0\n",
       "1   2112.0  0.322917  0.717175  0.0  0.0  0.0  0.0  3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#numericについては目的変数でグルーピングして統計量を算出\n",
    "for target_col in numeric_col_list:\n",
    "    print(\"\\ntarget_col：\",target_col)\n",
    "    display(train_df.groupby(\"y\")[target_col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  job          \n",
       "0  admin.           2911\n",
       "   blue-collar      5612\n",
       "   entrepreneur     1060\n",
       "   housemaid         686\n",
       "   management       4883\n",
       "   retired           836\n",
       "   self-employed    1051\n",
       "   services         2308\n",
       "   student           249\n",
       "   technician       4704\n",
       "   unemployed        688\n",
       "1  admin.            276\n",
       "   blue-collar       345\n",
       "   entrepreneur       95\n",
       "   housemaid          68\n",
       "   management        463\n",
       "   retired           168\n",
       "   self-employed     112\n",
       "   services          163\n",
       "   student           104\n",
       "   technician        211\n",
       "   unemployed        107\n",
       "Name: job, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： marital\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  marital \n",
       "0  divorced     2278\n",
       "   married     16467\n",
       "   single       6243\n",
       "1  divorced      157\n",
       "   married      1098\n",
       "   single        857\n",
       "Name: marital, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： education\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  education\n",
       "0  primary       3112\n",
       "   secondary    14928\n",
       "   tertiary      6033\n",
       "   unknown        915\n",
       "1  primary        217\n",
       "   secondary     1027\n",
       "   tertiary       704\n",
       "   unknown        164\n",
       "Name: education, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  default\n",
       "0  no         24978\n",
       "   yes           10\n",
       "1  no          2112\n",
       "Name: default, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： housing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  housing\n",
       "0  no          9812\n",
       "   yes        15176\n",
       "1  no          1469\n",
       "   yes          643\n",
       "Name: housing, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： loan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  loan\n",
       "0  no      21656\n",
       "   yes      3332\n",
       "1  no       1995\n",
       "   yes       117\n",
       "Name: loan, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： contact\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  contact  \n",
       "0  cellular     17398\n",
       "   telephone     1005\n",
       "   unknown       6585\n",
       "1  cellular      1749\n",
       "   telephone       99\n",
       "   unknown        264\n",
       "Name: contact, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： day\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  day\n",
       "0  1         1\n",
       "   2      1442\n",
       "   3       707\n",
       "   4       838\n",
       "   5       149\n",
       "   6       473\n",
       "   7      1761\n",
       "   8      1050\n",
       "   9       280\n",
       "   10        4\n",
       "   11      288\n",
       "   12      961\n",
       "   13      530\n",
       "   14      332\n",
       "   15     1424\n",
       "   16     1579\n",
       "   17     1092\n",
       "   18     1605\n",
       "   19      123\n",
       "   20     1597\n",
       "   21     1282\n",
       "   22      112\n",
       "   23      249\n",
       "   25      108\n",
       "   26     1058\n",
       "   27     4087\n",
       "   28      957\n",
       "   29       37\n",
       "   30      859\n",
       "   31        3\n",
       "1  2        53\n",
       "   3        99\n",
       "   4        34\n",
       "   5        50\n",
       "   6        29\n",
       "   7       158\n",
       "   8        92\n",
       "   9        96\n",
       "   11       36\n",
       "   12       99\n",
       "   13       88\n",
       "   14      103\n",
       "   15       27\n",
       "   16      102\n",
       "   17      193\n",
       "   18      127\n",
       "   19       17\n",
       "   20       96\n",
       "   21       46\n",
       "   22       12\n",
       "   23       19\n",
       "   25        8\n",
       "   26      114\n",
       "   27       42\n",
       "   28       87\n",
       "   29        1\n",
       "   30      284\n",
       "Name: day, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： month\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  month\n",
       "0  1          315\n",
       "   2          922\n",
       "   3          115\n",
       "   4         1597\n",
       "   5        10736\n",
       "   6         2910\n",
       "   7         3020\n",
       "   8         3150\n",
       "   9           19\n",
       "   10          42\n",
       "   11        2162\n",
       "1  1           46\n",
       "   2          161\n",
       "   3           99\n",
       "   4          408\n",
       "   5          496\n",
       "   6          176\n",
       "   7          287\n",
       "   8          231\n",
       "   9            8\n",
       "   10          55\n",
       "   11         145\n",
       "Name: month, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： poutcome\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  poutcome\n",
       "0  failure      2598\n",
       "   other         786\n",
       "   success       147\n",
       "   unknown     21457\n",
       "1  failure       119\n",
       "   other          40\n",
       "   success       311\n",
       "   unknown      1642\n",
       "Name: poutcome, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  y\n",
       "0  0    24988\n",
       "1  1     2112\n",
       "Name: y, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "target_col： age_round\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y  age_round\n",
       "0  20            1226\n",
       "   30           18923\n",
       "   40            3054\n",
       "   50            1383\n",
       "   60             389\n",
       "   70              13\n",
       "1  20             220\n",
       "   30            1227\n",
       "   40             323\n",
       "   50             185\n",
       "   60             157\n",
       "Name: age_round, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#categoricalについては目的変数でグルーピングしてカウント\n",
    "for target_col in categorical_col_list:\n",
    "    print(\"\\ntarget_col：\",target_col)\n",
    "    display(train_df.groupby([\"y\",target_col])[target_col].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#平均値と中央値を可視化して確認\n",
    "#yの01別で平均値、中央値\n",
    "y0_df = train_df.query('y == 0')\n",
    "y1_df = train_df.query('y == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEJCAYAAACT/UyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUDklEQVR4nO3dfZBldX3n8ffHAYQACiwNO86AQxniQxkctJl1tWIUlQWiEbZISioxk110cEsjVqIRk60IxqwxkZBKuWEzCIHauEbWyOKqEREYjSkK08AwPBlRMi7ILDQgCMmKYfjuH/dMvPZ0z1wezr3d/Xu/qm71eby/b8+c++lzf+cpVYUkqR3PmHQBkqTxMvglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EsTlmRNkkqyRzf+10nWT7ouLV97TLoAST+uqk6YdA1a3tzjl6TGGPxaUpKcmeTbSR5OcmuSk4fmrUhyTpL7kvxDknfO6UJ5dpILkmxL8t0kH0qyYsR2z0ryP5P8Rdf2TUl+Ksn7k9yb5M4kxw0tv2BbXZ0f7eq8A/i5OW1tSvLWbvh5Sa5Kcn+3/CeSHDC07NYk70myJclDST6VZO+n9I+sZc/g11LzbeBngGcDZwN/kWRlN+9twAnAWuClwElz1r0YeAz4SeBo4DhgR8AenuTBJIfvou03Av8dOBC4AbicwWdoFfBB4M9Gaaur8w3d9GnglF20GeDDwHOAFwKHAWfNWeYXgeOBI4CjgF/dxftJUFW+fC3ZF7AZeFM3fBVw+tC81wHF4FjWocCjwD5D808Frh6xnbOAK4bG3wg8Aqzoxvfv2jpgd211db59aN5xO+rsxjcBb12gjpOAG4bGtwK/PDT+B8B/m/T/i6/F/fLgrpaUJL8C/Dqwppu0H3BwN/wc4M6hxYeHnwvsCWxLsmPaM+Ysszv3DA3/P+C+qto+NL6jnufspq25dX5noQaTHAL8CYNvOft37/O9OYv936Hhf+reX1qQwa8lI8lzgfOB1wLXVNX2JJsZdIcAbANWD61y2NDwnQz2wg+uqsd6LnV3bW2bU9uuupc+zODbwFFVdX+Sk4CPPW2Vqkn28Wsp2ZdBCM4CJPkPwIuH5l8CnJFkVXcA9H07ZlTVNuBLwDlJnpXkGd2B0599uoscoa1LgHclWZ3kQODMXbzd/gy6lB5Msgp479Ndr9pj8GvJqKpbgXOAaxh0u/w08LdDi5zPIHC3MDj4+gUGB1h3dMf8CrAXcCuD7pJPAyvhXw7uPrKbg7tPxIJtdXVeDtwIXA98ZhfvczaDA9UPAZ/fzbLSSFLlg1i0PCU5gcGBzudOuhZpMXGPX8tGkn2SnJhkj65b5APApZOuS1ps3OPXspHkJ4CvAC9gcJbN54Ezqur7Ey1MWmQMfklqjF09ktSYJXEe/8EHH1xr1qyZdBmStKRcd91191XV1NzpSyL416xZw8zMzKTLkKQlJcm8V4Xb1SNJjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmN6D/7uwdI3JPlcN35EkmuT3N49GHqvvmuQJP3IOPb4zwBuGxr/CHBuVR3J4D7lp42hBklSp9fgT7Ia+Dng4914gGMZPJQC4GIGD4+WJI1J33v8fwz8JvB4N/6vgAeHnkN6F7BqvhWTbEgyk2Rmdna25zIlqR29BX+SNwD3VtV1w5PnWXTe+0JX1caqmq6q6ampne4xJEl6kvq8SdsrgZ9PciKwN/AsBt8ADkiyR7fXvxq4u8caJElz9LbHX1Xvr6rVVbUGeDNwVVX9EnA1cEq32Hrgsr5qkCTtbBLn8b8P+PUk32LQ53/BBGqQpGaN5X78VbUJ2NQN3wGsG0e7kqSdeeWuJDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxfT5sfe8kX09yY5JbkpzdTb8oyT8k2dy91vZVgyRpZ30+getR4NiqeiTJnsDXkvx1N++9VfXpHtuWJC2gt+CvqgIe6Ub37F7VV3uSpNH02sefZEWSzcC9wBVVdW036/eSbElybpJn9lmDJOnH9Rr8VbW9qtYCq4F1SV4MvB94AXAMcBDwvvnWTbIhyUySmdnZ2T7LlKSmjOWsnqp6ENgEHF9V22rgUeDPgXULrLOxqqaranpqamocZUpSE/o8q2cqyQHd8D7A64BvJFnZTQtwEnBzXzVIknbW51k9K4GLk6xg8Afmkqr6XJKrkkwBATYDb++xBknSHH2e1bMFOHqe6cf21aYkaff63OOXNIKcnUmXoEWsPvD0nwXvLRskqTEGvyQ1xuCXpMYY/JLUmGV/cNcDZ1pIHwfNpKXAPX5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxfT5zd+8kX09yY5JbkpzdTT8iybVJbk/yqSR79VWDJGlnfe7xPwocW1UvAdYCxyd5OfAR4NyqOhL4HnBajzVIkuboLfhr4JFudM/uVcCxwKe76RcDJ/VVgyRpZ7328SdZkWQzcC9wBfBt4MGqeqxb5C5g1QLrbkgyk2Rmdna2zzIlqSm9Bn9Vba+qtcBqYB3wwvkWW2DdjVU1XVXTU1NTfZYpSU0Zy1k9VfUgsAl4OXBAkh0PgFkN3D2OGiRJA32e1TOV5IBueB/gdcBtwNXAKd1i64HL+qpBkrSzPh+9uBK4OMkKBn9gLqmqzyW5FfjLJB8CbgAu6LEGSdIcvQV/VW0Bjp5n+h0M+vslSRPglbuS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmD6fuXtYkquT3JbkliRndNPPSvLdJJu714l91SBJ2lmfz9x9DPiNqro+yf7AdUmu6OadW1Uf7bFtSdIC+nzm7jZgWzf8cJLbgFV9tSdJGs1Y+viTrGHw4PVru0nvTLIlyYVJDlxgnQ1JZpLMzM7OjqNMSWpC78GfZD/gr4B3V9X3gfOA5wFrGXwjOGe+9apqY1VNV9X01NRU32VKUjN6Df4kezII/U9U1WcAquqeqtpeVY8D5wPr+qxBkvTj+jyrJ8AFwG1V9UdD01cOLXYycHNfNUiSdtbnWT2vBN4C3JRkczftt4BTk6wFCtgKnN5jDZKkOfo8q+drQOaZ9YW+2pQk7Z5X7kpSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1JgnFPxJ9u2rEEnSeIwU/ElekeRW4LZu/CVJ/rTXyiRJvRh1j/9c4N8B9wNU1Y3Aq/oqSpLUn5G7eqrqzjmTtj/NtUiSxmDUe/XcmeQVQCXZC3gXXbePJGlpGXWP/+3AOxg8OvEuBg9ReUdfRUmS+jPSHn9V3Qf8Us+1SJLGYKTgT/In80x+CJipqsue3pIkSX0atatnbwbdO7d3r6OAg4DTkvxxT7VJknow6sHdnwSOrarHAJKcB3wJeD1wU0+1SZJ6MOoe/ypg+KrdfYHnVNV24NH5VkhyWJKrk9yW5JYkZ3TTD0pyRZLbu58HPqXfQJL0hIwa/H8AbE7y50kuAm4APtrdwuHLC6zzGPAbVfVC4OXAO5K8CDgTuLKqjgSu7MYlSWMyUvBX1QUMHp7+DeBS4D8D36yqf6yq9y6wzraqur4bfpjBef+rgDcBF3eLXQyc9JR+A0nSEzLqWT1vBc4AVgObGezBXwMcO+L6a4CjgWuBQ6tqGwz+OCQ5ZIF1NgAbAA4//PBRmpEkjWDUrp4zgGOA71TVaxiE+OwoKybZD/gr4N1V9f1RC6uqjVU1XVXTU1NTo64mSdqNUYP/B1X1A4Akz6yqbwDP391KSfZkEPqfqKrPdJPvSbKym78SuPeJly1JerJGDf67khwA/C/giiSXAXfvaoUkAS4AbquqPxqa9VlgfTe8HvACMEkao1Fv2XByN3hWkquBZwNf3M1qrwTeAtyUZHM37beA3wcuSXIa8H+AX3jCVUuSnrRRL+D6F1X1lRGX+xqQBWa/9om2K0l6evjMXUlqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSY3oL/iQXJrk3yc1D085K8t0km7vXiX21L0maX597/BcBx88z/dyqWtu9vtBj+5KkefQW/FX1VeCBvt5fkvTkTKKP/51JtnRdQQdOoH1Jatq4g/884HnAWmAbcM5CCybZkGQmyczs7Oy46pOkZW+swV9V91TV9qp6HDgfWLeLZTdW1XRVTU9NTY2vSEla5sYa/ElWDo2eDNy80LKSpH7s0dcbJ/kk8Grg4CR3AR8AXp1kLVDAVuD0vtqXJM2vt+CvqlPnmXxBX+1JkkbjlbuS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmN6CP8mFSe5NcvPQtIOSXJHk9u7ngX21L0maX597/BcBx8+ZdiZwZVUdCVzZjUuSxqi34K+qrwIPzJn8JuDibvhi4KS+2pckzW/cffyHVtU2gO7nIQstmGRDkpkkM7Ozs2MrUJKWu0V7cLeqNlbVdFVNT01NTbocSVo2xh389yRZCdD9vHfM7UtS88Yd/J8F1nfD64HLxty+JDWvz9M5PwlcAzw/yV1JTgN+H3h9ktuB13fjkqQx2qOvN66qUxeY9dq+2pQk7d6iPbgrSeqHwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JakxvT+DalSRbgYeB7cBjVTU9iTokqUUTCf7Oa6rqvgm2L0lNsqtHkhozqeAv4EtJrkuyYb4FkmxIMpNkZnZ2dszlSdLyNangf2VVvRQ4AXhHklfNXaCqNlbVdFVNT01Njb9CSVqmJhL8VXV39/Ne4FJg3STqkKQWjT34k+ybZP8dw8BxwM3jrkOSWjWJs3oOBS5NsqP9/1FVX5xAHZLUpLEHf1XdAbxk3O1KkgY8nVOSGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaM5HgT3J8kr9P8q0kZ06iBklq1SQetr4C+K/ACcCLgFOTvGjcdUhSqyaxx78O+FZV3VFVPwT+EnjTBOqQpCaN/WHrwCrgzqHxu4B/M3ehJBuADd3oI0n+fgy1teBg4L5JF7EY5KxMugTNz210yFPcTp8738RJBP98v0XtNKFqI7Cx/3LakmSmqqYnXYe0ELfR/k2iq+cu4LCh8dXA3ROoQ5KaNIng/zvgyCRHJNkLeDPw2QnUIUlNGntXT1U9luSdwOXACuDCqrpl3HU0zO4zLXZuoz1L1U7d65KkZcwrdyWpMQa/JDXG4Jekxhj8i1iS9Ulu717rx9juRUlO6YY/7i01tJAkX0zyYJLPjbnds5K8pxv+YJLXjbP9pW4SF3BpBEkOAj4ATDO4wO26JJ+tqu+Ns46qeus429OS84fATwCnT6qAqvqdSbW9VLnHvwgk+d0kZwyN/x7wa8AVVfVAF/ZXAMfv4j0eSfKRJNcl+XKSdUk2Jbkjyc93y6xI8odJ/i7JliSnd9OT5GNJbk3yeeCQoffdlGS6Gz4vyUySW5KcPbTM1iRnJ7k+yU1JXvA0/xNpwubbRpO8q6quBB4e8T22JvkvSa7ptqOXJrk8ybeTvH1oufcObaPD29lvd3f1/TLw/KHpw99Qf6db9+YkG5Okm76p+3x8Pck3k/zMU/9XWboM/sXhAmA9QJJnMLio7QfsfE+jVbt4j32BTVX1MgYfxA8BrwdOBj7YLXMa8FBVHQMcA7wtyRHdMs8Hfhp4G/CKBdr47e5S+qOAn01y1NC8+6rqpcB5wHtG+aW1pMy3jX7iSbzPnVX1b4G/AS4CTgFeTreNJjkOOJLBzRzXAi9L8qokL+vaPBr49wy23/l8rKqOqaoXA/sAbxiat0dVrQPezeDbdLPs6lkEqmprkvuTHA0cCtwAPD7fort4mx8CX+yGbwIerap/TnITsKabfhxw1I69I+DZDD5krwI+WVXbgbuTXLVAG7/Y3TxvD2Alg9tqb+nmfab7eR2DD6aWkfm20aq6/0m81Y6r9G8C9quqh4GHk/wgyQEMttHjGHwGAPZjsI3uD1xaVf8EkGShq/1fk+Q3GXQ/HQTcAvzvbt7wNrrmSdS+bBj8i8fHgV8F/jVwIYNQfvXQ/NXApl2s/8/1o6vxHgceBaiqx5Ps+H8O8GtVdfnwiklOZNd/VOi+GbwHOKaqvpfkImDvoUUe7X5ux+1quZq7jT4ZO7aTx4eGd4zvwWAb/XBV/dnwSkneze630b2BPwWmq+rOJGfhNjovu3oWj0sZ9OEfw+B2FpcDxyU5MMmBDPaCLt/F+qO4HPhPSfYESPJTSfYFvgq8uTsGsBJ4zTzrPgv4R+ChJIcyeJCO2jJ3G+3D5cB/TLIfQJJVSQ5hsI2enGSfJPsDb5xn3R0hf1+3/inzLCMa/6u3mFTVD5NcDTzYdbk8kOR3GdzUDuCDVfXAU2zm4wy+4l7fHfSaBU5i8IE+lsHX728CX5mnvhuT3MDgq/MdwN8+xVq0xMyzjZLkb4AXAPsluQs4be43yifYxpeSvBC4pjsu+wjwy1V1fZJPAZuB7zA4RjB33QeTnM9gO97Kjz47msN79SwS3QGz64FfqKrbJ12PNJfb6PJhV88ikMEFUt8CrvQDpcXIbXR5cY9/iUlyLfDMOZPfUlU3TaIeaa4klwJHzJn8vqfSBaSnl8EvSY2xq0eSGmPwS1JjDH5JaozBL0mN+f/axxR1uj9HtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEJCAYAAACOr7BbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYBUlEQVR4nO3dfbRddX3n8feHAKIgGElEzYOJFYswIuo11bFTYdQYn0BHq2F8wIqNOqJTx9rBzhpBtPWp2rWqVImShVIFWysaNBhQRHSUmhulPCklRmzuhDGRAEJVIPCdP85OOdzse3NC7s69uXm/1jrrnv37/fY+33Oycz93P55UFZIkjbbPZBcgSZqaDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0LaRUnuSPLYya5DmmjxOghJUhu3ICRJrQwITWlJ5iX5UpLNSW5O8vGm/XeSXNq0/TLJ55I8rG++G5O8M8lVSf4tydlJDktyUZLbk3wjycxm7IIklWRZko1Jbkryjr5lLUry/SS3Nn0fT7J/X38leVzz/NAkFyb5VZI1Sd6X5Lujxr4pyQ1JbklyZpIM+FmcnuQfkvxd8x6uTvL4JO9KsinJhiSL+8Yf0rzvm5L836aWGTvx+f1p8/ndluQLSQ54IP+G2nMZEJqyml9mXwV+DiwA5gDnb+sG3g88GngCMA84fdQiXgY8F3g88GLgIuDPgVn01v23jRp/HHA4sBg4NclzmvZ7gLc38z0DeDbw38Yo+0zg34BHAic1j9FeBDwNeBLwCuB5zfud34TQ/DGWTfM+zgVmAj8CVjfvZQ5wBnBW39jPAFuBxwFPbt7XG5q+QT6/VwBLgIXA0cDrxqlL01FV+fAxJR/0fhlvBvYdYOxLgB/1Td8IvKpv+h+BT/RNvxX4cvN8AVDAEX39HwLOHuO1/gS4oG+66P0SngHcDfxuX9/7gO+OGvv7fdN/D5w64OdxOnBJ3/SLgTuAGc30Q5vlPww4DLgTeHDf+BOBb+3E5/fqUZ/HJyd7nfCxex/77kK2SF2bB/y8qraO7kjyCOBvgP9E7xfjPsAto4b9ou/5b1qmDxo1fkPf858DT2xe6/HAR4Eh4CHAvsDalnpnN339y9nQMu7/9T3/dUsd4xn9Hn5ZVff0TdMs79HAfsBNfXuw9tlWz4Cf3+g6H70TdWoacBeTprINwPwkbX/IvJ/eX8tHV9XBwKvp7TbZFfP6ns8HNjbPPwH8BDi8ea0/H+O1NtPbpTN3jGXuThvobUHMqqqHNY+Dq+qopr+Lz0/TjAGhqewHwE3AB5IcmOSAJM9s+h5Kb/fKrUnmAO+cgNf730kekuQo4I+AL/S91q+AO5IcAby5bebmL/kvAac3yzkCeO0E1LXTquom4GLgI0kOTrJPc2D6Wc2QLj4/TTMGhKas5hfui+nt3/9XYAR4ZdP9HuApwG3A1+j9Yt5V3wbWAd8E/qqqLm7a/xT4r8DtwKe4LzjanAIcQm/3zLnAefT+kt+h5iD1HTs4SL0zXgvsD1xHb/fRF4FHNX1dfH6aZrxQTnu9JAuAnwH7tR3v2MVlfxB4ZFW1nc0kTWluQUgTKMkRSY5OzyLgZOCCya5LeiA8i0maWA+lt1vp0cAm4CPAVya1IukBcheTJKmVu5gkSa2m1S6mWbNm1YIFCya7DEnaY6xdu/aXVTW7rW9aBcSCBQsYHh6e7DIkaY+R5Odj9bmLSZLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1mlZfOborFpz6tckuQVPUjR944WSXIE2KzgIiyQrgRcCmqvoPLf3vBF7VV8cTgNlVtSXJjcDtwD3A1qoa6qpOSVK7LncxnQMsGauzqj5cVcdU1THAu4BvV9WWviHHNf2GgyRNgs4CoqouB7bscGDPicB5XdUiSdp5k36QOslD6G1p/GNfcwEXJ1mbZNkO5l+WZDjJ8ObNm7ssVZL2KpMeEMCLgf8zavfSM6vqKcDzgbck+YOxZq6q5VU1VFVDs2fP7rpWSdprTIWAWMqo3UtVtbH5uQm4AFg0CXVJ0l5tUgMiySHAs4Cv9LUdmOSh254Di4FrJqdCSdp7dXma63nAscCsJCPAacB+AFX1yWbYS4GLq+rf+mY9DLggybb6Pl9VX++qTklSu84CoqpOHGDMOfROh+1vWw88qZuqJEmDmgrHICRJU5ABIUlq5b2YpD2E9wvTWLq6X5hbEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJatVZQCRZkWRTkmvG6D82yW1Jrmwe7+7rW5Lk+iTrkpzaVY2SpLF1uQVxDrBkB2O+U1XHNI8zAJLMAM4Eng8cCZyY5MgO65QktegsIKrqcmDLA5h1EbCuqtZX1V3A+cAJE1qcJGmHJvsYxDOS/HOSi5Ic1bTNATb0jRlp2iRJu9Fkfif1D4HHVNUdSV4AfBk4HEjL2BprIUmWAcsA5s+f30WdkrRXmrQtiKr6VVXd0TxfBeyXZBa9LYZ5fUPnAhvHWc7yqhqqqqHZs2d3WrMk7U0mLSCSPDJJmueLmlpuBtYAhydZmGR/YCmwcrLqlKS9VWe7mJKcBxwLzEoyApwG7AdQVZ8EXg68OclW4DfA0qoqYGuSU4DVwAxgRVVd21WdkqR2nQVEVZ24g/6PAx8fo28VsKqLuiRJg5nss5gkSVOUASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWnUWEElWJNmU5Jox+l+V5Krm8b0kT+rruzHJ1UmuTDLcVY2SpLF1uQVxDrBknP6fAc+qqqOB9wLLR/UfV1XHVNVQR/VJksaxb1cLrqrLkywYp/97fZNXAHO7qkWStPOmyjGIk4GL+qYLuDjJ2iTLxpsxybIkw0mGN2/e3GmRkrQ36WwLYlBJjqMXEL/f1/zMqtqY5BHAJUl+UlWXt81fVctpdk8NDQ1V5wVL0l5iUrcgkhwNfBo4oapu3tZeVRubn5uAC4BFk1OhJO29Ji0gkswHvgS8pqr+pa/9wCQP3fYcWAy0ngklSepOZ7uYkpwHHAvMSjICnAbsB1BVnwTeDRwK/G0SgK3NGUuHARc0bfsCn6+qr3dVpySpXZdnMZ24g/43AG9oaV8PPGn7OSRJu9NUOYtJkjTFGBCSpFYGhCSp1cDHIJL8R2BB/zxV9dkOapIkTQEDBUSSc4HfAa4E7mmaCzAgJGmaGnQLYgg4sqq8UlmS9hKDHoO4Bnhkl4VIkqaWQbcgZgHXJfkBcOe2xqo6vpOqJEmTbtCAOL3LIiRJU89AAVFV3+66EEnS1DLoWUy30ztrqd9twDDwjub2GJKkaWTQXUwfBTYCnwcCLKV30Pp6YAW9m/JJkqaRQc9iWlJVZ1XV7VX1q+ZLel5QVV8AZnZYnyRpkgwaEPcmeUWSfZrHK/r6vDZCkqahQQPiVcBrgE3AL5rnr07yYOCUjmqTJE2iQc9iWg+8eIzu705cOZKkqWLcgEjyZ1X1oSQfo2VXUlW9rbPKJEmTakdbED9ufg53XYgkaWoZNyCq6sLm52d2TzmSpKlioIPUSWYn+askq5Jcuu0xwHwrkmxKcs0Y/UnyN0nWJbkqyVP6+k5KckPzOGnwtyRJmgiDnsX0OXq7mxYC7wFuBNYMMN85wJJx+p8PHN48lgGfAEjycOA04PeARcBpSbzeQpJ2o0ED4tCqOhu4u6q+XVWvB56+o5mq6nJgyzhDTgA+Wz1XAA9L8ijgecAlVbWlqm4BLmH8oJEkTbBBb7Vxd/PzpiQvpHfbjbkT8PpzgA190yNN21jt20myjN7WB/Pnz5+AkiRJMHhAvC/JIcA7gI8BBwNvn4DXT0tbjdO+fWPvth/LAYaGhryqW5ImyKAXyn21eXobcNwEvv4IMK9vei69rZMR7n8DwLnAZRP4upKkHRj0LKbHJrkwyS+bs5K+kuSxE/D6K4HXNmczPR24rapuAlYDi5PMbA5OL27aJEm7yaC7mD4PnAm8tJleCpxH7yyjMSU5j96WwKwkI/TOTNoPoKo+CawCXgCsA34N/FHTtyXJe7nvTKkzqmq8g92SpAk2aECkqs7tm/67JDu8SV9VnbiD/gLeMkbfCnrfNSFJmgSDBsS3kpwKnE/vYPErga811yvgX/eSNP0MGhCvbH6+cVT76+kFxkQcj5AkTSGDnsW0sOtCJElTy0ABkWQG8EJgQf88VfXRbsqSJE22QXcxXQj8FrgauLe7ciRJU8WgATG3qo7utBJJ0pQy6M36LkqyuNNKJElTyqBbEFcAFyTZh96N+0LvMoaDO6tMkjSpBg2IjwDPAK5uLm6TJE1zg+5iugG4xnCQpL3HoFsQNwGXJbkIuHNbo6e5StL0NWhA/Kx57N88JEnT3KBXUr+n60IkSVPLoFdSzwb+DDgKOGBbe1X9547qkiRNskEPUn8O+AmwEHgPcCP3fVeDJGkaGjQgDq2qs4G7q+rbVfV64Okd1iVJmmSDHqS+u/l5U5IX0vve6LndlCRJmgoGDYj3JTkEeAfwMeBg4E86q0qSNOkG3cX0h/S+dvSaqjoOeC73fT+1JGkaGjQgjq6qW7dNNF8x+uQdzZRkSZLrk6xrvrJ0dP9fJ7myefxLklv7+u7p61s5YJ2SpAky6C6mfZLMrKpbAJrvoh533uZLhs6kt7UxAqxJsrKqrts2pqre3jf+rdw/dH5TVccMWJ8kaYLtzM36vpfki/S+g/oVwF/sYJ5FwLqqWg+Q5HzgBOC6McafCJw2YD2SpI4NtIupqj4LvAz4BbAZ+C9Vde4OZpsDbOibHmnatpPkMfSusbi0r/mAJMNJrkjykrFeJMmyZtzw5s2bB3g3kqRBDLoFQbNraKy//tukbTFjjF0KfLGq7ulrm19VG5M8Frg0ydVV9dOWupYDywGGhoa826wkTZBBD1I/ECPAvL7pufSun2izFDivv6GqNjY/1wOXMcBBcUnSxOkyINYAhydZmGR/eiGw3dlISX4XmAl8v69tZpIHNc9nAc9k57ZeJEm7aOBdTDurqrYmOQVYDcwAVlTVtUnOAIaraltYnAicP+rLiJ4AnJXkXnoh9oH+s58kSd3rLCAAqmoVsGpU27tHTZ/eMt/3gCd2WZskaXxd7mKSJO3BDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVKrTgMiyZIk1ydZl+TUlv7XJdmc5Mrm8Ya+vpOS3NA8TuqyTknS9jr7TuokM4AzgecCI8CaJCur6rpRQ79QVaeMmvfhwGnAEFDA2mbeW7qqV5J0f11uQSwC1lXV+qq6CzgfOGHAeZ8HXFJVW5pQuARY0lGdkqQWXQbEHGBD3/RI0zbay5JcleSLSebt5LySpI50GRBpaatR0xcCC6rqaOAbwGd2Yt7ewGRZkuEkw5s3b37AxUqS7q/LgBgB5vVNzwU29g+oqpur6s5m8lPAUwedt28Zy6tqqKqGZs+ePSGFS5K6DYg1wOFJFibZH1gKrOwfkORRfZPHAz9unq8GFieZmWQmsLhpkyTtJp2dxVRVW5OcQu8X+wxgRVVdm+QMYLiqVgJvS3I8sBXYAryumXdLkvfSCxmAM6pqS1e1SpK211lAAFTVKmDVqLZ39z1/F/CuMeZdAazosj5J0ti8klqS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtOg2IJEuSXJ9kXZJTW/r/R5LrklyV5JtJHtPXd0+SK5vHyi7rlCRtb9+uFpxkBnAm8FxgBFiTZGVVXdc37EfAUFX9OsmbgQ8Br2z6flNVx3RVnyRpfF1uQSwC1lXV+qq6CzgfOKF/QFV9q6p+3UxeAcztsB5J0k7oMiDmABv6pkeatrGcDFzUN31AkuEkVyR5yVgzJVnWjBvevHnzrlUsSfp3ne1iAtLSVq0Dk1cDQ8Cz+prnV9XGJI8FLk1ydVX9dLsFVi0HlgMMDQ21Ll+StPO63IIYAeb1Tc8FNo4elOQ5wP8Cjq+qO7e1V9XG5ud64DLgyR3WKkkapcuAWAMcnmRhkv2BpcD9zkZK8mTgLHrhsKmvfWaSBzXPZwHPBPoPbkuSOtbZLqaq2prkFGA1MANYUVXXJjkDGK6qlcCHgYOAf0gC8K9VdTzwBOCsJPfSC7EPjDr7SZLUsS6PQVBVq4BVo9re3ff8OWPM9z3giV3WJkkan1dSS5JaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqVWnAZFkSZLrk6xLcmpL/4OSfKHp/6ckC/r63tW0X5/keV3WKUnaXmcBkWQGcCbwfOBI4MQkR44adjJwS1U9Dvhr4IPNvEcCS4GjgCXA3zbLkyTtJl1uQSwC1lXV+qq6CzgfOGHUmBOAzzTPvwg8O0ma9vOr6s6q+hmwrlmeJGk32bfDZc8BNvRNjwC/N9aYqtqa5Dbg0Kb9ilHzzml7kSTLgGXN5B1Jrt/10vd6s4BfTnYRU0U+ONkVaAyup41dXEcfM1ZHlwGRlrYacMwg8/Yaq5YDy3euNI0nyXBVDU12HdJ4XE+71+UuphFgXt/0XGDjWGOS7AscAmwZcF5JUoe6DIg1wOFJFibZn95B55WjxqwETmqevxy4tKqqaV/anOW0EDgc+EGHtUqSRulsF1NzTOEUYDUwA1hRVdcmOQMYrqqVwNnAuUnW0dtyWNrMe22SvweuA7YCb6mqe7qqVdtxl532BK6nHUvvD3ZJku7PK6klSa0MCElSKwNCktTKgJiGkpyU5IbmcdKO55B2ryRfT3Jrkq9Odi0amwepp5kkDweGgSF6FxeuBZ5aVbdMamFSnyTPBh4CvLGqXjTZ9aidWxB7sCTvTfLf+6b/AngrcElVbWlC4RJ6Nzwcaxl3JPlgkrVJvpFkUZLLkqxPcnwzZkaSDydZk+SqJG9s2g9K8s0kP0xydZITmvYFSX6c5FNJrk1ycZIHd/lZaGpqW0eTvK2qvgncPuAybkzyl0m+n2Q4yVOSrE7y0yRv6hv3zr519D197V9u1u9rm1vzbGu/o6nnn5NckeSwCXrb04YBsWc7m+ZCwyT70LuO5Ldsfw+s1vtYNQ4ELquqp9L7D/s+4LnAS4EzmjEnA7dV1dOApwF/3FzA+FvgpVX1FOA44CPNzRahd3HjmVV1FHAr8LJdfK/aM7Wto597AMvZUFXPAL4DnEPvwtqn06yjSRbTW+cWAccAT03yB828r2/W7yHgbUkObdoPBK6oqicBlwN//ADqmta6vBeTOlZVNya5OcmTgcOAHwH3tg0dZzF3AV9vnl8N3FlVdye5GljQtC8Gjk7y8mb6EHr/GUeAv2z+I95LL4i2/RX2s6q6snm+tm9Z2ou0raNVdfMDWNS2uzBcDRxUVbcDtyf5bZKH0VtHF9P7PwBwEL119HJ6ofDSpn1e034zvXV/2zGQtfT+MFIfA2LP92ngdcAjgRX0fnkf29c/F7hsnPnvrvsORN0L3AlQVfc298eC3s0T31pVq/tnTPI6YDa9Yxx3J7kROKDpvrNv6D2Au5j2XqPX0Qdi2/p0L/dft+6l93sswPur6qz+mZIcCzwHeEZV/TrJZdy3jvav+/fg78PtuItpz3cBvWMMT6N3W5PVwOIkM5PMpPdX1epx5h/EauDNSfYDSPL4JAfSC6NNTTgcxzi3DdZebfQ62oXVwOuTHASQZE6SR9BbR29pwuEIerulNCATcw9XVXcl+RZwa3O/qi1J3kvvZokAZ1TVll18mU/T20X0w+YYw2bgJfT2JV+YZBi4EvjJLr6OpqGWdZQk3wGOAA5KMgKcPHoLdSdf4+IkTwC+3xwGuwN4Nb3dp29KchVwPff/nhntgKe57uGaA38/BP6wqm6Y7Hqk0VxH91zuYtqDNd/dvQ74pv/xNBW5ju7Z3ILYSyT5J+BBo5pfU1VXT0Y90mhJLgAWjmr+n7uy60m7xoCQJLVyF5MkqZUBIUlqZUBIkloZEJKkVv8f6QXW6Nwjp9YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for target_col in numeric_col_list:\n",
    "\n",
    "    #0,1別平均値\n",
    "    y0_target_col_mean = y0_df[target_col].mean()\n",
    "    y1_target_col_mean = y1_df[target_col].mean()\n",
    "\n",
    "    #0,1別中央値\n",
    "    y0_target_col_median = y0_df[target_col].median()\n",
    "    y1_target_col_median = y1_df[target_col].median()\n",
    "\n",
    "    #縦軸設定\n",
    "    #平均値、中央値のうち最大値の1.1倍を縦軸とする\n",
    "    #倍率は見やすければ何でもよい\n",
    "    graph_y_length = (1.1*max(y0_target_col_mean,y1_target_col_mean,y0_target_col_median,y1_target_col_median))\n",
    "\n",
    "    plt.title(target_col + \": mean\")\n",
    "    plt.ylabel(target_col)\n",
    "    plt.ylim([0,graph_y_length],)\n",
    "    plt.bar([\"y0_mean\",\"y1_mean\"],[y0_target_col_mean,y1_target_col_mean])\n",
    "    #plt.annotate(y0_target_col_mean,y0_target_col_mean)\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(target_col + \": median\")\n",
    "    plt.ylabel(target_col)\n",
    "    plt.ylim([0,graph_y_length],)\n",
    "    plt.bar([\"y0_median\",\"y1_median\"],[y0_target_col_median,y1_target_col_median],color = \"green\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 age\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 age\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOAElEQVR4nO3cf4xl5V3H8fdHtlXbalhkIbi7utRstGhSIBOK1hhslQJtXEwk0qjdEMz6B8TW1Jht/0HbmNBEW9ukkqyA3SYVSvojbCopblaS+g/IbNtQKG3YUITpruzUbWljk1b06x/3TLi7OzszzO7eO9Pv+5VMzjnf89y5zz37zOeefe65J1WFJKmHH5t2ByRJk2PoS1Ijhr4kNWLoS1Ijhr4kNbJh2h1Yyvnnn1/btm2bdjckaV05ePDgt6pq02L71nTob9u2jdnZ2Wl3Q5LWlST/cap9Tu9IUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiPLhn6SrUkeSvJkkieSvHOon5dkf5KnhuXGoZ4kH0lyKMljSS4f+107h/ZPJdl59l6WJGkxKznTfxF4d1W9DrgSuCXJJcBu4EBVbQcODNsA1wLbh59dwB0wepMAbgPeAFwB3LbwRiFJmoxlQ7+qjlTVF4f17wFPApuBHcDeodle4PphfQfw8Rp5GDg3yUXAW4D9VXWsqr4N7AeuOaOvRpK0pJc1p59kG3AZ8AhwYVUdgdEbA3DB0Gwz8NzYw+aG2qnqJz7HriSzSWbn5+dfTvckSctYcegneQ3waeBdVfXdpZouUqsl6scXqvZU1UxVzWzatGml3ZMkrcCKQj/JKxgF/ieq6jND+flh2oZheXSozwFbxx6+BTi8RF2SNCEruXonwF3Ak1X1wbFd+4CFK3B2AveP1d8xXMVzJfDCMP3zIHB1ko3DB7hXDzVJ0oRsWEGbNwJ/BHwlyZeH2nuB24H7ktwMPAvcMOx7ALgOOAR8H7gJoKqOJXk/8OjQ7n1VdeyMvApJ0oqk6qRp9TVjZmamZmdnp90NSVpXkhysqpnF9vmNXElqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEaWDf0kdyc5muTxsdpfJvlmki8PP9eN7XtPkkNJvp7kLWP1a4baoSS7z/xLkSQtZyVn+h8Drlmk/qGqunT4eQAgySXAjcAvD4/5+yTnJDkH+ChwLXAJ8PahrSRpgjYs16CqvpBk2wp/3w7g3qr6AfCNJIeAK4Z9h6rqaYAk9w5tv/qyeyxJWrXTmdO/Ncljw/TPxqG2GXhurM3cUDtV/SRJdiWZTTI7Pz9/Gt2TJJ1otaF/B/ALwKXAEeBvh3oWaVtL1E8uVu2pqpmqmtm0adMquydJWsyy0zuLqarnF9aT/APwuWFzDtg61nQLcHhYP1VdkjQhqzrTT3LR2ObvAgtX9uwDbkzy40kuBrYD/w48CmxPcnGSVzL6sHff6rstSVqNZc/0k9wDXAWcn2QOuA24KsmljKZongH+BKCqnkhyH6MPaF8Ebqmq/x1+z63Ag8A5wN1V9cQZfzWSpCWlatGp9TVhZmamZmdnp90NSVpXkhysqpnF9vmNXElqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqZNnQT3J3kqNJHh+rnZdkf5KnhuXGoZ4kH0lyKMljSS4fe8zOof1TSXaenZcjSVrKSs70PwZcc0JtN3CgqrYDB4ZtgGuB7cPPLuAOGL1JALcBbwCuAG5beKOQJE3OsqFfVV8Ajp1Q3gHsHdb3AteP1T9eIw8D5ya5CHgLsL+qjlXVt4H9nPxGIkk6y1Y7p39hVR0BGJYXDPXNwHNj7eaG2qnqJ0myK8lsktn5+flVdk+StJgz/UFuFqnVEvWTi1V7qmqmqmY2bdp0RjsnSd2tNvSfH6ZtGJZHh/ocsHWs3Rbg8BJ1SdIErTb09wELV+DsBO4fq79juIrnSuCFYfrnQeDqJBuHD3CvHmqSpAnasFyDJPcAVwHnJ5ljdBXO7cB9SW4GngVuGJo/AFwHHAK+D9wEUFXHkrwfeHRo976qOvHDYUnSWZaqRafW14SZmZmanZ2ddjckaV1JcrCqZhbb5zdyJakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjH0JakRQ1+SGjmt0E/yTJKvJPlyktmhdl6S/UmeGpYbh3qSfCTJoSSPJbn8TLwASdLKnYkz/d+sqkurambY3g0cqKrtwIFhG+BaYPvwswu44ww8tyTpZTgb0zs7gL3D+l7g+rH6x2vkYeDcJBedheeXJJ3C6YZ+Af+S5GCSXUPtwqo6AjAsLxjqm4Hnxh47N9SOk2RXktkks/Pz86fZPUnSuA2n+fg3VtXhJBcA+5N8bYm2WaRWJxWq9gB7AGZmZk7aL0lavdM606+qw8PyKPBZ4Arg+YVpm2F5dGg+B2wde/gW4PDpPL8k6eVZdegneXWSn1pYB64GHgf2ATuHZjuB+4f1fcA7hqt4rgReWJgGkiRNxulM71wIfDbJwu/5p6r6fJJHgfuS3Aw8C9wwtH8AuA44BHwfuOk0nluStAqrDv2qehp4/SL1/wLevEi9gFtW+3xaG7bt/udF68/c/tYJ90TSaviNXElqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEYMfUlqxNCXpEZO94ZrEuCXtqT1wjN9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRrwNg86qU92eAbxFgzQNhr6mxvv1SJNn6OskS52dS1rfnNOXpEY805fWEafEdLo805ekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrESzalNcgvyOlsMfTV1mquefc6ea13Tu9IUiOe6etHwpm8m+eZnlrxfwdaSzzTl6RGJn6mn+Qa4MPAOcCdVXX7pPug9Ws1Z+F+KCq9ZKKhn+Qc4KPAbwNzwKNJ9lXVVyfZD42s1TBcq/1aynrss3qa9Jn+FcChqnoaIMm9wA7A0D9LDKO1y38bTcOkQ38z8NzY9hzwhvEGSXYBu4bNHyR5fEJ9Ww/OB7417U6sIR6PQT7gsThB9+Px86faMenQzyK1Om6jag+wByDJbFXNTKJj64HH43gej5d4LI7n8Ti1SV+9MwdsHdveAhyecB8kqa1Jh/6jwPYkFyd5JXAjsG/CfZCktiY6vVNVLya5FXiQ0SWbd1fVE0s8ZM9kerZueDyO5/F4icfieB6PU0hVLd9KkvQjwW/kSlIjhr4kNbJmQz/JNUm+nuRQkt3T7s+kJdma5KEkTyZ5Isk7h/p5SfYneWpYbpx2XyclyTlJvpTkc8P2xUkeGY7FJ4eLA1pIcm6STyX52jBGfrXr2EjyZ8PfyONJ7knyE53HxnLWZOiP3a7hWuAS4O1JLplurybuReDdVfU64ErgluEY7AYOVNV24MCw3cU7gSfHtj8AfGg4Ft8Gbp5Kr6bjw8Dnq+qXgNczOi7txkaSzcCfAjNV9SuMLhC5kd5jY0lrMvQZu11DVf0QWLhdQxtVdaSqvjisf4/RH/VmRsdh79BsL3D9dHo4WUm2AG8F7hy2A7wJ+NTQpNOx+GngN4C7AKrqh1X1HZqODUZXIf5kkg3Aq4AjNB0bK7FWQ3+x2zVsnlJfpi7JNuAy4BHgwqo6AqM3BuCC6fVsov4O+Avg/4btnwG+U1UvDtudxshrgXngH4fprjuTvJqGY6Oqvgn8DfAso7B/AThI37GxrLUa+sverqGLJK8BPg28q6q+O+3+TEOStwFHq+rgeHmRpl3GyAbgcuCOqroM+G8aTOUsZvjcYgdwMfCzwKsZTQufqMvYWNZaDX1v1wAkeQWjwP9EVX1mKD+f5KJh/0XA0Wn1b4LeCPxOkmcYTfW9idGZ/7nDf+mh1xiZA+aq6pFh+1OM3gQ6jo3fAr5RVfNV9T/AZ4Bfo+/YWNZaDf32t2sY5qzvAp6sqg+O7doH7BzWdwL3T7pvk1ZV76mqLVW1jdFY+Neq+gPgIeD3hmYtjgVAVf0n8FySXxxKb2Z0e/J2Y4PRtM6VSV41/M0sHIuWY2Ml1uw3cpNcx+hsbuF2DX895S5NVJJfB/4N+AovzWO/l9G8/n3AzzEa8DdU1bGpdHIKklwF/HlVvS3Jaxmd+Z8HfAn4w6r6wTT7NylJLmX0ofYrgaeBmxidxLUbG0n+Cvh9Rle8fQn4Y0Zz+C3HxnLWbOhLks68tTq9I0k6Cwx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRv4feL6LvvgTWTYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 balance\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 balance\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 duration\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 duration\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 campaign\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 campaign\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 pdays\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 pdays\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0 previous\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 previous\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ヒストグラムでも全体像把握\n",
    "for target_col in numeric_col_list:\n",
    "    #軸の設定\n",
    "    graph_x_length = 1.1*max(train_df[target_col])\n",
    "    graph_y_length = len(y0_df)\n",
    "\n",
    "    print(\"y0\",target_col)\n",
    "    plt.xlim([0,graph_x_length],)\n",
    "    plt.ylim([0,graph_y_length],)\n",
    "    plt.hist(y0_df[target_col],bins = 20)\n",
    "    plt.show()\n",
    "\n",
    "    graph_y_length = graph_y_length/10\n",
    "    print(\"y1\",target_col)\n",
    "    plt.xlim([0,graph_x_length],)\n",
    "    plt.ylim([0,graph_y_length],)\n",
    "    plt.hist(y1_df[target_col],bins = 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>age_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>-0.001724</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.007897</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.010432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.008676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>-0.059669</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>-0.055642</td>\n",
       "      <td>0.037633</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.086668</td>\n",
       "      <td>0.931341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.002334</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.009717</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.001724</td>\n",
       "      <td>-0.059669</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079510</td>\n",
       "      <td>0.134440</td>\n",
       "      <td>-0.060326</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.048624</td>\n",
       "      <td>-0.011804</td>\n",
       "      <td>-0.058463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>-0.079510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.140541</td>\n",
       "      <td>0.113377</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>-0.041304</td>\n",
       "      <td>-0.049524</td>\n",
       "      <td>0.099008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>-0.001855</td>\n",
       "      <td>-0.055642</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.134440</td>\n",
       "      <td>-0.140541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094643</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>-0.015184</td>\n",
       "      <td>-0.030313</td>\n",
       "      <td>-0.052068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>-0.007897</td>\n",
       "      <td>0.037633</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>-0.060326</td>\n",
       "      <td>0.113377</td>\n",
       "      <td>-0.094643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003626</td>\n",
       "      <td>-0.038244</td>\n",
       "      <td>-0.030653</td>\n",
       "      <td>0.039394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>-0.003626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.002858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>-0.003045</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.009717</td>\n",
       "      <td>-0.048624</td>\n",
       "      <td>-0.041304</td>\n",
       "      <td>-0.015184</td>\n",
       "      <td>-0.038244</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188473</td>\n",
       "      <td>0.048863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.086668</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>-0.011804</td>\n",
       "      <td>-0.049524</td>\n",
       "      <td>-0.030313</td>\n",
       "      <td>-0.030653</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.188473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_round</th>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.931341</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>-0.058463</td>\n",
       "      <td>0.099008</td>\n",
       "      <td>-0.052068</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>0.048863</td>\n",
       "      <td>0.078462</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       age   balance       day     month  duration  \\\n",
       "id         1.000000  0.008676  0.002334 -0.001724  0.003756 -0.001855   \n",
       "age        0.008676  1.000000 -0.001185 -0.059669  0.105084 -0.055642   \n",
       "balance    0.002334 -0.001185  1.000000  0.003816 -0.004632  0.003144   \n",
       "day       -0.001724 -0.059669  0.003816  1.000000 -0.079510  0.134440   \n",
       "month      0.003756  0.105084 -0.004632 -0.079510  1.000000 -0.140541   \n",
       "duration  -0.001855 -0.055642  0.003144  0.134440 -0.140541  1.000000   \n",
       "campaign  -0.007897  0.037633 -0.001229 -0.060326  0.113377 -0.094643   \n",
       "pdays      0.001369  0.008551  0.003018 -0.000433  0.001434  0.003804   \n",
       "previous  -0.003045  0.037545  0.009717 -0.048624 -0.041304 -0.015184   \n",
       "y          0.002318  0.086668 -0.000899 -0.011804 -0.049524 -0.030313   \n",
       "age_round  0.010432  0.931341  0.000427 -0.058463  0.099008 -0.052068   \n",
       "\n",
       "           campaign     pdays  previous         y  age_round  \n",
       "id        -0.007897  0.001369 -0.003045  0.002318   0.010432  \n",
       "age        0.037633  0.008551  0.037545  0.086668   0.931341  \n",
       "balance   -0.001229  0.003018  0.009717 -0.000899   0.000427  \n",
       "day       -0.060326 -0.000433 -0.048624 -0.011804  -0.058463  \n",
       "month      0.113377  0.001434 -0.041304 -0.049524   0.099008  \n",
       "duration  -0.094643  0.003804 -0.015184 -0.030313  -0.052068  \n",
       "campaign   1.000000 -0.003626 -0.038244 -0.030653   0.039394  \n",
       "pdays     -0.003626  1.000000  0.002187 -0.000116   0.002858  \n",
       "previous  -0.038244  0.002187  1.000000  0.188473   0.048863  \n",
       "y         -0.030653 -0.000116  0.188473  1.000000   0.078462  \n",
       "age_round  0.039394  0.002858  0.048863  0.078462   1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#相関係数算出\n",
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0.002318\n",
       "age          0.086668\n",
       "balance     -0.000899\n",
       "day         -0.011804\n",
       "month       -0.049524\n",
       "duration    -0.030313\n",
       "campaign    -0.030653\n",
       "pdays       -0.000116\n",
       "previous     0.188473\n",
       "y            1.000000\n",
       "age_round    0.078462\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#目的変数の相関係数だけピックアップ\n",
    "train_df.corr()[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import functools\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#こいつがマジで有能\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib \n",
    "\n",
    "\n",
    "#dataの読み込み\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "submit_df = pd.read_csv(\"submit_sample.csv\",header = None)\n",
    "\n",
    "\n",
    "#訓練データ、テストデータがわかるようにダミーの目的変数を代入\n",
    "test_df[\"y\"] = -999\n",
    "\n",
    "#訓練データ、テストデータを結合\n",
    "all_df = pd.concat([train_df,test_df])\n",
    "del train_df , test_df\n",
    "\n",
    "all_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "#月末フラグ\n",
    "month_list = list(all_df[\"month\"])\n",
    "day_list = list(all_df[\"day\"])\n",
    "\n",
    "end_of_month_flag = []\n",
    "for i in range(len(all_df)):\n",
    "    if day_list[i] in [30,31]:\n",
    "        end_of_month_flag.append(1)\n",
    "    elif day_list[i] == 29 and month_list[i] in [\"feb\",\"apr\",\"jun\",\"sep\",\"nov\"]:\n",
    "        end_of_month_flag.append(1)\n",
    "    elif day_list[i] == 28 and month_list[i] == \"feb\":\n",
    "        end_of_month_flag.append(1)\n",
    "    else:\n",
    "        end_of_month_flag.append(0)\n",
    "\n",
    "all_df[\"end_of_month_flag\"] = end_of_month_flag\n",
    "\n",
    "\n",
    "#月(month列)を数値に変換\n",
    "month_dict = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12}\n",
    "month_int = [month_dict[all_df[\"month\"][i]] for i in range(len(all_df))]\n",
    "all_df[\"month\"] = month_int\n",
    "\n",
    "#month_day列作成\n",
    "#決定木は大小関係さえわかればいいのでintのまま扱って問題ないと思っています\n",
    "month_day = []\n",
    "month_day = all_df[\"month\"]*100 + all_df[\"day\"]\n",
    "all_df[\"month_day\"] = month_day\n",
    "\n",
    "#不要列削除\n",
    "del all_df[\"index\"]\n",
    "del all_df[\"id\"]\n",
    "del all_df[\"pdays\"]\n",
    "del all_df[\"balance\"]\n",
    "\n",
    "#カテゴリカルのカラム名を指定\n",
    "categorical_features = [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\",\"month\",\"poutcome\",\"end_of_month_flag\"]\n",
    "\n",
    "\n",
    "#ラベルエンコード\n",
    "#target encodingもしましたがスコアは変わらなかったです\n",
    "\n",
    "for col in categorical_features:\n",
    "  lbl = preprocessing.LabelEncoder()\n",
    "  lbl.fit(all_df[col])\n",
    "  lbl.transform(all_df[col])\n",
    "  all_df[col] = lbl.transform(all_df[col])\n",
    "\n",
    "\n",
    "#訓練データ、テストデータの分割\n",
    "train_df = all_df[all_df[\"y\"] != -999]\n",
    "test_df = all_df[all_df[\"y\"] == -999]\n",
    "\n",
    "#説明変数と目的変数に分ける\n",
    "origin_y_train = train_df[\"y\"]\n",
    "origin_X_train = train_df.drop([\"y\"],axis = 1)\n",
    "origin_X_test = test_df.drop([\"y\"],axis = 1)\n",
    "\n",
    "output_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##ここから先の実行は私のPC(第10世代corei5 メモリ8GB)では10数時間かかりました\n",
    "\n",
    "for i in range(100):\n",
    "    #訓練データからテストデータを分割\n",
    "    X_train , X_valid , y_train , y_valid = train_test_split(origin_X_train,origin_y_train,test_size = 0.3 , random_state = i , stratify=origin_y_train)\n",
    "    #データセット作成\n",
    "    lgb_train = lgb.Dataset(X_train,y_train,categorical_feature = categorical_features,free_raw_data=False)\n",
    "    lgb_eval = lgb.Dataset(X_valid , y_valid , reference = lgb_train , categorical_feature = categorical_features,free_raw_data=False)\n",
    "    params ={\"objective\":\"binary\",\n",
    "             \"metric\":\"auc\",\n",
    "             'force_col_wise': 'true',\n",
    "    }\n",
    "\n",
    "    best_params, tuning_history = dict(), list()\n",
    "    booster = lgb.train(params, lgb_train, valid_sets=[lgb_train,lgb_eval],\n",
    "                        verbose_eval=0,\n",
    "                        best_params=best_params,\n",
    "                        tuning_history=tuning_history)\n",
    "\n",
    "    print(\"Best Params:\", best_params)\n",
    "    print(\"Tuning history:\", tuning_history)\n",
    "\n",
    "    #最もAUCの高いハイパーパラメーターを追加\n",
    "    params.update(best_params)\n",
    "\n",
    "    #学習\n",
    "    model = lgb.train(\n",
    "        params,lgb_train,\n",
    "        valid_sets=[lgb_train,lgb_eval],\n",
    "        verbose_eval = 10,\n",
    "        num_boost_round = 1000,\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    #コンペデータで予測\n",
    "    y_pred = model.predict(origin_X_test,num_iteration=model.best_iteration)\n",
    "\n",
    "    output_df[i] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
